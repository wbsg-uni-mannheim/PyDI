{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3 - Information Extraction with PyDI\n",
    "\n",
    "In this exercise, you will learn how to use PyDI's information extraction module to extract structured information from unstructured text data. We'll work with product descriptions and demonstrate different extraction techniques including regex patterns, custom code functions, and evaluation metrics.\n",
    "\n",
    "This exercise uses evaluation methods adapted from the [SelfRefinement4ExtractGPT](https://github.com/wbsg-uni-mannheim/SelfRefinement4ExtractGPT) repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Data Loading\n",
    "\n",
    "First, let's import the necessary libraries and load our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add PyDI to path\n",
    "sys.path.append('../../../')\n",
    "\n",
    "# Import PyDI information extraction modules\n",
    "from PyDI.informationextraction import RegexExtractor, CodeExtractor, ExtractorPipeline\n",
    "from PyDI.informationextraction.rules import built_in_rules\n",
    "\n",
    "# Import evaluation utilities\n",
    "from evaluation import load_jsonl_targets, evaluate_predictions, print_evaluation_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.1: Load and Explore the Dataset\n",
    "\n",
    "Load the OA-Mine dataset which contains product descriptions with target attribute values. This dataset is commonly used for evaluating information extraction systems.\n",
    "\n",
    "The data format is JSONL where each line contains:\n",
    "- `input`: Product description text\n",
    "- `category`: Product category \n",
    "- `target_scores`: Dictionary of target attributes and their values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the target data from JSONL format\n",
    "targets_df = load_jsonl_targets('input/oa-mine_test.jsonl')\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(f\"Dataset shape: {targets_df.shape}\")\n",
    "print(f\"Columns: {list(targets_df.columns)}\")\n",
    "print(\"\\nFirst few examples:\")\n",
    "targets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the distribution of categories\n",
    "print(\"Category distribution:\")\n",
    "print(targets_df['category'].value_counts())\n",
    "\n",
    "# Look at some example product descriptions\n",
    "print(\"\\nSample product descriptions:\")\n",
    "for i in range(3):\n",
    "    print(f\"{i+1}. {targets_df['input'].iloc[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.2: Basic Regex-Based Extraction\n",
    "\n",
    "Create a RegexExtractor to extract product attributes using regular expression patterns. Start with simple patterns for common attributes like brand, gender, and size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Define regex rules for extracting product attributes\n",
    "# Hint: Create rules dictionary with pattern definitions for:\n",
    "# - Brand: Look for common brand patterns at the beginning\n",
    "# - Gender: Men's, Women's, Boys', Girls' patterns  \n",
    "# - Size: Numeric patterns with units\n",
    "# - Color: Common color names\n",
    "\n",
    "regex_rules = {\n",
    "    # Add your regex rules here\n",
    "    \"Brand\": {\n",
    "        \"source_column\": \"input\",\n",
    "        \"pattern\": r\"^([A-Za-z][A-Za-z\\s&\\.]+?)(?:\\s+(?:Men's|Women's|Boys'|Girls'|Mens|Womens|for|\\d))\",\n",
    "        \"group\": 1,\n",
    "        \"postprocess\": \"strip\"\n",
    "    },\n",
    "    # TODO: Add more rules\n",
    "}\n",
    "\n",
    "# Create the RegexExtractor\n",
    "# TODO: Initialize the extractor with your rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the regex extractor to the dataset\n",
    "# TODO: Use the extract method to process the targets_df\n",
    "\n",
    "# Display some results\n",
    "print(\"Regex extraction results (first 10 rows):\")\n",
    "# TODO: Show relevant columns from the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.3: Custom Code-Based Extraction\n",
    "\n",
    "For more complex extraction logic that can't be easily handled with regex, use the CodeExtractor with custom Python functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom extraction functions\n",
    "def extract_gender(text):\n",
    "    \"\"\"Extract gender information from product text.\"\"\"\n",
    "    text_lower = text.lower()\n",
    "    # TODO: Implement gender extraction logic\n",
    "    # Look for patterns like \"men's\", \"women's\", \"boys'\", \"girls'\"\n",
    "    # Return the extracted gender or None\n",
    "    pass\n",
    "\n",
    "def extract_shoe_type(text):\n",
    "    \"\"\"Extract shoe type from product description.\"\"\"\n",
    "    text_lower = text.lower()\n",
    "    # TODO: Implement shoe type extraction\n",
    "    # Look for patterns like \"sneaker\", \"boot\", \"sandal\", \"loafer\", etc.\n",
    "    # Return the extracted shoe type or None\n",
    "    pass\n",
    "\n",
    "def extract_size(text):\n",
    "    \"\"\"Extract size information from product text.\"\"\"\n",
    "    # TODO: Implement size extraction logic\n",
    "    # Look for numeric patterns, possibly with letters (like \"10 D US\")\n",
    "    # Return the extracted size or None\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define code extraction rules\n",
    "code_rules = {\n",
    "    # TODO: Define rules that use your custom functions\n",
    "    # Format: \"field_name\": {\"source_column\": \"input\", \"function\": function_name}\n",
    "}\n",
    "\n",
    "# Create and apply CodeExtractor\n",
    "# TODO: Initialize CodeExtractor with your rules and apply it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.4: Combining Extractors with Pipeline\n",
    "\n",
    "Use ExtractorPipeline to combine multiple extractors for more comprehensive attribute extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create an ExtractorPipeline combining regex and code extractors\n",
    "# pipeline = ExtractorPipeline([regex_extractor, code_extractor])\n",
    "\n",
    "# Apply the pipeline\n",
    "# TODO: Use pipeline.extract() to process the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.5: Evaluation\n",
    "\n",
    "Now let's evaluate our extraction results using precision, recall, and F1 metrics adapted from the SelfRefinement4ExtractGPT evaluation framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for evaluation\n",
    "# TODO: Get the list of attribute columns that exist in both predicted and target data\n",
    "# attribute_columns = [...]\n",
    "\n",
    "# Run evaluation\n",
    "# TODO: Use evaluate_predictions() to compare your results with targets\n",
    "# results = evaluate_predictions(predictions_df, targets_df, attribute_columns)\n",
    "\n",
    "# Print results\n",
    "# TODO: Use print_evaluation_results() to display the evaluation metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.6: Analysis and Improvement\n",
    "\n",
    "Analyze your results and suggest improvements to the extraction rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Analyze the results\n",
    "# 1. Which attributes had the best/worst performance?\n",
    "# 2. Look at some examples where extraction failed\n",
    "# 3. What patterns could you add to improve performance?\n",
    "\n",
    "# Example: Find cases where brand extraction failed\n",
    "# TODO: Filter and examine failed extractions to understand patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus Task 3.7: LLM-Based Extraction (Optional)\n",
    "\n",
    "If you have access to an API key for OpenAI or another LLM provider, try using the LLMExtractor for more sophisticated extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: LLM-based extraction\n",
    "# This requires API keys and is optional\n",
    "\n",
    "try:\n",
    "    from PyDI.informationextraction import LLMExtractor\n",
    "    from langchain_openai import ChatOpenAI\n",
    "    from pydantic import BaseModel\n",
    "    from typing import Optional\n",
    "    \n",
    "    class Product(BaseModel):\n",
    "        brand: Optional[str] = None\n",
    "        gender: Optional[str] = None\n",
    "        model_name: Optional[str] = None\n",
    "        shoe_type: Optional[str] = None\n",
    "        color: Optional[str] = None\n",
    "        size: Optional[str] = None\n",
    "    \n",
    "    # TODO: If you have an OpenAI API key, uncomment and configure:\n",
    "    # chat = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "    # llm_extractor = LLMExtractor(\n",
    "    #     chat_model=chat,\n",
    "    #     schema=Product,\n",
    "    #     source_column=\"input\",\n",
    "    #     system_prompt=\"Extract product attributes from the description as JSON.\"\n",
    "    # )\n",
    "    # llm_results = llm_extractor.extract(targets_df.head(10))  # Test on small sample\n",
    "    \n",
    "    print(\"LLM extraction would require API keys - skipping for now\")\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"LLM extraction dependencies not available - install with: pip install langchain-openai\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
