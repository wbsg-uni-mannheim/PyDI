{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyDI Data Integration Tutorial\n",
    "\n",
    "This tutorial demonstrates comprehensive data integration using PyDI. We'll work with movie datasets to showcase the complete data integration pipeline.\n",
    "\n",
    "### What You'll Learn\n",
    "\n",
    "1. **Data Loading & Profiling**: Load and analyze movie datasets with provenance tracking\n",
    "2. **Identity Resolution**: \n",
    "   - Advanced blocking strategies (Standard, Sorted Neighbourhood, Token-based, Embedding-based)\n",
    "   - Multi-attribute similarity matching with custom comparators\n",
    "   - Machine learning-based entity matching\n",
    "3. **Data Fusion**: \n",
    "   - Conflict resolution with custom fusion rules\n",
    "   - Quality assessment against gold standards\n",
    "   - Provenance tracking and trust management\n",
    "4. **Advanced Techniques**: \n",
    "   - Semantic similarity with embeddings\n",
    "   - Performance optimization and scalability\n",
    "   - End-to-end pipeline integration\n",
    "\n",
    "### Datasets\n",
    "\n",
    "We'll use three movie datasets:\n",
    "- **Academy Awards**: Movies with Oscar information (4,592 records)\n",
    "- **Actors**: Movies with actor details (149 records) \n",
    "- **Golden Globes**: Movies with Golden Globe awards (2,286 records)\n",
    "\n",
    "These datasets contain overlapping movie information but with different attributes, data quality issues, and conflicting values - perfect for demonstrating real-world data integration challenges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the PyDI package if not already installed\n",
    "# First navigate to the root directory of the repository in your terminal, then run:\n",
    "# !pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† Embedding models available\n",
      "PyDI Tutorial\n",
      "Repository root: c:\\Users\\Ralph\\dev\\pydi\n",
      "Output directory: c:\\Users\\Ralph\\dev\\pydi\\output\\tutorial\n",
      "All systems ready! üöÄ\n"
     ]
    }
   ],
   "source": [
    "# Core Python libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import logging\n",
    "import time\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# PyDI imports for data loading and profiling\n",
    "from PyDI.io import load_xml, load_csv\n",
    "from PyDI.profiling import DataProfiler\n",
    "\n",
    "# PyDI imports for entity matching\n",
    "from PyDI.entitymatching import (\n",
    "    # Blocking strategies\n",
    "    NoBlocking, StandardBlocking, SortedNeighbourhood, \n",
    "    TokenBlocking, EmbeddingBlocking,\n",
    "    # Matchers\n",
    "    RuleBasedMatcher, MLBasedMatcher,\n",
    "    # Comparators\n",
    "    StringComparator, DateComparator, NumericComparator,\n",
    "    # Evaluation - NEW: Separate methods for blocking and matching evaluation\n",
    "    EntityMatchingEvaluator,\n",
    "    # Utilities\n",
    "    ensure_record_ids\n",
    ")\n",
    "\n",
    "# PyDI imports for data fusion\n",
    "from PyDI.fusion import (\n",
    "    DataFusionEngine, DataFusionStrategy, DataFusionEvaluator,\n",
    "    # Fusion rules\n",
    "    longest_string, shortest_string, most_recent, earliest,\n",
    "    average, median, maximum, minimum, most_complete,\n",
    "    union, intersection, voting,\n",
    "    # Convenient aliases\n",
    "    LONGEST, SHORTEST, LATEST, EARLIEST, AVG, MAX, MIN, VOTE, UNION,\n",
    "    # Analysis and reporting\n",
    "    FusionReport, FusionQualityMetrics, ProvenanceTracker,\n",
    "    build_record_groups_from_correspondences,\n",
    ")\n",
    "\n",
    "# Setup paths\n",
    "def get_repo_root():\n",
    "    \"\"\"Get repository root directory.\"\"\"\n",
    "    current = Path.cwd()\n",
    "    while current != current.parent:\n",
    "        if (current / 'pyproject.toml').exists():\n",
    "            return current\n",
    "        current = current.parent\n",
    "    return Path.cwd()\n",
    "\n",
    "ROOT = get_repo_root()\n",
    "OUTPUT_DIR = ROOT / \"output\" / \"tutorial\"\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Check if embeddings are available\n",
    "try:\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    use_embeddings = True\n",
    "    print(\"üß† Embedding models available\")\n",
    "except ImportError:\n",
    "    use_embeddings = False\n",
    "    print(\"‚ö†Ô∏è  Embedding models not available (install sentence-transformers)\")\n",
    "\n",
    "print(f\"PyDI Tutorial\")\n",
    "print(f\"Repository root: {ROOT}\")\n",
    "print(f\"Output directory: {OUTPUT_DIR}\")\n",
    "print(f\"All systems ready! üöÄ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Data Loading and Profiling\n",
    "\n",
    "PyDI provides provenance-aware data loading that automatically tracks dataset metadata and adds unique identifiers. Let's load our movie datasets and understand their characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Loading Movie Datasets ===\n",
      "PyDI provides provenance-aware loading with automatic ID generation.\n",
      "\n",
      "Academy Awards:\n",
      "  Records: 4,592\n",
      "  Attributes: 7\n",
      "  Columns: ['_id', 'id', 'title', 'actor_name', 'date', 'director_name', 'oscar']\n",
      "  Dataset name: academy_awards\n",
      "\n",
      "Actors:\n",
      "  Records: 149\n",
      "  Attributes: 7\n",
      "  Columns: ['_id', 'id', 'title', 'actor_name', 'actors_actor_birthday', 'actors_actor_birthplace', 'date']\n",
      "  Dataset name: actors\n",
      "\n",
      "Golden Globes:\n",
      "  Records: 2,286\n",
      "  Attributes: 7\n",
      "  Columns: ['_id', 'id', 'title', 'actor_name', 'date', 'director_name', 'globe']\n",
      "  Dataset name: golden_globes\n",
      "\n",
      "Total records across all datasets: 7,027\n"
     ]
    }
   ],
   "source": [
    "# Define dataset paths\n",
    "DATA_DIR = ROOT / \"input\" / \"movies\"\n",
    "\n",
    "print(\"=== Loading Movie Datasets ===\")\n",
    "print(\"PyDI provides provenance-aware loading with automatic ID generation.\\n\")\n",
    "\n",
    "# Load Academy Awards dataset\n",
    "academy_awards = load_xml(\n",
    "    DATA_DIR / \"entitymatching\" / \"data\" / \"academy_awards.xml\",\n",
    "    name=\"academy_awards\",\n",
    "    record_tag=\"movie\",\n",
    "    add_index=True,\n",
    "    index_column_name=\"_id\"\n",
    ")\n",
    "\n",
    "# Load Actors dataset  \n",
    "actors = load_xml(\n",
    "    DATA_DIR / \"entitymatching\" / \"data\" / \"actors.xml\",\n",
    "    name=\"actors\", \n",
    "    record_tag=\"movie\",\n",
    "    add_index=True,\n",
    "    index_column_name=\"_id\"\n",
    ")\n",
    "\n",
    "# Load Golden Globes dataset\n",
    "golden_globes = load_xml(\n",
    "    DATA_DIR / \"fusion\" / \"data\" / \"golden_globes.xml\",\n",
    "    name=\"golden_globes\",\n",
    "    record_tag=\"movie\", \n",
    "    add_index=True,\n",
    "    index_column_name=\"_id\"\n",
    ")\n",
    "\n",
    "# Display basic information\n",
    "datasets = [academy_awards, actors, golden_globes]\n",
    "names = [\"Academy Awards\", \"Actors\", \"Golden Globes\"]\n",
    "\n",
    "for df, name in zip(datasets, names):\n",
    "    print(f\"{name}:\")\n",
    "    print(f\"  Records: {len(df):,}\")\n",
    "    print(f\"  Attributes: {len(df.columns)}\")\n",
    "    print(f\"  Columns: {list(df.columns)}\")\n",
    "    print(f\"  Dataset name: {df.attrs.get('dataset_name', 'unknown')}\")\n",
    "    print()\n",
    "\n",
    "total_records = sum(len(df) for df in datasets)\n",
    "print(f\"Total records across all datasets: {total_records:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Dataset Previews ===\n",
      "\n",
      "üìΩÔ∏è Academy Awards Dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>actor_name</th>\n",
       "      <th>date</th>\n",
       "      <th>director_name</th>\n",
       "      <th>oscar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>academy_awards-0000</td>\n",
       "      <td>academy_awards_1</td>\n",
       "      <td>Biutiful</td>\n",
       "      <td>Javier Bardem</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>academy_awards-0001</td>\n",
       "      <td>academy_awards_2</td>\n",
       "      <td>True Grit</td>\n",
       "      <td>Jeff Bridges</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>Joel Coen</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>academy_awards-0002</td>\n",
       "      <td>academy_awards_2</td>\n",
       "      <td>True Grit</td>\n",
       "      <td>Jeff Bridges</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>Ethan Coen</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   _id                id      title     actor_name  \\\n",
       "0  academy_awards-0000  academy_awards_1   Biutiful  Javier Bardem   \n",
       "1  academy_awards-0001  academy_awards_2  True Grit   Jeff Bridges   \n",
       "2  academy_awards-0002  academy_awards_2  True Grit   Jeff Bridges   \n",
       "\n",
       "         date director_name oscar  \n",
       "0  2010-01-01           NaN   NaN  \n",
       "1  2010-01-01     Joel Coen   NaN  \n",
       "2  2010-01-01    Ethan Coen   NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üé≠ Actors Dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>actor_name</th>\n",
       "      <th>actors_actor_birthday</th>\n",
       "      <th>actors_actor_birthplace</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>actors-0000</td>\n",
       "      <td>actors_1</td>\n",
       "      <td>7th Heaven</td>\n",
       "      <td>Janet Gaynor</td>\n",
       "      <td>1906-01-01</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>1929-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>actors-0001</td>\n",
       "      <td>actors_2</td>\n",
       "      <td>Coquette</td>\n",
       "      <td>Mary Pickford</td>\n",
       "      <td>1892-01-01</td>\n",
       "      <td>Canada</td>\n",
       "      <td>1930-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>actors-0002</td>\n",
       "      <td>actors_3</td>\n",
       "      <td>The Divorcee</td>\n",
       "      <td>Norma Shearer</td>\n",
       "      <td>1902-01-01</td>\n",
       "      <td>Canada</td>\n",
       "      <td>1931-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           _id        id         title     actor_name actors_actor_birthday  \\\n",
       "0  actors-0000  actors_1    7th Heaven   Janet Gaynor            1906-01-01   \n",
       "1  actors-0001  actors_2      Coquette  Mary Pickford            1892-01-01   \n",
       "2  actors-0002  actors_3  The Divorcee  Norma Shearer            1902-01-01   \n",
       "\n",
       "  actors_actor_birthplace        date  \n",
       "0            Pennsylvania  1929-01-01  \n",
       "1                  Canada  1930-01-01  \n",
       "2                  Canada  1931-01-01  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üèÜ Golden Globes Dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>actor_name</th>\n",
       "      <th>date</th>\n",
       "      <th>director_name</th>\n",
       "      <th>globe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>golden_globes-0000</td>\n",
       "      <td>golden_globes_1</td>\n",
       "      <td>Frankie and Alice</td>\n",
       "      <td>Halle Berry</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>golden_globes-0001</td>\n",
       "      <td>golden_globes_2</td>\n",
       "      <td>Rabbit Hole</td>\n",
       "      <td>Nicole Kidman</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>golden_globes-0002</td>\n",
       "      <td>golden_globes_3</td>\n",
       "      <td>Winter's Bone</td>\n",
       "      <td>Jennifer Lawrence</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  _id               id              title         actor_name  \\\n",
       "0  golden_globes-0000  golden_globes_1  Frankie and Alice        Halle Berry   \n",
       "1  golden_globes-0001  golden_globes_2        Rabbit Hole      Nicole Kidman   \n",
       "2  golden_globes-0002  golden_globes_3      Winter's Bone  Jennifer Lawrence   \n",
       "\n",
       "         date director_name globe  \n",
       "0  2011-01-01           NaN   NaN  \n",
       "1  2011-01-01           NaN   NaN  \n",
       "2  2011-01-01           NaN   NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Preview the data structure\n",
    "print(\"=== Dataset Previews ===\")\n",
    "\n",
    "print(\"\\nüìΩÔ∏è Academy Awards Dataset:\")\n",
    "display(academy_awards.head(3))\n",
    "\n",
    "print(\"\\nüé≠ Actors Dataset:\")\n",
    "display(actors.head(3))\n",
    "\n",
    "print(\"\\nüèÜ Golden Globes Dataset:\")\n",
    "display(golden_globes.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Quality Analysis\n",
    "\n",
    "Let's use PyDI's profiling capabilities to understand our data quality and identify the best attributes for matching."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Dataset Summary\n",
    "\n",
    "First, let's use the DataProfiler's `summary()` method to get basic statistics for each dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Dataset Summary Statistics ===\n",
      "\n",
      "academy_awards:\n",
      "  Rows: 4,592\n",
      "  Columns: 7\n",
      "  Total nulls: 11,036\n",
      "  Null percentage: 34.3%\n",
      "  Null counts per column:\n",
      "    title: 12 (0.3%)\n",
      "    actor_name: 3,535 (77.0%)\n",
      "    director_name: 4,172 (90.9%)\n",
      "    oscar: 3,317 (72.2%)\n",
      "\n",
      "actors:\n",
      "  Rows: 149\n",
      "  Columns: 7\n",
      "  Total nulls: 0\n",
      "  Null percentage: 0.0%\n",
      "\n",
      "golden_globes:\n",
      "  Rows: 2,286\n",
      "  Columns: 7\n",
      "  Total nulls: 3,681\n",
      "  Null percentage: 23.0%\n",
      "  Null counts per column:\n",
      "    actor_name: 54 (2.4%)\n",
      "    director_name: 1,966 (86.0%)\n",
      "    globe: 1,661 (72.7%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'rows': 2286,\n",
       " 'columns': 7,\n",
       " 'nulls_total': 3681,\n",
       " 'nulls_per_column': {'_id': 0,\n",
       "  'id': 0,\n",
       "  'title': 0,\n",
       "  'actor_name': 54,\n",
       "  'date': 0,\n",
       "  'director_name': 1966,\n",
       "  'globe': 1661},\n",
       " 'dtypes': {'_id': 'string',\n",
       "  'id': 'object',\n",
       "  'title': 'object',\n",
       "  'actor_name': 'object',\n",
       "  'date': 'object',\n",
       "  'director_name': 'object',\n",
       "  'globe': 'object'}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize the DataProfiler\n",
    "profiler = DataProfiler()\n",
    "\n",
    "print(\"=== Dataset Summary Statistics ===\\n\")\n",
    "\n",
    "for df, name in zip(datasets, names):\n",
    "    profile = profiler.summary(df) # automatically prints some statistics and returns object containing stats\n",
    "\n",
    "display(profile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attribute Coverage Analysis\n",
    "\n",
    "Next, let's use the `analyze_coverage()` method to understand how attributes overlap across datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Attribute Coverage Analysis ===\n",
      "\n",
      "üìä Attribute coverage across datasets:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attribute</th>\n",
       "      <th>academy_awards_count</th>\n",
       "      <th>academy_awards_pct</th>\n",
       "      <th>academy_awards_coverage</th>\n",
       "      <th>academy_awards_samples</th>\n",
       "      <th>actors_count</th>\n",
       "      <th>actors_pct</th>\n",
       "      <th>actors_coverage</th>\n",
       "      <th>actors_samples</th>\n",
       "      <th>golden_globes_count</th>\n",
       "      <th>golden_globes_pct</th>\n",
       "      <th>golden_globes_coverage</th>\n",
       "      <th>golden_globes_samples</th>\n",
       "      <th>avg_coverage</th>\n",
       "      <th>max_coverage</th>\n",
       "      <th>datasets_with_attribute</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>_id</td>\n",
       "      <td>4592/4592</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>['academy_awards-0000', 'academy_awards-0001',...</td>\n",
       "      <td>149/149</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['actors-0000', 'actors-0001', 'actors-0002']</td>\n",
       "      <td>2286/2286</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>['golden_globes-0000', 'golden_globes-0001', '...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>actor_name</td>\n",
       "      <td>1057/4592</td>\n",
       "      <td>23.0%</td>\n",
       "      <td>0.230183</td>\n",
       "      <td>['Javier Bardem', 'Jeff Bridges', 'Jeff Bridges']</td>\n",
       "      <td>149/149</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['Janet Gaynor', 'Mary Pickford', 'Norma Shear...</td>\n",
       "      <td>2232/2286</td>\n",
       "      <td>97.6%</td>\n",
       "      <td>0.976378</td>\n",
       "      <td>['Halle Berry', 'Nicole Kidman', 'Jennifer Law...</td>\n",
       "      <td>0.735520</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>actors_actor_birthday</td>\n",
       "      <td>0/0</td>\n",
       "      <td>0%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>N/A</td>\n",
       "      <td>149/149</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['1906-01-01', '1892-01-01', '1902-01-01']</td>\n",
       "      <td>0/0</td>\n",
       "      <td>0%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>actors_actor_birthplace</td>\n",
       "      <td>0/0</td>\n",
       "      <td>0%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>N/A</td>\n",
       "      <td>149/149</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['Pennsylvania', 'Canada', 'Canada']</td>\n",
       "      <td>0/0</td>\n",
       "      <td>0%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>date</td>\n",
       "      <td>4592/4592</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>['2010-01-01', '2010-01-01', '2010-01-01']</td>\n",
       "      <td>149/149</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['1929-01-01', '1930-01-01', '1931-01-01']</td>\n",
       "      <td>2286/2286</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>['2011-01-01', '2011-01-01', '2011-01-01']</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>director_name</td>\n",
       "      <td>420/4592</td>\n",
       "      <td>9.1%</td>\n",
       "      <td>0.091463</td>\n",
       "      <td>['Joel Coen', 'Ethan Coen', 'David Fincher']</td>\n",
       "      <td>0/0</td>\n",
       "      <td>0%</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N/A</td>\n",
       "      <td>320/2286</td>\n",
       "      <td>14.0%</td>\n",
       "      <td>0.139983</td>\n",
       "      <td>['Darren Aronofsky', 'David Fincher', 'Tom Hoo...</td>\n",
       "      <td>0.077149</td>\n",
       "      <td>0.139983</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>globe</td>\n",
       "      <td>0/0</td>\n",
       "      <td>0%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0/0</td>\n",
       "      <td>0%</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N/A</td>\n",
       "      <td>625/2286</td>\n",
       "      <td>27.3%</td>\n",
       "      <td>0.273403</td>\n",
       "      <td>['yes', 'yes', 'yes']</td>\n",
       "      <td>0.091134</td>\n",
       "      <td>0.273403</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>id</td>\n",
       "      <td>4592/4592</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>['academy_awards_1', 'academy_awards_2', 'acad...</td>\n",
       "      <td>149/149</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['actors_1', 'actors_2', 'actors_3']</td>\n",
       "      <td>2286/2286</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>['golden_globes_1', 'golden_globes_2', 'golden...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>oscar</td>\n",
       "      <td>1275/4592</td>\n",
       "      <td>27.8%</td>\n",
       "      <td>0.277657</td>\n",
       "      <td>['yes', 'yes', 'yes']</td>\n",
       "      <td>0/0</td>\n",
       "      <td>0%</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0/0</td>\n",
       "      <td>0%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0.092552</td>\n",
       "      <td>0.277657</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>title</td>\n",
       "      <td>4580/4592</td>\n",
       "      <td>99.7%</td>\n",
       "      <td>0.997387</td>\n",
       "      <td>['Biutiful', 'True Grit', 'True Grit']</td>\n",
       "      <td>149/149</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['7th Heaven', 'Coquette', 'The Divorcee']</td>\n",
       "      <td>2286/2286</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>['Frankie and Alice', 'Rabbit Hole', \"Winter's...</td>\n",
       "      <td>0.999129</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 attribute academy_awards_count academy_awards_pct  \\\n",
       "0                      _id            4592/4592             100.0%   \n",
       "1               actor_name            1057/4592              23.0%   \n",
       "2    actors_actor_birthday                  0/0                 0%   \n",
       "3  actors_actor_birthplace                  0/0                 0%   \n",
       "4                     date            4592/4592             100.0%   \n",
       "5            director_name             420/4592               9.1%   \n",
       "6                    globe                  0/0                 0%   \n",
       "7                       id            4592/4592             100.0%   \n",
       "8                    oscar            1275/4592              27.8%   \n",
       "9                    title            4580/4592              99.7%   \n",
       "\n",
       "   academy_awards_coverage                             academy_awards_samples  \\\n",
       "0                 1.000000  ['academy_awards-0000', 'academy_awards-0001',...   \n",
       "1                 0.230183  ['Javier Bardem', 'Jeff Bridges', 'Jeff Bridges']   \n",
       "2                 0.000000                                                N/A   \n",
       "3                 0.000000                                                N/A   \n",
       "4                 1.000000         ['2010-01-01', '2010-01-01', '2010-01-01']   \n",
       "5                 0.091463       ['Joel Coen', 'Ethan Coen', 'David Fincher']   \n",
       "6                 0.000000                                                N/A   \n",
       "7                 1.000000  ['academy_awards_1', 'academy_awards_2', 'acad...   \n",
       "8                 0.277657                              ['yes', 'yes', 'yes']   \n",
       "9                 0.997387             ['Biutiful', 'True Grit', 'True Grit']   \n",
       "\n",
       "  actors_count actors_pct  actors_coverage  \\\n",
       "0      149/149     100.0%              1.0   \n",
       "1      149/149     100.0%              1.0   \n",
       "2      149/149     100.0%              1.0   \n",
       "3      149/149     100.0%              1.0   \n",
       "4      149/149     100.0%              1.0   \n",
       "5          0/0         0%              0.0   \n",
       "6          0/0         0%              0.0   \n",
       "7      149/149     100.0%              1.0   \n",
       "8          0/0         0%              0.0   \n",
       "9      149/149     100.0%              1.0   \n",
       "\n",
       "                                      actors_samples golden_globes_count  \\\n",
       "0      ['actors-0000', 'actors-0001', 'actors-0002']           2286/2286   \n",
       "1  ['Janet Gaynor', 'Mary Pickford', 'Norma Shear...           2232/2286   \n",
       "2         ['1906-01-01', '1892-01-01', '1902-01-01']                 0/0   \n",
       "3               ['Pennsylvania', 'Canada', 'Canada']                 0/0   \n",
       "4         ['1929-01-01', '1930-01-01', '1931-01-01']           2286/2286   \n",
       "5                                                N/A            320/2286   \n",
       "6                                                N/A            625/2286   \n",
       "7               ['actors_1', 'actors_2', 'actors_3']           2286/2286   \n",
       "8                                                N/A                 0/0   \n",
       "9         ['7th Heaven', 'Coquette', 'The Divorcee']           2286/2286   \n",
       "\n",
       "  golden_globes_pct  golden_globes_coverage  \\\n",
       "0            100.0%                1.000000   \n",
       "1             97.6%                0.976378   \n",
       "2                0%                0.000000   \n",
       "3                0%                0.000000   \n",
       "4            100.0%                1.000000   \n",
       "5             14.0%                0.139983   \n",
       "6             27.3%                0.273403   \n",
       "7            100.0%                1.000000   \n",
       "8                0%                0.000000   \n",
       "9            100.0%                1.000000   \n",
       "\n",
       "                               golden_globes_samples  avg_coverage  \\\n",
       "0  ['golden_globes-0000', 'golden_globes-0001', '...      1.000000   \n",
       "1  ['Halle Berry', 'Nicole Kidman', 'Jennifer Law...      0.735520   \n",
       "2                                                N/A      0.333333   \n",
       "3                                                N/A      0.333333   \n",
       "4         ['2011-01-01', '2011-01-01', '2011-01-01']      1.000000   \n",
       "5  ['Darren Aronofsky', 'David Fincher', 'Tom Hoo...      0.077149   \n",
       "6                              ['yes', 'yes', 'yes']      0.091134   \n",
       "7  ['golden_globes_1', 'golden_globes_2', 'golden...      1.000000   \n",
       "8                                                N/A      0.092552   \n",
       "9  ['Frankie and Alice', 'Rabbit Hole', \"Winter's...      0.999129   \n",
       "\n",
       "   max_coverage  datasets_with_attribute  \n",
       "0      1.000000                        3  \n",
       "1      1.000000                        3  \n",
       "2      1.000000                        1  \n",
       "3      1.000000                        1  \n",
       "4      1.000000                        3  \n",
       "5      0.139983                        2  \n",
       "6      0.273403                        1  \n",
       "7      1.000000                        3  \n",
       "8      0.277657                        1  \n",
       "9      1.000000                        3  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîó Attributes suitable for entity matching:\n",
      "Available in 2+ datasets: ['_id', 'actor_name', 'date', 'director_name', 'id', 'title']\n"
     ]
    }
   ],
   "source": [
    "# Analyze attribute coverage across all three datasets\n",
    "print(\"=== Attribute Coverage Analysis ===\\n\")\n",
    "\n",
    "coverage = profiler.analyze_coverage(\n",
    "    datasets=datasets,\n",
    "    include_samples=True,\n",
    "    sample_count=3  # Show 3 sample values per attribute\n",
    ")\n",
    "\n",
    "print(\"üìä Attribute coverage across datasets:\")\n",
    "display(coverage)\n",
    "\n",
    "# Identify attributes suitable for entity matching\n",
    "print(\"\\nüîó Attributes suitable for entity matching:\")\n",
    "matching_attrs = coverage[coverage['datasets_with_attribute'] >= 2]['attribute'].tolist()\n",
    "print(f\"Available in 2+ datasets: {matching_attrs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detailed Data Profiling\n",
    "\n",
    "Now let's generate comprehensive HTML profiles for each dataset using the `profile()` method. These reports provide in-depth statistical analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Generating Detailed Dataset Profiles ===\n",
      "\n",
      "üìä Profiling Academy Awards...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <ins><a href=\"https://ydata.ai/register\">Upgrade to ydata-sdk</a></ins>\n",
       "                <p>\n",
       "                    Improve your data and profiling with ydata-sdk, featuring data quality scoring, redundancy detection, outlier identification, text validation, and synthetic data generation.\n",
       "                </p>\n",
       "            </div>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef1237f5449d44a6a90ea45238113578",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 101.45it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de15e4c3a0a84d68ae0981a0a6df9ef0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate report structure:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35c248eac38a468a8bdfb7cb68d2bb02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Render HTML:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d0d01d5c8d34e6ab592169e85bfcf25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Export report to file:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úÖ Profile saved: c:\\Users\\Ralph\\dev\\pydi\\output\\tutorial\\data_profiles\\academy_awards_profile.html\n",
      "üìä Profiling Actors...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c31a04151cd14d0db8f937392efa72db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 225.81it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecb7bb51acc944b8a66bb11d15cd8eae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate report structure:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbd44516d0f348e1b3ae3e411a60b906",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Render HTML:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1cb0dccf37f4f5fa36ba5d4b020ee7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Export report to file:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úÖ Profile saved: c:\\Users\\Ralph\\dev\\pydi\\output\\tutorial\\data_profiles\\actors_profile.html\n",
      "üìä Profiling Golden Globes...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f16d7955bd14f6bb5093ecb9efd92a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 148.94it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e9a2344f0e44a69ad67ea3a4868b877",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate report structure:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f8ecf7cd11d4b6cbc6264c174875821",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Render HTML:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2df61d4501a945788ad683c49bcafb61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Export report to file:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úÖ Profile saved: c:\\Users\\Ralph\\dev\\pydi\\output\\tutorial\\data_profiles\\golden_globes_profile.html\n",
      "\n",
      "üéØ Generated 3 detailed HTML reports\n",
      "üìÅ Location: c:\\Users\\Ralph\\dev\\pydi\\output\\tutorial\\data_profiles\n",
      "\n",
      "üí° Open these HTML files in your browser for interactive exploration:\n",
      "  ‚Ä¢ academy_awards_profile.html\n",
      "  ‚Ä¢ actors_profile.html\n",
      "  ‚Ä¢ golden_globes_profile.html\n"
     ]
    }
   ],
   "source": [
    "# Generate detailed HTML profiles for each dataset\n",
    "print(\"=== Generating Detailed Dataset Profiles ===\\n\")\n",
    "\n",
    "profile_dir = OUTPUT_DIR / \"data_profiles\"\n",
    "profile_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "profile_paths = []\n",
    "\n",
    "for df, name in zip(datasets, names):\n",
    "    print(f\"üìä Profiling {name}...\")\n",
    "    \n",
    "    profile_path = profiler.profile(df, str(profile_dir))\n",
    "    profile_paths.append(profile_path)\n",
    "    print(f\"  ‚úÖ Profile saved: {profile_path}\")\n",
    "\n",
    "print(f\"\\nüéØ Generated {len(profile_paths)} detailed HTML reports\")\n",
    "print(f\"üìÅ Location: {profile_dir}\")\n",
    "print(\"\\nüí° Open these HTML files in your browser for interactive exploration:\")\n",
    "for path in profile_paths:\n",
    "    print(f\"  ‚Ä¢ {Path(path).name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Comparison\n",
    "\n",
    "Finally, let's use the `compare()` method to create a comparison report between two datasets, highlighting differences and similarities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Dataset Comparison Analysis ===\n",
      "\n",
      "üîç Comparing Academy Awards vs Golden Globes datasets...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dd1300df3564012bdd55fa981ee585c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "                                             |          | [  0%]   00:00 -> (? left)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report c:\\Users\\Ralph\\dev\\pydi\\output\\tutorial\\comparisons\\academy_awards_vs_golden_globes_compare.html was generated! NOTEBOOK/COLAB USERS: the web browser MAY not pop up, regardless, the report IS saved in your notebook/colab files.\n",
      "‚úÖ Comparison report saved: c:\\Users\\Ralph\\dev\\pydi\\output\\tutorial\\comparisons\\academy_awards_vs_golden_globes_compare.html\n",
      "\n",
      "üéØ Interactive comparison report generated\n",
      "üìÅ Location: c:\\Users\\Ralph\\dev\\pydi\\output\\tutorial\\comparisons\\academy_awards_vs_golden_globes_compare.html\n",
      "üí° Open in browser to explore:\n",
      "  ‚Ä¢ Attribute distributions\n",
      "  ‚Ä¢ Value frequency comparisons\n",
      "  ‚Ä¢ Missing data patterns\n",
      "  ‚Ä¢ Statistical differences\n"
     ]
    }
   ],
   "source": [
    "# Compare Academy Awards vs Golden Globes datasets\n",
    "print(\"=== Dataset Comparison Analysis ===\\n\")\n",
    "\n",
    "compare_dir = OUTPUT_DIR / \"comparisons\"\n",
    "compare_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"üîç Comparing Academy Awards vs Golden Globes datasets...\")\n",
    "\n",
    "# Fix the comparison call by using Sweetviz directly with correct format\n",
    "import sweetviz as sv\n",
    "report = sv.compare((academy_awards, \"Academy Awards\"), (golden_globes, \"Golden Globes\"))\n",
    "comparison_path = str(compare_dir / \"academy_awards_vs_golden_globes_compare.html\")\n",
    "report.show_html(comparison_path)\n",
    "print(f\"‚úÖ Comparison report saved: {comparison_path}\")\n",
    "\n",
    "print(f\"\\nüéØ Interactive comparison report generated\")\n",
    "print(f\"üìÅ Location: {comparison_path}\")\n",
    "print(\"üí° Open in browser to explore:\")\n",
    "print(\"  ‚Ä¢ Attribute distributions\")\n",
    "print(\"  ‚Ä¢ Value frequency comparisons\") \n",
    "print(\"  ‚Ä¢ Missing data patterns\")\n",
    "print(\"  ‚Ä¢ Statistical differences\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Identity Resolution (Entity Matching)\n",
    "\n",
    "Identity Resolution is the process of identifying records that refer to the same real-world entity. PyDI provides comprehensive blocking and matching capabilities.\n",
    "\n",
    "### Step 1: Blocking Strategies\n",
    "\n",
    "Blocking reduces the number of comparisons from O(n¬≤) to a manageable subset. Let's explore different blocking strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Identity Resolution: Blocking Strategies ===\n",
      "Blocking reduces comparisons from full Cartesian product to manageable candidates.\n",
      "\n",
      "Without blocking: 684,208 comparisons required\n",
      "\n",
      "üéØ Goal: Reduce comparisons while maintaining high recall\n",
      "\n",
      "Testing different blocking strategies...\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Identity Resolution: Blocking Strategies ===\")\n",
    "print(\"Blocking reduces comparisons from full Cartesian product to manageable candidates.\\n\")\n",
    "\n",
    "# We'll focus on Academy Awards vs Actors for entity matching\n",
    "left_df = academy_awards\n",
    "right_df = actors\n",
    "\n",
    "max_pairs = len(left_df) * len(right_df)\n",
    "print(f\"Without blocking: {max_pairs:,} comparisons required\")\n",
    "print(\"\\nüéØ Goal: Reduce comparisons while maintaining high recall\\n\")\n",
    "\n",
    "# Ensure datasets have proper IDs for matching\n",
    "left_df = ensure_record_ids(left_df)\n",
    "right_df = ensure_record_ids(right_df)\n",
    "\n",
    "blocking_results = []\n",
    "\n",
    "print(\"Testing different blocking strategies...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1Ô∏è‚É£ Standard Blocking (First 3 Characters of Title)\n",
      "  Generated: 34,457 candidates\n",
      "  Reduction: 95.0% (0.0504 ratio)\n",
      "  Time: 0.064 seconds\n"
     ]
    }
   ],
   "source": [
    "# 1. Standard Blocking - First 3 characters of title\n",
    "print(\"\\n1Ô∏è‚É£ Standard Blocking (First 3 Characters of Title)\")\n",
    "\n",
    "# Add title_prefix directly to the original dataframes\n",
    "academy_awards['title_prefix'] = academy_awards['title'].astype(str).str[:3]\n",
    "actors['title_prefix'] = actors['title'].astype(str).str[:3]\n",
    "\n",
    "standard_blocker = StandardBlocking(\n",
    "    academy_awards, actors,\n",
    "    on=['title_prefix'],  # Block on first 3 characters of title\n",
    "    batch_size=1000\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "standard_candidates = []\n",
    "for batch in standard_blocker:\n",
    "    standard_candidates.extend(batch.to_dict('records'))\n",
    "    \n",
    "standard_time = time.time() - start_time\n",
    "reduction_ratio = len(standard_candidates) / max_pairs\n",
    "\n",
    "print(f\"  Generated: {len(standard_candidates):,} candidates\")\n",
    "print(f\"  Reduction: {(1-reduction_ratio)*100:.1f}% ({reduction_ratio:.4f} ratio)\")\n",
    "print(f\"  Time: {standard_time:.3f} seconds\")\n",
    "\n",
    "blocking_results.append({\n",
    "    'strategy': 'StandardBlocking',\n",
    "    'candidates': len(standard_candidates),\n",
    "    'reduction_ratio': reduction_ratio,\n",
    "    'time_seconds': standard_time\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2Ô∏è‚É£ Sorted Neighbourhood Blocking (Title-based, Window=5)\n",
      "  Generated: 2,906 candidates\n",
      "  Reduction: 99.6% (0.0042 ratio)\n",
      "  Time: 0.007 seconds\n"
     ]
    }
   ],
   "source": [
    "# 2. Sorted Neighbourhood - Sequential similarity\n",
    "print(\"\\n2Ô∏è‚É£ Sorted Neighbourhood Blocking (Title-based, Window=5)\")\n",
    "\n",
    "sn_blocker = SortedNeighbourhood(\n",
    "    academy_awards, actors,\n",
    "    key='title',  # Sort by title\n",
    "    window=10,     # Compare with 5 neighbors\n",
    "    batch_size=1000\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "sn_candidates = []\n",
    "for batch in sn_blocker:\n",
    "    sn_candidates.extend(batch.to_dict('records'))\n",
    "    \n",
    "sn_time = time.time() - start_time\n",
    "reduction_ratio = len(sn_candidates) / max_pairs\n",
    "\n",
    "print(f\"  Generated: {len(sn_candidates):,} candidates\")\n",
    "print(f\"  Reduction: {(1-reduction_ratio)*100:.1f}% ({reduction_ratio:.4f} ratio)\")\n",
    "print(f\"  Time: {sn_time:.3f} seconds\")\n",
    "\n",
    "blocking_results.append({\n",
    "    'strategy': 'SortedNeighbourhood', \n",
    "    'candidates': len(sn_candidates),\n",
    "    'reduction_ratio': reduction_ratio,\n",
    "    'time_seconds': sn_time\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3Ô∏è‚É£ Token Blocking (Title Tokens, Min Length=2)\n",
      "  Generated: 75,242 candidates\n",
      "  Reduction: 89.0% (0.1100 ratio)\n",
      "  Time: 0.147 seconds\n"
     ]
    }
   ],
   "source": [
    "# 3. Token Blocking - Token-based similarity\n",
    "print(\"\\n3Ô∏è‚É£ Token Blocking (Title Tokens, Min Length=2)\")\n",
    "\n",
    "token_blocker = TokenBlocking(\n",
    "    academy_awards, actors,\n",
    "    column='title',      # Tokenize titles\n",
    "    min_token_len=2,     # Ignore very short tokens\n",
    "    batch_size=1000\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "token_candidates = []\n",
    "batch_count = 0\n",
    "\n",
    "# Token blocking can generate many candidates, so we'll limit processing\n",
    "for batch in token_blocker:\n",
    "    batch_count += 1\n",
    "    token_candidates.extend(batch.to_dict('records'))\n",
    "        \n",
    "token_time = time.time() - start_time\n",
    "reduction_ratio = len(token_candidates) / max_pairs\n",
    "\n",
    "print(f\"  Generated: {len(token_candidates):,} candidates\")\n",
    "print(f\"  Reduction: {(1-reduction_ratio)*100:.1f}% ({reduction_ratio:.4f} ratio)\")\n",
    "print(f\"  Time: {token_time:.3f} seconds\")\n",
    "\n",
    "blocking_results.append({\n",
    "    'strategy': 'TokenBlocking',\n",
    "    'candidates': len(token_candidates),\n",
    "    'reduction_ratio': reduction_ratio, \n",
    "    'time_seconds': token_time\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4Ô∏è‚É£ Embedding Blocking (Semantic Similarity)\n",
      "Using neural embeddings for semantic movie matching...\n",
      "  Generated: 1,030 candidates\n",
      "  Reduction: 99.8% (0.0015 ratio)\n",
      "  Time: 3.393 seconds\n",
      "  üß† Semantic matching can find similar movies with different titles!\n"
     ]
    }
   ],
   "source": [
    "# 4. Embedding Blocking - Semantic similarity (Advanced)\n",
    "print(\"\\n4Ô∏è‚É£ Embedding Blocking (Semantic Similarity)\")\n",
    "print(\"Using neural embeddings for semantic movie matching...\")\n",
    "\n",
    "embedding_blocker = EmbeddingBlocking(\n",
    "    academy_awards, actors,\n",
    "    text_cols=['title'],\n",
    "    model=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    index_backend=\"sklearn\",\n",
    "    top_k=10,          # Top 10 most similar\n",
    "    threshold=0.5,     # Similarity threshold\n",
    "    batch_size=500\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "embedding_candidates = []\n",
    "for batch in embedding_blocker:\n",
    "    embedding_candidates.extend(batch.to_dict('records'))\n",
    "    \n",
    "embedding_time = time.time() - start_time\n",
    "reduction_ratio = len(embedding_candidates) / max_pairs\n",
    "\n",
    "print(f\"  Generated: {len(embedding_candidates):,} candidates\")\n",
    "print(f\"  Reduction: {(1-reduction_ratio)*100:.1f}% ({reduction_ratio:.4f} ratio)\")\n",
    "print(f\"  Time: {embedding_time:.3f} seconds\")\n",
    "print(\"  üß† Semantic matching can find similar movies with different titles!\")\n",
    "\n",
    "blocking_results.append({\n",
    "    'strategy': 'EmbeddingBlocking',\n",
    "    'candidates': len(embedding_candidates),\n",
    "    'reduction_ratio': reduction_ratio,\n",
    "    'time_seconds': embedding_time\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Pair Completeness: 0.979\n",
      "  Pair Quality:      0.001\n",
      "  Reduction Ratio:   0.950\n",
      "  True Matches Found: 46/47\n",
      "\n",
      "üí° Evaluating pair quality only makes sense if the test set contains all possible pairs, which is not the case in this example!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'pair_completeness': 0.9787234042553191,\n",
       " 'pair_quality': 0.0013349972429404766,\n",
       " 'reduction_ratio': 0.9496395832846152,\n",
       " 'total_candidates': 34457,\n",
       " 'total_possible_pairs': 684208,\n",
       " 'true_positives_found': 46,\n",
       " 'total_true_pairs': 47,\n",
       " 'evaluation_timestamp': '2025-09-08T17:45:50.888971'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Showcase EntityMatchingEvaluator.evaluate_blocking utility\n",
    "\n",
    "# Load test set with proper _id format\n",
    "test_gt = load_csv(\n",
    "    DATA_DIR / \"entitymatching\" / \"splits\" / \"academy_awards_2_actors_test.csv\",\n",
    "    name=\"test_set\", header=None, names=['id1', 'id2', 'label'], add_index=False\n",
    ")\n",
    "\n",
    "# Use EntityMatchingEvaluator.evaluate_blocking on Standard Blocking\n",
    "candidates_df = pd.DataFrame(standard_candidates)\n",
    "total_pairs = len(academy_awards) * len(actors)\n",
    "\n",
    "results = EntityMatchingEvaluator.evaluate_blocking(\n",
    "    candidate_pairs=candidates_df[['id1', 'id2']],\n",
    "    test_pairs=test_gt,\n",
    "    total_possible_pairs=total_pairs\n",
    ")\n",
    "\n",
    "print(f\"\\nüí° Evaluating pair quality only makes sense if the test set contains all possible pairs, which is not the case in this example!\")\n",
    "\n",
    "display(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Selecting Best Blocking Method ===\n",
      "Standard\n",
      "  Pair Completeness: 0.979\n",
      "  Pair Quality:      0.001\n",
      "  Reduction Ratio:   0.950\n",
      "  True Matches Found: 46/47\n",
      "SortedNeighbourhood\n",
      "  Pair Completeness: 0.979\n",
      "  Pair Quality:      0.016\n",
      "  Reduction Ratio:   0.996\n",
      "  True Matches Found: 46/47\n",
      "Token\n",
      "  Pair Completeness: 1.000\n",
      "  Pair Quality:      0.001\n",
      "  Reduction Ratio:   0.890\n",
      "  True Matches Found: 47/47\n",
      "Embedding\n",
      "  Pair Completeness: 1.000\n",
      "  Pair Quality:      0.046\n",
      "  Reduction Ratio:   0.998\n",
      "  True Matches Found: 47/47\n",
      "üìä Blocking Method Comparison:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>Candidates</th>\n",
       "      <th>Completeness</th>\n",
       "      <th>Reduction</th>\n",
       "      <th>Time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Standard</td>\n",
       "      <td>34457</td>\n",
       "      <td>0.979</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SortedNeighbourhood</td>\n",
       "      <td>2906</td>\n",
       "      <td>0.979</td>\n",
       "      <td>0.996</td>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Token</td>\n",
       "      <td>75242</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.890</td>\n",
       "      <td>0.147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Embedding</td>\n",
       "      <td>1030</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.998</td>\n",
       "      <td>3.393</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Method  Candidates Completeness Reduction Time (s)\n",
       "0             Standard       34457        0.979     0.950    0.064\n",
       "1  SortedNeighbourhood        2906        0.979     0.996    0.007\n",
       "2                Token       75242        1.000     0.890    0.147\n",
       "3            Embedding        1030        1.000     0.998    3.393"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üèÜ Best Method: Embedding (Completeness: 1.000, Reduction: 0.998)\n",
      "‚úÖ Using 1,030 candidate pairs for matching\n"
     ]
    }
   ],
   "source": [
    "# Evaluate all blocking methods and select the best one based on highest pair completeness, then highest reduction ratio (if tie)\n",
    "print(\"=== Selecting Best Blocking Method ===\")\n",
    "\n",
    "# Evaluate all blocking strategies\n",
    "blocking_methods = {\n",
    "    'Standard': (standard_candidates, standard_time),\n",
    "    'SortedNeighbourhood': (sn_candidates, sn_time), \n",
    "    'Token': (token_candidates, token_time),\n",
    "    'Embedding': (embedding_candidates, embedding_time)\n",
    "}\n",
    "\n",
    "best_method = None\n",
    "best_completeness = -1\n",
    "best_reduction = -1\n",
    "results_summary = []\n",
    "\n",
    "for method, (candidates, time_taken) in blocking_methods.items():\n",
    "    print(method)\n",
    "    candidates_df = pd.DataFrame(candidates)\n",
    "    eval_results = EntityMatchingEvaluator.evaluate_blocking(\n",
    "        candidate_pairs=candidates_df[['id1', 'id2']],\n",
    "        test_pairs=test_gt,\n",
    "        total_possible_pairs=total_pairs\n",
    "    )\n",
    "    \n",
    "    completeness = eval_results['pair_completeness']\n",
    "    reduction = eval_results['reduction_ratio']\n",
    "    \n",
    "    results_summary.append({\n",
    "        'Method': method,\n",
    "        'Candidates': len(candidates),\n",
    "        'Completeness': f\"{completeness:.3f}\",\n",
    "        'Reduction': f\"{reduction:.3f}\",\n",
    "        'Time (s)': f\"{time_taken:.3f}\"\n",
    "    })\n",
    "    \n",
    "    # Select best: highest completeness, then highest reduction ratio (if tie)\n",
    "    if (completeness > best_completeness or \n",
    "        (completeness == best_completeness and reduction > best_reduction)):\n",
    "        best_completeness = completeness\n",
    "        best_reduction = reduction\n",
    "        best_method = method\n",
    "\n",
    "# Display results\n",
    "print(\"üìä Blocking Method Comparison:\")\n",
    "display(pd.DataFrame(results_summary))\n",
    "\n",
    "# Select best candidates\n",
    "best_candidates = blocking_methods[best_method][0]\n",
    "print(f\"\\nüèÜ Best Method: {best_method} (Completeness: {best_completeness:.3f}, Reduction: {best_reduction:.3f})\")\n",
    "print(f\"‚úÖ Using {len(best_candidates):,} candidate pairs for matching\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: Blocking log functionality. What should this look like as each method does blocking very differently? Print samples of the \"blocks\"?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Entity Matching with Comparators\n",
    "\n",
    "Now we'll use PyDI's matching capabilities to find duplicate movies using multiple attribute comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparators for different attributes\n",
    "comparators = [\n",
    "    # Title similarity - most important for movies\n",
    "    StringComparator(\n",
    "        column='title',\n",
    "        similarity_function='jaro_winkler',  # Good for movie titles\n",
    "        preprocess=str.lower  # Case normalization\n",
    "    ),\n",
    "    \n",
    "    # Date proximity - movies from same year likely same film\n",
    "    DateComparator(\n",
    "        column='date', \n",
    "        max_days_difference=365  # Allow 1 year difference\n",
    "    ),\n",
    "    \n",
    "    # Actor name similarity - supporting evidence\n",
    "    StringComparator(\n",
    "        column='actor_name',\n",
    "        similarity_function='cosine',  # Good for names\n",
    "        preprocess=str.lower\n",
    "    )\n",
    "]\n",
    "\n",
    "# Define attribute weights\n",
    "weights = [0.6, 0.25, 0.15]  # Title most important, then date, then actor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Performing Entity Matching ===\n",
      "Candidate pairs to evaluate: 1,030\n",
      "Applying multi-attribute matching rules with threshold 0.7...\n",
      "\n",
      "Found 114 matches in 0.462 seconds\n"
     ]
    }
   ],
   "source": [
    "# Initialize Rule-Based Matcher\n",
    "matcher = RuleBasedMatcher()\n",
    "\n",
    "print(\"\\n=== Performing Entity Matching ===\")\n",
    "print(f\"Candidate pairs to evaluate: {len(best_candidates):,}\")\n",
    "print(\"Applying multi-attribute matching rules with threshold 0.7...\\n\")\n",
    "\n",
    "candidates_df = pd.DataFrame(best_candidates)\n",
    "\n",
    "# Perform matching with threshold 0.7\n",
    "start_time = time.time()\n",
    "\n",
    "matches = matcher.match(\n",
    "    df_left=left_df,\n",
    "    df_right=right_df, \n",
    "    candidates=[candidates_df],\n",
    "    comparators=comparators,\n",
    "    weights=weights,\n",
    "    threshold=0.7\n",
    ")\n",
    "\n",
    "matching_time = time.time() - start_time\n",
    "\n",
    "print(f\"Found {len(matches):,} matches in {matching_time:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Evaluation Against Ground Truth\n",
    "\n",
    "PyDI provides separate, focused evaluation methods for different aspects of entity matching:\n",
    "- **`evaluate_blocking()`**: Evaluates blocking strategies with pair completeness, pair quality, and reduction ratio\n",
    "- **`evaluate_matching()`**: Evaluates matching results with precision, recall, F1-score, and accuracy\n",
    "\n",
    "Let's evaluate our matching results against the provided ground truth correspondences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Evaluation Against Ground Truth ===\n",
      "Loading Winter framework's ground truth correspondences...\n",
      "\n",
      "Training ground truth: 335 pairs\n",
      "Test ground truth: 3,347 pairs\n",
      "Training set: 103 positive matches out of 335 pairs (30.7%)\n",
      "Test set: 47 positive matches out of 3,347 pairs (1.4%)\n",
      "\n",
      "üéØ We'll evaluate against the test set (3,347 pairs)\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Evaluation Against Ground Truth ===\")\n",
    "print(\"Loading Winter framework's ground truth correspondences...\\n\")\n",
    "\n",
    "# Load ground truth correspondences\n",
    "gt_train = load_csv(\n",
    "    DATA_DIR / \"entitymatching\" / \"splits\" / \"academy_awards_2_actors_training.csv\",\n",
    "    name=\"ground_truth_train\",\n",
    "    header=None,\n",
    "    names=['id1', 'id2', 'label'],\n",
    "    add_index=False\n",
    ")\n",
    "\n",
    "gt_test = load_csv(\n",
    "    DATA_DIR / \"entitymatching\" / \"splits\" / \"academy_awards_2_actors_test.csv\", \n",
    "    name=\"ground_truth_test\",\n",
    "    header=None,\n",
    "    names=['id1', 'id2', 'label'],\n",
    "    add_index=False\n",
    ")\n",
    "\n",
    "print(f\"Training ground truth: {len(gt_train):,} pairs\")\n",
    "print(f\"Test ground truth: {len(gt_test):,} pairs\")\n",
    "\n",
    "# Analyze label distribution\n",
    "for name, gt in [('Training', gt_train), ('Test', gt_test)]:\n",
    "    true_matches = (gt['label'] == 'TRUE').sum() if 'TRUE' in gt['label'].values else (gt['label'] == True).sum()\n",
    "    total = len(gt)\n",
    "    print(f\"{name} set: {true_matches:,} positive matches out of {total:,} pairs ({true_matches/total*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nüéØ We'll evaluate against the test set ({len(gt_test):,} pairs)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Entity Matching Evaluation Results ===\n",
      "Performance Metrics:\n",
      "  Accuracy:  0.976\n",
      "  Precision: 0.342\n",
      "  Recall:    0.830\n",
      "  F1-Score:  0.484\n",
      "Confusion Matrix:\n",
      "  True Positives:  39\n",
      "  True Negatives:  3299\n",
      "  False Positives: 75\n",
      "  False Negatives: 8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'precision': 0.34210526315789475,\n",
       " 'recall': 0.8297872340425532,\n",
       " 'f1': 0.484472049689441,\n",
       " 'accuracy': 0.9757380882782812,\n",
       " 'true_positives': 39,\n",
       " 'false_positives': 75,\n",
       " 'false_negatives': 8,\n",
       " 'true_negatives': 3299,\n",
       " 'threshold_used': 0.0,\n",
       " 'total_correspondences': 114,\n",
       " 'filtered_correspondences': 114,\n",
       " 'evaluation_timestamp': '2025-09-08T17:45:52.835410',\n",
       " 'output_files': ['c:\\\\Users\\\\Ralph\\\\dev\\\\pydi\\\\output\\\\tutorial\\\\matching_evaluation_summary.json',\n",
       "  'c:\\\\Users\\\\Ralph\\\\dev\\\\pydi\\\\output\\\\tutorial\\\\matching_detailed_results.csv']}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Perform evaluation using PyDI's EntityMatchingEvaluator\n",
    "print(\"\\n=== Entity Matching Evaluation Results ===\")\n",
    "\n",
    "# Use the new evaluate_matching method for cleaner evaluation\n",
    "eval_results = EntityMatchingEvaluator.evaluate_matching(\n",
    "    correspondences=matches,\n",
    "    test_pairs=gt_test,\n",
    "    out_dir=str(OUTPUT_DIR)\n",
    ")\n",
    "\n",
    "display(eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Re-running matcher with debug mode to capture detailed results:\n",
      "  Using 1030 actual candidate pairs from Embedding blocking\n",
      "  Found 114 matches in 0.480 seconds with debug enabled\n",
      "  ‚úÖ Full debug results: debugResultsMatchingRule.csv\n",
      "  ‚úÖ Short debug results: debugResultsMatchingRule.csv_short\n",
      "üìÅ Debug files saved to: c:\\Users\\Ralph\\dev\\pydi\\output\\tutorial\\debug_results\n"
     ]
    }
   ],
   "source": [
    "# Re-run the matcher with debug mode enabled to get detailed debug data\n",
    "print(\"üîç Re-running matcher with debug mode to capture detailed results:\")\n",
    "\n",
    "# Use the same candidates and settings from before\n",
    "candidates_df = pd.DataFrame(best_candidates)\n",
    "print(f\"  Using {len(candidates_df)} actual candidate pairs from {best_method} blocking\")\n",
    "\n",
    "# Re-run matching with debug enabled to capture detailed comparator results\n",
    "start_time = time.time()\n",
    "\n",
    "# Enable debug mode in the matcher to capture detailed results\n",
    "matches, debug_info = matcher.match(\n",
    "    df_left=left_df,\n",
    "    df_right=right_df, \n",
    "    candidates=[candidates_df],\n",
    "    comparators=comparators,\n",
    "    weights=weights,\n",
    "    threshold=0.7,\n",
    "    debug=True  # This enables debug output capture\n",
    ")\n",
    "\n",
    "matching_time = time.time() - start_time\n",
    "print(f\"  Found {len(matches)} matches in {matching_time:.3f} seconds with debug enabled\")\n",
    "\n",
    "debug_output_dir = OUTPUT_DIR / \"debug_results\"\n",
    "debug_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Call the write_debug_results function with actual results\n",
    "full_debug_path, short_debug_path = EntityMatchingEvaluator.write_debug_results(\n",
    "    correspondences=matches,\n",
    "    debug_results=debug_info,\n",
    "    out_dir=str(debug_output_dir),\n",
    "    matcher_instance=matcher\n",
    ")\n",
    "\n",
    "print(f\"  ‚úÖ Full debug results: {Path(full_debug_path).name}\")\n",
    "print(f\"  ‚úÖ Short debug results: {Path(short_debug_path).name}\")\n",
    "\n",
    "print(f\"üìÅ Debug files saved to: {debug_output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Demonstrating Cluster Size Distribution Analysis ===\n",
      "Analyzing cluster size distribution in our entity matching results...\n",
      "\n",
      "üìä Cluster Size Distribution Results:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster_size</th>\n",
       "      <th>frequency</th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>110</td>\n",
       "      <td>98.214286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1.785714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cluster_size  frequency  percentage\n",
       "0             2        110   98.214286\n",
       "1             3          2    1.785714"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"=== Demonstrating Cluster Size Distribution Analysis ===\")\n",
    "print(\"Analyzing cluster size distribution in our entity matching results...\")\n",
    "\n",
    "# Create cluster size distribution from our matches\n",
    "cluster_distribution = EntityMatchingEvaluator.create_cluster_size_distribution(\n",
    "    correspondences=matches,\n",
    "    out_dir=str(OUTPUT_DIR / \"cluster_analysis\")\n",
    ")\n",
    "\n",
    "print(f\"\\nüìä Cluster Size Distribution Results:\")\n",
    "display(cluster_distribution)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write out detailed cluster information with all entity records for debugging purposes\n",
    "\n",
    "# Use the matches we found earlier to demonstrate cluster details\n",
    "cluster_details_path = OUTPUT_DIR / \"cluster_analysis\" / \"detailed_cluster_info.json\"\n",
    "cluster_details_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Call write_cluster_details with our entity matches\n",
    "output_path = EntityMatchingEvaluator.write_cluster_details(\n",
    "    correspondences=matches,\n",
    "    out_path=str(cluster_details_path)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Machine Learning-based Matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TBD in notebook, functionality is there"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Data Fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Data Fusion: Resolving Conflicts ===\n",
      "Creating unified movie records from multiple sources...\n",
      "\n",
      "üìä Fusion Input Datasets:\n",
      "  Academy Awards: 4,592 records\n",
      "  Actors: 149 records\n",
      "  Golden Globes: 2,286 records\n",
      "  Total: 7,027 records\n",
      "\n",
      "üéØ Goal: Create single authoritative movie record per entity\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Data Fusion: Resolving Conflicts ===\")\n",
    "print(\"Creating unified movie records from multiple sources...\\n\")\n",
    "\n",
    "# Load all three datasets for fusion\n",
    "print(\"üìä Fusion Input Datasets:\")\n",
    "for df, name in zip(datasets, names):\n",
    "    print(f\"  {name}: {len(df):,} records\")\n",
    "\n",
    "total_input_records = sum(len(df) for df in datasets)\n",
    "print(f\"  Total: {total_input_records:,} records\")\n",
    "print(f\"\\nüéØ Goal: Create single authoritative movie record per entity\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pydi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
