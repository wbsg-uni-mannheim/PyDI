{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyDI Data Integration Tutorial\n",
    "\n",
    "This tutorial demonstrates comprehensive data integration using PyDI. We'll work with movie datasets to showcase the data integration pipeline from entity matching to Data Fusion.\n",
    "\n",
    "### What You'll Learn\n",
    "\n",
    "1. **Data Loading & Profiling**: Load and analyze movie datasets with provenance tracking\n",
    "2. **Identity Resolution**: \n",
    "   - Blocking strategies (Standard, Sorted Neighbourhood, Token-based, Embedding-based)\n",
    "   - Multi-attribute similarity matching with custom comparators\n",
    "   - Machine learning-based entity matching\n",
    "3. **Data Fusion**: \n",
    "   - Conflict resolution with custom fusion rules\n",
    "   - Quality assessment against test set\n",
    "   - Provenance-based conflict resolution\n",
    "\n",
    "### Datasets\n",
    "\n",
    "We'll use three movie datasets:\n",
    "- **Academy Awards**: Movies with Oscar information (4,592 records)\n",
    "- **Actors**: Movies with actor details (149 records) \n",
    "- **Golden Globes**: Movies with Golden Globe awards (2,286 records)\n",
    "\n",
    "These datasets contain overlapping movie information but with different attributes, data quality issues, and conflicting values - perfect for demonstrating real-world data integration challenges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Core Python libraries\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import logging\n",
    "# import time\n",
    "# import json\n",
    "# from datetime import datetime\n",
    "\n",
    "# # PyDI imports for data loading and profiling\n",
    "\n",
    "# # PyDI imports for entity matching\n",
    "# from PyDI.entitymatching import (\n",
    "#     # Blocking strategies\n",
    "#     NoBlocking, StandardBlocking, SortedNeighbourhood, \n",
    "#     TokenBlocking, EmbeddingBlocking,\n",
    "#     # Matchers\n",
    "#     RuleBasedMatcher, MLBasedMatcher,\n",
    "#     # Feature extraction for ML\n",
    "#     FeatureExtractor,\n",
    "#     # Comparators\n",
    "#     StringComparator, DateComparator, NumericComparator,\n",
    "#     # Evaluation - NEW: Separate methods for blocking and matching evaluation\n",
    "#     EntityMatchingEvaluator,\n",
    "#     # Utilities\n",
    "#     ensure_record_ids\n",
    "# )\n",
    "\n",
    "# # PyDI imports for data fusion\n",
    "# from PyDI.fusion import (\n",
    "#     DataFusionEngine, DataFusionStrategy, DataFusionEvaluator,\n",
    "#     # Fusion rules\n",
    "#     longest_string, shortest_string, most_recent, earliest,\n",
    "#     average, median, maximum, minimum, most_complete,\n",
    "#     union, intersection, voting,\n",
    "#     # Convenient aliases\n",
    "#     LONGEST, SHORTEST, LATEST, EARLIEST, AVG, MAX, MIN, VOTE, UNION,\n",
    "#     # Analysis and reporting\n",
    "#     FusionReport, FusionQualityMetrics, ProvenanceTracker,\n",
    "#     build_record_groups_from_correspondences,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's setup logging first\n",
    "import logging\n",
    "\n",
    "# # Configure logging for INFO level\n",
    "# logging.basicConfig(\n",
    "#     level=logging.INFO,\n",
    "#     format='[%(levelname)-5s] %(name)s - %(message)s',\n",
    "#     handlers=[\n",
    "#           logging.FileHandler('output/logs/pydi.log'),  # Save to file\n",
    "#           logging.StreamHandler()                      # Display on console\n",
    "#       ],\n",
    "#     force=True\n",
    "# )\n",
    "\n",
    "# Configure logging for DEBUG level\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format='[%(levelname)-5s] %(name)s - %(message)s',\n",
    "    handlers=[\n",
    "          logging.FileHandler('output/logs/pydi.log'),  # Save to file\n",
    "          logging.StreamHandler()                      # Display on console\n",
    "      ],\n",
    "    force=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the PyDI package if not already installed\n",
    "# First navigate to the root directory of the repository in your terminal, then run:\n",
    "# !pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyDI Tutorial\n",
      "Repository root: c:\\Users\\Ralph\\dev\\pydi\n",
      "Output directory: c:\\Users\\Ralph\\dev\\pydi\\PyDI\\tutorial\\output\\movies\n",
      "All systems ready! üöÄ\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Setup paths\n",
    "def get_repo_root():\n",
    "    \"\"\"Get repository root directory.\"\"\"\n",
    "    current = Path.cwd()\n",
    "    while current != current.parent:\n",
    "        if (current / 'pyproject.toml').exists():\n",
    "            return current\n",
    "        current = current.parent\n",
    "    return Path.cwd()\n",
    "\n",
    "ROOT = get_repo_root()\n",
    "OUTPUT_DIR = ROOT / \"PyDI\" / \"tutorial\" / \"output\" / \"movies\"\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"PyDI Tutorial\")\n",
    "print(f\"Repository root: {ROOT}\")\n",
    "print(f\"Output directory: {OUTPUT_DIR}\")\n",
    "print(f\"All systems ready! üöÄ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Data Loading and Profiling\n",
    "\n",
    "PyDI provides provenance-aware data loading that automatically tracks dataset metadata and optionally adds unique identifiers to each record. Let's load our movie datasets and understand their characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Academy Awards:\n",
      "  Records: 100,291\n",
      "  Attributes: 7\n",
      "  Columns: ['_id', 'id', 'title', 'actor_name', 'date', 'director_name', 'oscar']\n",
      "  Dataset name: academy_awards\n",
      "\n",
      "Actors:\n",
      "  Records: 100,000\n",
      "  Attributes: 7\n",
      "  Columns: ['_id', 'id', 'title', 'actor_name', 'actors_actor_birthday', 'actors_actor_birthplace', 'date']\n",
      "  Dataset name: actors\n",
      "\n",
      "Golden Globes:\n",
      "  Records: 100,323\n",
      "  Attributes: 7\n",
      "  Columns: ['_id', 'id', 'title', 'actor_name', 'date', 'director_name', 'globe']\n",
      "  Dataset name: golden_globes\n",
      "\n",
      "Total records across all datasets: 300,614\n"
     ]
    }
   ],
   "source": [
    "from PyDI.io import load_xml\n",
    "\n",
    "# Define dataset paths\n",
    "DATA_DIR = ROOT / \"PyDI\" / \"tutorial\" / \"input\" / \"movies\"\n",
    "\n",
    "# Load Academy Awards dataset\n",
    "academy_awards = load_xml(\n",
    "    DATA_DIR / \"data\" / \"academy_awards_large.xml\",\n",
    "    name=\"academy_awards\",\n",
    "    record_tag=\"movie\",\n",
    "    add_index=True,\n",
    "    index_column_name=\"_id\"\n",
    ")\n",
    "\n",
    "# Load Actors dataset  \n",
    "actors = load_xml(\n",
    "    DATA_DIR / \"data\" / \"actors_large.xml\",\n",
    "    name=\"actors\", \n",
    "    record_tag=\"movie\",\n",
    "    add_index=True,\n",
    "    index_column_name=\"_id\"\n",
    ")\n",
    "\n",
    "# Load Golden Globes dataset\n",
    "golden_globes = load_xml(\n",
    "    DATA_DIR / \"data\" / \"golden_globes_large.xml\",\n",
    "    name=\"golden_globes\",\n",
    "    record_tag=\"movie\", \n",
    "    add_index=True,\n",
    "    index_column_name=\"_id\"\n",
    ")\n",
    "\n",
    "# Display basic information\n",
    "datasets = [academy_awards, actors, golden_globes]\n",
    "names = [\"Academy Awards\", \"Actors\", \"Golden Globes\"]\n",
    "\n",
    "for df, name in zip(datasets, names):\n",
    "    print(f\"{name}:\")\n",
    "    print(f\"  Records: {len(df):,}\")\n",
    "    print(f\"  Attributes: {len(df.columns)}\")\n",
    "    print(f\"  Columns: {list(df.columns)}\")\n",
    "    print(f\"  Dataset name: {df.attrs.get('dataset_name', 'unknown')}\")\n",
    "    print()\n",
    "\n",
    "total_records = sum(len(df) for df in datasets)\n",
    "print(f\"Total records across all datasets: {total_records:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìΩÔ∏è Academy Awards Dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>actor_name</th>\n",
       "      <th>date</th>\n",
       "      <th>director_name</th>\n",
       "      <th>oscar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>academy_awards-000000</td>\n",
       "      <td>academy_awards_1</td>\n",
       "      <td>Biutiful</td>\n",
       "      <td>Javier Bardem</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>academy_awards-000001</td>\n",
       "      <td>academy_awards_2</td>\n",
       "      <td>True Grit</td>\n",
       "      <td>Jeff Bridges</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>Joel Coen</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>academy_awards-000002</td>\n",
       "      <td>academy_awards_2</td>\n",
       "      <td>True Grit</td>\n",
       "      <td>Jeff Bridges</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>Ethan Coen</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     _id                id      title     actor_name  \\\n",
       "0  academy_awards-000000  academy_awards_1   Biutiful  Javier Bardem   \n",
       "1  academy_awards-000001  academy_awards_2  True Grit   Jeff Bridges   \n",
       "2  academy_awards-000002  academy_awards_2  True Grit   Jeff Bridges   \n",
       "\n",
       "         date director_name oscar  \n",
       "0  2010-01-01           NaN   NaN  \n",
       "1  2010-01-01     Joel Coen   NaN  \n",
       "2  2010-01-01    Ethan Coen   NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üé≠ Actors Dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>actor_name</th>\n",
       "      <th>actors_actor_birthday</th>\n",
       "      <th>actors_actor_birthplace</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>actors-00000</td>\n",
       "      <td>actors_1</td>\n",
       "      <td>7th Heaven</td>\n",
       "      <td>Janet Gaynor</td>\n",
       "      <td>1906-01-01</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>1929-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>actors-00001</td>\n",
       "      <td>actors_2</td>\n",
       "      <td>Coquette</td>\n",
       "      <td>Mary Pickford</td>\n",
       "      <td>1892-01-01</td>\n",
       "      <td>Canada</td>\n",
       "      <td>1930-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>actors-00002</td>\n",
       "      <td>actors_3</td>\n",
       "      <td>The Divorcee</td>\n",
       "      <td>Norma Shearer</td>\n",
       "      <td>1902-01-01</td>\n",
       "      <td>Canada</td>\n",
       "      <td>1931-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            _id        id         title     actor_name actors_actor_birthday  \\\n",
       "0  actors-00000  actors_1    7th Heaven   Janet Gaynor            1906-01-01   \n",
       "1  actors-00001  actors_2      Coquette  Mary Pickford            1892-01-01   \n",
       "2  actors-00002  actors_3  The Divorcee  Norma Shearer            1902-01-01   \n",
       "\n",
       "  actors_actor_birthplace        date  \n",
       "0            Pennsylvania  1929-01-01  \n",
       "1                  Canada  1930-01-01  \n",
       "2                  Canada  1931-01-01  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üèÜ Golden Globes Dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>actor_name</th>\n",
       "      <th>date</th>\n",
       "      <th>director_name</th>\n",
       "      <th>globe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>golden_globes-000000</td>\n",
       "      <td>golden_globes_1</td>\n",
       "      <td>Frankie and Alice</td>\n",
       "      <td>Halle Berry</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>golden_globes-000001</td>\n",
       "      <td>golden_globes_2</td>\n",
       "      <td>Rabbit Hole</td>\n",
       "      <td>Nicole Kidman</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>golden_globes-000002</td>\n",
       "      <td>golden_globes_3</td>\n",
       "      <td>Winter's Bone</td>\n",
       "      <td>Jennifer Lawrence</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    _id               id              title  \\\n",
       "0  golden_globes-000000  golden_globes_1  Frankie and Alice   \n",
       "1  golden_globes-000001  golden_globes_2        Rabbit Hole   \n",
       "2  golden_globes-000002  golden_globes_3      Winter's Bone   \n",
       "\n",
       "          actor_name        date director_name globe  \n",
       "0        Halle Berry  2011-01-01           NaN   NaN  \n",
       "1      Nicole Kidman  2011-01-01           NaN   NaN  \n",
       "2  Jennifer Lawrence  2011-01-01           NaN   NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Preview the data structure\n",
    "\n",
    "print(\"\\nüìΩÔ∏è Academy Awards Dataset:\")\n",
    "display(academy_awards.head(3))\n",
    "\n",
    "print(\"\\nüé≠ Actors Dataset:\")\n",
    "display(actors.head(3))\n",
    "\n",
    "print(\"\\nüèÜ Golden Globes Dataset:\")\n",
    "display(golden_globes.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Quality Analysis\n",
    "\n",
    "Let's use PyDI's profiling capabilities to understand our data quality and identify the best attributes for matching."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Dataset Summary\n",
    "\n",
    "First, let's use the DataProfiler's `summary()` method to get basic statistics for each dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "academy_awards:\n",
      "  Rows: 100,291\n",
      "  Columns: 7\n",
      "  Total nulls: 240,789\n",
      "  Null percentage: 34.3%\n",
      "  Null counts per column:\n",
      "    title: 267 (0.3%)\n",
      "    actor_name: 77,184 (77.0%)\n",
      "    director_name: 91,081 (90.8%)\n",
      "    oscar: 72,257 (72.0%)\n",
      "\n",
      "actors:\n",
      "  Rows: 100,000\n",
      "  Columns: 7\n",
      "  Total nulls: 0\n",
      "  Null percentage: 0.0%\n",
      "\n",
      "golden_globes:\n",
      "  Rows: 100,323\n",
      "  Columns: 7\n",
      "  Total nulls: 161,794\n",
      "  Null percentage: 23.0%\n",
      "  Null counts per column:\n",
      "    actor_name: 2,349 (2.3%)\n",
      "    director_name: 86,392 (86.1%)\n",
      "    globe: 73,053 (72.8%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'rows': 100323,\n",
       " 'columns': 7,\n",
       " 'nulls_total': 161794,\n",
       " 'nulls_per_column': {'_id': 0,\n",
       "  'id': 0,\n",
       "  'title': 0,\n",
       "  'actor_name': 2349,\n",
       "  'date': 0,\n",
       "  'director_name': 86392,\n",
       "  'globe': 73053},\n",
       " 'dtypes': {'_id': 'string',\n",
       "  'id': 'object',\n",
       "  'title': 'object',\n",
       "  'actor_name': 'object',\n",
       "  'date': 'object',\n",
       "  'director_name': 'object',\n",
       "  'globe': 'object'}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from PyDI.profiling import DataProfiler\n",
    "\n",
    "# Initialize the DataProfiler\n",
    "profiler = DataProfiler()\n",
    "\n",
    "for df, name in zip(datasets, names):\n",
    "    profile = profiler.summary(df) # automatically prints some statistics and returns object containing stats\n",
    "\n",
    "display(profile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attribute Coverage Analysis\n",
    "\n",
    "Next, let's use the `analyze_coverage()` method to understand how attributes overlap across datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Attribute coverage across datasets:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attribute</th>\n",
       "      <th>academy_awards_count</th>\n",
       "      <th>academy_awards_pct</th>\n",
       "      <th>academy_awards_coverage</th>\n",
       "      <th>academy_awards_samples</th>\n",
       "      <th>actors_count</th>\n",
       "      <th>actors_pct</th>\n",
       "      <th>actors_coverage</th>\n",
       "      <th>actors_samples</th>\n",
       "      <th>golden_globes_count</th>\n",
       "      <th>golden_globes_pct</th>\n",
       "      <th>golden_globes_coverage</th>\n",
       "      <th>golden_globes_samples</th>\n",
       "      <th>avg_coverage</th>\n",
       "      <th>max_coverage</th>\n",
       "      <th>datasets_with_attribute</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>_id</td>\n",
       "      <td>100291/100291</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>['academy_awards-000000', 'academy_awards-0000...</td>\n",
       "      <td>100000/100000</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['actors-00000', 'actors-00001', 'actors-00002']</td>\n",
       "      <td>100323/100323</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>['golden_globes-000000', 'golden_globes-000001...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>actor_name</td>\n",
       "      <td>23107/100291</td>\n",
       "      <td>23.0%</td>\n",
       "      <td>0.230400</td>\n",
       "      <td>['Javier Bardem', 'Jeff Bridges', 'Jeff Bridges']</td>\n",
       "      <td>100000/100000</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['Janet Gaynor', 'Mary Pickford', 'Norma Shear...</td>\n",
       "      <td>97974/100323</td>\n",
       "      <td>97.7%</td>\n",
       "      <td>0.976586</td>\n",
       "      <td>['Halle Berry', 'Nicole Kidman', 'Jennifer Law...</td>\n",
       "      <td>0.735662</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>actors_actor_birthday</td>\n",
       "      <td>0/0</td>\n",
       "      <td>0%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>N/A</td>\n",
       "      <td>100000/100000</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['1906-01-01', '1892-01-01', '1902-01-01']</td>\n",
       "      <td>0/0</td>\n",
       "      <td>0%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>actors_actor_birthplace</td>\n",
       "      <td>0/0</td>\n",
       "      <td>0%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>N/A</td>\n",
       "      <td>100000/100000</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['Pennsylvania', 'Canada', 'Canada']</td>\n",
       "      <td>0/0</td>\n",
       "      <td>0%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>date</td>\n",
       "      <td>100291/100291</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>['2010-01-01', '2010-01-01', '2010-01-01']</td>\n",
       "      <td>100000/100000</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['1929-01-01', '1930-01-01', '1931-01-01']</td>\n",
       "      <td>100323/100323</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>['2011-01-01', '2011-01-01', '2011-01-01']</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>director_name</td>\n",
       "      <td>9210/100291</td>\n",
       "      <td>9.2%</td>\n",
       "      <td>0.091833</td>\n",
       "      <td>['Joel Coen', 'Ethan Coen', 'David Fincher']</td>\n",
       "      <td>0/0</td>\n",
       "      <td>0%</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N/A</td>\n",
       "      <td>13931/100323</td>\n",
       "      <td>13.9%</td>\n",
       "      <td>0.138861</td>\n",
       "      <td>['Darren Aronofsky', 'David Fincher', 'Tom Hoo...</td>\n",
       "      <td>0.076898</td>\n",
       "      <td>0.138861</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>globe</td>\n",
       "      <td>0/0</td>\n",
       "      <td>0%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0/0</td>\n",
       "      <td>0%</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N/A</td>\n",
       "      <td>27270/100323</td>\n",
       "      <td>27.2%</td>\n",
       "      <td>0.271822</td>\n",
       "      <td>['yes', 'yes', 'yes']</td>\n",
       "      <td>0.090607</td>\n",
       "      <td>0.271822</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>id</td>\n",
       "      <td>100291/100291</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>['academy_awards_1', 'academy_awards_2', 'acad...</td>\n",
       "      <td>100000/100000</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['actors_1', 'actors_2', 'actors_3']</td>\n",
       "      <td>100323/100323</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>['golden_globes_1', 'golden_globes_2', 'golden...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>oscar</td>\n",
       "      <td>28034/100291</td>\n",
       "      <td>28.0%</td>\n",
       "      <td>0.279527</td>\n",
       "      <td>['yes', 'yes', 'yes']</td>\n",
       "      <td>0/0</td>\n",
       "      <td>0%</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0/0</td>\n",
       "      <td>0%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0.093176</td>\n",
       "      <td>0.279527</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>title</td>\n",
       "      <td>100024/100291</td>\n",
       "      <td>99.7%</td>\n",
       "      <td>0.997338</td>\n",
       "      <td>['Biutiful', 'True Grit', 'True Grit']</td>\n",
       "      <td>100000/100000</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['7th Heaven', 'Coquette', 'The Divorcee']</td>\n",
       "      <td>100323/100323</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>['Frankie and Alice', 'Rabbit Hole', \"Winter's...</td>\n",
       "      <td>0.999113</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 attribute academy_awards_count academy_awards_pct  \\\n",
       "0                      _id        100291/100291             100.0%   \n",
       "1               actor_name         23107/100291              23.0%   \n",
       "2    actors_actor_birthday                  0/0                 0%   \n",
       "3  actors_actor_birthplace                  0/0                 0%   \n",
       "4                     date        100291/100291             100.0%   \n",
       "5            director_name          9210/100291               9.2%   \n",
       "6                    globe                  0/0                 0%   \n",
       "7                       id        100291/100291             100.0%   \n",
       "8                    oscar         28034/100291              28.0%   \n",
       "9                    title        100024/100291              99.7%   \n",
       "\n",
       "   academy_awards_coverage                             academy_awards_samples  \\\n",
       "0                 1.000000  ['academy_awards-000000', 'academy_awards-0000...   \n",
       "1                 0.230400  ['Javier Bardem', 'Jeff Bridges', 'Jeff Bridges']   \n",
       "2                 0.000000                                                N/A   \n",
       "3                 0.000000                                                N/A   \n",
       "4                 1.000000         ['2010-01-01', '2010-01-01', '2010-01-01']   \n",
       "5                 0.091833       ['Joel Coen', 'Ethan Coen', 'David Fincher']   \n",
       "6                 0.000000                                                N/A   \n",
       "7                 1.000000  ['academy_awards_1', 'academy_awards_2', 'acad...   \n",
       "8                 0.279527                              ['yes', 'yes', 'yes']   \n",
       "9                 0.997338             ['Biutiful', 'True Grit', 'True Grit']   \n",
       "\n",
       "    actors_count actors_pct  actors_coverage  \\\n",
       "0  100000/100000     100.0%              1.0   \n",
       "1  100000/100000     100.0%              1.0   \n",
       "2  100000/100000     100.0%              1.0   \n",
       "3  100000/100000     100.0%              1.0   \n",
       "4  100000/100000     100.0%              1.0   \n",
       "5            0/0         0%              0.0   \n",
       "6            0/0         0%              0.0   \n",
       "7  100000/100000     100.0%              1.0   \n",
       "8            0/0         0%              0.0   \n",
       "9  100000/100000     100.0%              1.0   \n",
       "\n",
       "                                      actors_samples golden_globes_count  \\\n",
       "0   ['actors-00000', 'actors-00001', 'actors-00002']       100323/100323   \n",
       "1  ['Janet Gaynor', 'Mary Pickford', 'Norma Shear...        97974/100323   \n",
       "2         ['1906-01-01', '1892-01-01', '1902-01-01']                 0/0   \n",
       "3               ['Pennsylvania', 'Canada', 'Canada']                 0/0   \n",
       "4         ['1929-01-01', '1930-01-01', '1931-01-01']       100323/100323   \n",
       "5                                                N/A        13931/100323   \n",
       "6                                                N/A        27270/100323   \n",
       "7               ['actors_1', 'actors_2', 'actors_3']       100323/100323   \n",
       "8                                                N/A                 0/0   \n",
       "9         ['7th Heaven', 'Coquette', 'The Divorcee']       100323/100323   \n",
       "\n",
       "  golden_globes_pct  golden_globes_coverage  \\\n",
       "0            100.0%                1.000000   \n",
       "1             97.7%                0.976586   \n",
       "2                0%                0.000000   \n",
       "3                0%                0.000000   \n",
       "4            100.0%                1.000000   \n",
       "5             13.9%                0.138861   \n",
       "6             27.2%                0.271822   \n",
       "7            100.0%                1.000000   \n",
       "8                0%                0.000000   \n",
       "9            100.0%                1.000000   \n",
       "\n",
       "                               golden_globes_samples  avg_coverage  \\\n",
       "0  ['golden_globes-000000', 'golden_globes-000001...      1.000000   \n",
       "1  ['Halle Berry', 'Nicole Kidman', 'Jennifer Law...      0.735662   \n",
       "2                                                N/A      0.333333   \n",
       "3                                                N/A      0.333333   \n",
       "4         ['2011-01-01', '2011-01-01', '2011-01-01']      1.000000   \n",
       "5  ['Darren Aronofsky', 'David Fincher', 'Tom Hoo...      0.076898   \n",
       "6                              ['yes', 'yes', 'yes']      0.090607   \n",
       "7  ['golden_globes_1', 'golden_globes_2', 'golden...      1.000000   \n",
       "8                                                N/A      0.093176   \n",
       "9  ['Frankie and Alice', 'Rabbit Hole', \"Winter's...      0.999113   \n",
       "\n",
       "   max_coverage  datasets_with_attribute  \n",
       "0      1.000000                        3  \n",
       "1      1.000000                        3  \n",
       "2      1.000000                        1  \n",
       "3      1.000000                        1  \n",
       "4      1.000000                        3  \n",
       "5      0.138861                        2  \n",
       "6      0.271822                        1  \n",
       "7      1.000000                        3  \n",
       "8      0.279527                        1  \n",
       "9      1.000000                        3  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîó Attributes suitable for entity matching:\n",
      "Attributes available in 2+ datasets: ['_id', 'actor_name', 'date', 'director_name', 'id', 'title']\n"
     ]
    }
   ],
   "source": [
    "coverage = profiler.analyze_coverage(\n",
    "    datasets=datasets,\n",
    "    include_samples=True,\n",
    "    sample_count=3  # Show 3 sample values per attribute\n",
    ")\n",
    "\n",
    "print(\"üìä Attribute coverage across datasets:\")\n",
    "display(coverage)\n",
    "\n",
    "# Identify attributes suitable for entity matching\n",
    "print(\"\\nüîó Attributes suitable for entity matching:\")\n",
    "matching_attrs = coverage[coverage['datasets_with_attribute'] >= 2]['attribute'].tolist()\n",
    "print(f\"Attributes available in 2+ datasets: {matching_attrs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detailed Data Profiling\n",
    "\n",
    "Now let's generate comprehensive HTML profiles for each dataset using the `profile()` method. These reports provide in-depth statistical analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Profiling Academy Awards...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <ins><a href=\"https://ydata.ai/register\">Upgrade to ydata-sdk</a></ins>\n",
       "                <p>\n",
       "                    Improve your data and profiling with ydata-sdk, featuring data quality scoring, redundancy detection, outlier identification, text validation, and synthetic data generation.\n",
       "                </p>\n",
       "            </div>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "601d37288f5f44d2b099e46fa2389efb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:01<00:00,  6.32it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "886969c4f20743279aec57a1417e99bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate report structure:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5362c0fa4bb947ce8c2caa50cec892e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Render HTML:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de621af13de84dfa90606f1b7d7d7e88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Export report to file:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úÖ Profile saved: c:\\Users\\Ralph\\dev\\pydi\\PyDI\\tutorial\\output\\movies\\dataset-profiles\\academy_awards_profile.html\n",
      "üìä Profiling Actors...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c1e7c6898384f68a2056f5c15ec81de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:01<00:00,  5.94it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f56e625318894591afd2a09293cee649",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate report structure:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7786def8a874a9aa36439d600e614a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Render HTML:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e262763a461f40d7aa2e3c077827d86e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Export report to file:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úÖ Profile saved: c:\\Users\\Ralph\\dev\\pydi\\PyDI\\tutorial\\output\\movies\\dataset-profiles\\actors_profile.html\n",
      "üìä Profiling Golden Globes...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f077ac97628444eac1affc84fed5327",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:01<00:00,  4.41it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9a66fa139454b00972f311d88e5a2bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate report structure:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bfd0fa2585940219652d237debb85ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Render HTML:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "818f7031334a4b39b8c335c2b6ed3230",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Export report to file:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úÖ Profile saved: c:\\Users\\Ralph\\dev\\pydi\\PyDI\\tutorial\\output\\movies\\dataset-profiles\\golden_globes_profile.html\n",
      "\n",
      "üéØ Generated 3 detailed HTML reports\n",
      "üìÅ Location: c:\\Users\\Ralph\\dev\\pydi\\PyDI\\tutorial\\output\\movies\\dataset-profiles\n",
      "\n",
      "üí° Open these HTML files in your browser for interactive exploration:\n",
      "  ‚Ä¢ academy_awards_profile.html\n",
      "  ‚Ä¢ actors_profile.html\n",
      "  ‚Ä¢ golden_globes_profile.html\n"
     ]
    }
   ],
   "source": [
    "# Generate detailed HTML profiles for each dataset\n",
    "\n",
    "profile_dir = OUTPUT_DIR / \"dataset-profiles\"\n",
    "profile_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "profile_paths = []\n",
    "\n",
    "for df, name in zip(datasets, names):\n",
    "    print(f\"üìä Profiling {name}...\")\n",
    "    \n",
    "    profile_path = profiler.profile(df, str(profile_dir))\n",
    "    profile_paths.append(profile_path)\n",
    "    print(f\"  ‚úÖ Profile saved: {profile_path}\")\n",
    "\n",
    "print(f\"\\nüéØ Generated {len(profile_paths)} detailed HTML reports\")\n",
    "print(f\"üìÅ Location: {profile_dir}\")\n",
    "print(\"\\nüí° Open these HTML files in your browser for interactive exploration:\")\n",
    "for path in profile_paths:\n",
    "    print(f\"  ‚Ä¢ {Path(path).name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Comparison\n",
    "\n",
    "Finally, let's use the `compare()` method to create a comparison report between two datasets, highlighting differences and similarities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Comparing Academy Awards vs Golden Globes datasets...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9a0e70fe85a490eab4883333690947a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "                                             |          | [  0%]   00:00 -> (? left)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report c:\\Users\\Ralph\\dev\\pydi\\PyDI\\tutorial\\output\\movies\\dataset-comparisons\\academy_awards_vs_golden_globes_compare.html was generated! NOTEBOOK/COLAB USERS: the web browser MAY not pop up, regardless, the report IS saved in your notebook/colab files.\n",
      "‚úÖ Comparison report saved: c:\\Users\\Ralph\\dev\\pydi\\PyDI\\tutorial\\output\\movies\\dataset-comparisons\\academy_awards_vs_golden_globes_compare.html\n",
      "üîç Comparing Academy Awards vs Golden Globes datasets...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6151f6d89a274260b7fb150d201aef93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "                                             |          | [  0%]   00:00 -> (? left)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report c:\\Users\\Ralph\\dev\\pydi\\PyDI\\tutorial\\output\\movies\\dataset-comparisons\\academy_awards_vs_actors_compare.html was generated! NOTEBOOK/COLAB USERS: the web browser MAY not pop up, regardless, the report IS saved in your notebook/colab files.\n",
      "‚úÖ Comparison report saved: c:\\Users\\Ralph\\dev\\pydi\\PyDI\\tutorial\\output\\movies\\dataset-comparisons\\academy_awards_vs_actors_compare.html\n",
      "üîç Comparing Academy Awards vs Golden Globes datasets...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d5dbb84780548f2bd92b5350dfeb206",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "                                             |          | [  0%]   00:00 -> (? left)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report c:\\Users\\Ralph\\dev\\pydi\\PyDI\\tutorial\\output\\movies\\dataset-comparisons\\actors_vs_golden_globes_compare.html was generated! NOTEBOOK/COLAB USERS: the web browser MAY not pop up, regardless, the report IS saved in your notebook/colab files.\n",
      "‚úÖ Comparison report saved: c:\\Users\\Ralph\\dev\\pydi\\PyDI\\tutorial\\output\\movies\\dataset-comparisons\\actors_vs_golden_globes_compare.html\n"
     ]
    }
   ],
   "source": [
    "# Compare Academy Awards vs Golden Globes datasets\n",
    "\n",
    "compare_dir = OUTPUT_DIR / \"dataset-comparisons\"\n",
    "compare_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"üîç Comparing Academy Awards vs Golden Globes datasets...\")\n",
    "\n",
    "comparison_path = profiler.compare(academy_awards, golden_globes, compare_dir)\n",
    "print(f\"‚úÖ Comparison report saved: {comparison_path}\")\n",
    "\n",
    "print(\"üîç Comparing Academy Awards vs Golden Globes datasets...\")\n",
    "\n",
    "comparison_path = profiler.compare(academy_awards, actors, compare_dir)\n",
    "print(f\"‚úÖ Comparison report saved: {comparison_path}\")\n",
    "\n",
    "print(\"üîç Comparing Academy Awards vs Golden Globes datasets...\")\n",
    "\n",
    "comparison_path = profiler.compare(actors, golden_globes, compare_dir)\n",
    "print(f\"‚úÖ Comparison report saved: {comparison_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Identity Resolution (Entity Matching)\n",
    "\n",
    "Identity Resolution is the process of identifying records that refer to the same real-world entity. PyDI provides comprehensive blocking and matching capabilities.\n",
    "\n",
    "### Step 1: Blocking Strategies\n",
    "\n",
    "Blocking reduces the number of comparisons from O(n¬≤) to a manageable subset. Let's explore different blocking strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's setup logging first\n",
    "import logging\n",
    "\n",
    "# # Configure logging for INFO level\n",
    "# logging.basicConfig(\n",
    "#     level=logging.INFO,\n",
    "#     format='[%(levelname)-5s] %(name)s - %(message)s',\n",
    "#     handlers=[\n",
    "#           logging.FileHandler('output/logs/pydi.log'),  # Save to file\n",
    "#           logging.StreamHandler()                      # Display on console\n",
    "#       ],\n",
    "#     force=True\n",
    "# )\n",
    "\n",
    "# Configure logging for DEBUG level\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format='[%(levelname)-5s] %(name)s - %(message)s',\n",
    "    handlers=[\n",
    "          logging.FileHandler('output/logs/pydi.log'),  # Save to file\n",
    "          logging.StreamHandler()                      # Display on console\n",
    "      ],\n",
    "    force=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without blocking: 10,032,300,000 comparisons required\n",
      "\n",
      "üéØ Goal: Reduce comparisons while maintaining high recall\n",
      "\n",
      "\n",
      " No Blocking\n"
     ]
    }
   ],
   "source": [
    "from PyDI.entitymatching import NoBlocking, StandardBlocking, SortedNeighbourhood, TokenBlocking, EmbeddingBlocking\n",
    "\n",
    "# We'll focus on Actors and Golden Globes for showcasing blocking strategies\n",
    "\n",
    "max_pairs = len(actors) * len(golden_globes)\n",
    "print(f\"Without blocking: {max_pairs:,} comparisons required\")\n",
    "print(\"\\nüéØ Goal: Reduce comparisons while maintaining high recall\\n\")\n",
    "\n",
    "# No Blocking - compare all possible pairs\n",
    "print(\"\\n No Blocking\")\n",
    "\n",
    "no_blocker = NoBlocking(\n",
    "    actors, golden_globes,\n",
    "    batch_size=1000\n",
    ")\n",
    "\n",
    "# # in an actual application, we do not build a list of all pairs but stream over them like this\n",
    "# for batch in no_blocker:\n",
    "#     # do something with the pairs\n",
    "#     continue\n",
    "\n",
    "# # we can also generate the full set of pairs (not recommended for large datasets)\n",
    "# no_candidates = no_blocker.materialize()\n",
    "\n",
    "# print(f\"  Generated: {len(no_candidates):,} candidates\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - Creating blocking key values for dataset1: 100000 records\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1Ô∏è‚É£ Standard Blocking (First 3 Characters of Title)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - Creating blocking key values for dataset2: 100323 records\n",
      "[INFO ] PyDI.entitymatching.blocking.standard.StandardBlocking - created 109 blocking keys for first dataset\n",
      "[INFO ] PyDI.entitymatching.blocking.standard.StandardBlocking - created 792 blocking keys for second dataset\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - Joining blocking key values: 109 x 792 blocks\n",
      "[INFO ] PyDI.entitymatching.blocking.standard.StandardBlocking - created 91 blocks from blocking keys\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - Block size distribution:\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - Frequency   Element\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 1           4439400\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 1           1253640\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 1           882428\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 1           802644\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 1           576004\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 1           560032\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 1           544725\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 1           456144\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 1           425784\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 1           405744\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 1           393890\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 1           367584\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 1           350588\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 1           346500\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 1           323724\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 1           286602\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 1           285735\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 1           285576\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 1           280840\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 1           273273\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 1           272650\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 1           265404\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 1           256413\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 1           248694\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 1           237658\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 1           235098\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 1           219364\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 1           218610\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 1           202556\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 1           201292\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 1           196084\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 1           195052\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 1           184275\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 1           167745\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 1           162240\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 1           154622\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 1           154512\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 1           153680\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 1           149796\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 1           148280\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 1           146845\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 1           144980\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 1           144695\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 1           144504\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 1           141245\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 1           140280\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 1           138245\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 1           138212\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 1           131990\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 1           128428\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 1           127908\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 1           123577\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 1           123025\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 1           115188\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 1           112582\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 1           106400\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 1           104935\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 1           96624\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 1           95760\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 1           93960\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 1           88646\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 1           84588\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 1           82902\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 1           69319\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 1           64992\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 1           63900\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 1           63840\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 1           63648\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 1           57460\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 1           57021\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 1           56270\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 1           53805\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 1           36795\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 1           36006\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 1           34320\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 1           33852\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 1           32732\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 1           32487\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 1           32101\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 1           31562\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 1           30060\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 1           29655\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 1           29040\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 1           28767\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 1           26960\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 1           26080\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 1           25662\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 1           24969\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 1           24624\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 1           23580\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 1           18312\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - Blocking key values:\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - BlockingKeyValue\tFrequency\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - The\t\t\t4439400\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - Mar\t\t\t1253640\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - In \t\t\t882428\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - My \t\t\t802644\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - One\t\t\t576004\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - All\t\t\t560032\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - Mon\t\t\t544725\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - Cha\t\t\t456144\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - Ali\t\t\t425784\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - Com\t\t\t405744\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - Sta\t\t\t393890\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - Mis\t\t\t367584\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - Chi\t\t\t350588\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - Ame\t\t\t346500\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - Wal\t\t\t323724\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - To \t\t\t286602\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - Lif\t\t\t285735\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - Mil\t\t\t285576\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - Tra\t\t\t280840\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - Goo\t\t\t273273\n",
      "[INFO ] PyDI.entitymatching.blocking.standard.StandardBlocking - Debug results written to file: output/debugResultsBlocking_StandardBlocking.csv\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - Creating candidate record pairs from 91 blocks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Generated: 21,428,220 candidates\n"
     ]
    }
   ],
   "source": [
    "# 1. Standard Blocking - First 3 characters of title\n",
    "print(\"\\n1Ô∏è‚É£ Standard Blocking (First 3 Characters of Title)\")\n",
    "\n",
    "# Add title_prefix directly to the original dataframes\n",
    "actors['title_prefix'] = actors['title'].astype(str).str[:3]\n",
    "golden_globes['title_prefix'] = golden_globes['title'].astype(str).str[:3]\n",
    "\n",
    "standard_blocker = StandardBlocking(\n",
    "    actors, golden_globes,\n",
    "    on=['title_prefix'],  # Block on first 3 characters of title\n",
    "    batch_size=1000\n",
    ")\n",
    "\n",
    "standard_candidates = standard_blocker.materialize()\n",
    "\n",
    "print()\n",
    "print(f\"  Generated: {len(standard_candidates):,} candidates\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[DEBUG] PyDI.entitymatching.blocking.sorted_neighbourhood.SortedNeighbourhood - Creating sort keys for dataset1: 100000 records\n",
      "[DEBUG] PyDI.entitymatching.blocking.sorted_neighbourhood.SortedNeighbourhood - Creating sort keys for dataset2: 100323 records\n",
      "[DEBUG] PyDI.entitymatching.blocking.sorted_neighbourhood.SortedNeighbourhood - Sorting combined dataset with 200323 records\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2Ô∏è‚É£ Sorted Neighbourhood Blocking (Title-based, Window=5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO ] PyDI.entitymatching.blocking.sorted_neighbourhood.SortedNeighbourhood - created sorted neighbourhood with window size 10\n",
      "[INFO ] PyDI.entitymatching.blocking.sorted_neighbourhood.SortedNeighbourhood - created 1 sorted sequence from 200323 records\n",
      "[INFO ] PyDI.entitymatching.blocking.sorted_neighbourhood.SortedNeighbourhood - Debug results written to file: output/debugResultsBlocking_SortedNeighbourhood.csv\n",
      "[DEBUG] PyDI.entitymatching.blocking.sorted_neighbourhood.SortedNeighbourhood - Creating candidate record pairs from sorted neighbourhood with window 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Generated: 12,540 candidates\n"
     ]
    }
   ],
   "source": [
    "# 2. Sorted Neighbourhood - Sequential similarity\n",
    "print(\"\\n2Ô∏è‚É£ Sorted Neighbourhood Blocking (Title-based, Window=5)\")\n",
    "\n",
    "sn_blocker = SortedNeighbourhood(\n",
    "    actors, golden_globes,\n",
    "    key='title',  # Sort by title\n",
    "    window=10,     # Compare with 5 neighbors\n",
    "    batch_size=1000\n",
    ")\n",
    "\n",
    "sn_candidates = sn_blocker.materialize()\n",
    "\n",
    "print()\n",
    "print(f\"  Generated: {len(sn_candidates):,} candidates\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - Creating token index for dataset1: 100000 records\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3Ô∏è‚É£ Token Blocking (Title Tokens, Min Length=5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - Creating token index for dataset2: 100323 records\n",
      "[INFO ] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - created 178 token keys for first dataset\n",
      "[INFO ] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - created 1776 token keys for second dataset\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - Joining token keys: 178 x 1776 tokens\n",
      "[INFO ] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - created 142 blocks from token keys\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - Token frequency distribution:\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - Frequency   Element\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 3           93660\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 3           39846\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 2           55880\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 2           34320\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 2           32732\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 2           31832\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 2           29788\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 2           26960\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 2           25194\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 2           24624\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           1524900\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           1279152\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           1244970\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           454878\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           357505\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           342540\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           297648\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           282048\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           260434\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           243573\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           228852\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           218790\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           200124\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           199710\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           171196\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           169472\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           164052\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           160625\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           145376\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           131350\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           114375\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           113348\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           106436\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           96726\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           95424\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           92338\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           90720\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           90041\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           87880\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           87490\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           86664\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           86198\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           83790\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           78416\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           76110\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           71280\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           68850\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           68136\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           67176\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           64992\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           64990\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           64224\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           63936\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           62310\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           62280\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           61334\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           60930\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           60515\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           60030\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           58812\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           58551\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           57460\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           57021\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           56932\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           56760\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           56072\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           55900\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           54513\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           52950\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           52920\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           52234\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           46506\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           36920\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           36905\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           36879\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           36795\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           36740\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           35560\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           35139\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           34980\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           33900\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           33852\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           33696\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           33320\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           33075\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           33020\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           32438\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           32130\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           31926\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           31824\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           31776\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           31694\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           31631\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           31584\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           31562\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           31114\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           30774\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           30690\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           30674\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           30314\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           30096\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           29756\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           29744\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           29655\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           29516\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           29316\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           29260\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           29128\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           28996\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           28424\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           28079\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           28056\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           27972\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           27846\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           27634\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           27511\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           26896\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           26880\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           26600\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           26586\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           26080\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           26000\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           25935\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           25662\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           25271\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           24969\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           23580\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           23392\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           21556\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           19410\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - Token values:\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - Token\t\t\tFrequency\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - story\t\t\t1524900\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - woman\t\t\t1279152\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - night\t\t\t1244970\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - heart\t\t\t454878\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - little\t\t\t357505\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - american\t\t\t342540\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - street\t\t\t297648\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - alice\t\t\t282048\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - river\t\t\t260434\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - daughter\t\t\t243573\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - three\t\t\t228852\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - country\t\t\t218790\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - women\t\t\t200124\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - golden\t\t\t199710\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - queen\t\t\t171196\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - goodbye\t\t\t169472\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - coming\t\t\t164052\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - great\t\t\t160625\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - heaven\t\t\t145376\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - field\t\t\t131350\n",
      "[INFO ] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - Debug results written to file: output/debugResultsBlocking_TokenBlocking.csv\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - Creating candidate record pairs from 142 token blocks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Generated: 12,540 candidates\n"
     ]
    }
   ],
   "source": [
    "# 3. Token Blocking - Token-based similarity\n",
    "print(\"\\n3Ô∏è‚É£ Token Blocking (Title Tokens, Min Length=5)\")\n",
    "\n",
    "token_blocker = TokenBlocking(\n",
    "    actors, golden_globes,\n",
    "    column='title',      # Tokenize titles\n",
    "    min_token_len=5,     # Ignore very short tokens\n",
    "    batch_size=1000\n",
    ")\n",
    "\n",
    "token_candidates = token_blocker.materialize()\n",
    "\n",
    "print()\n",
    "print(f\"  Generated: {len(sn_candidates):,} candidates\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO ] PyDI.entitymatching.blocking.embedding.EmbeddingBlocking - Initialized EmbeddingBlocking with sklearn backend, top_k=10, threshold=0.3\n",
      "[DEBUG] PyDI.entitymatching.blocking.embedding.EmbeddingBlocking - Computing embeddings for datasets...\n",
      "[DEBUG] PyDI.entitymatching.blocking.embedding.EmbeddingBlocking - Creating embeddings for dataset1: 100000 records\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4Ô∏è‚É£ Embedding Blocking (Semantic Similarity)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO ] sentence_transformers.SentenceTransformer - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n",
      "[DEBUG] urllib3.connectionpool - Starting new HTTPS connection (1): huggingface.co:443\n",
      "[DEBUG] urllib3.connectionpool - https://huggingface.co:443 \"HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/modules.json HTTP/1.1\" 307 0\n",
      "[DEBUG] urllib3.connectionpool - https://huggingface.co:443 \"HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/modules.json HTTP/1.1\" 200 0\n",
      "[DEBUG] urllib3.connectionpool - https://huggingface.co:443 \"HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config_sentence_transformers.json HTTP/1.1\" 307 0\n",
      "[DEBUG] urllib3.connectionpool - https://huggingface.co:443 \"HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config_sentence_transformers.json HTTP/1.1\" 200 0\n",
      "[DEBUG] urllib3.connectionpool - https://huggingface.co:443 \"HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/README.md HTTP/1.1\" 307 0\n",
      "[DEBUG] urllib3.connectionpool - https://huggingface.co:443 \"HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/README.md HTTP/1.1\" 200 0\n",
      "[DEBUG] urllib3.connectionpool - https://huggingface.co:443 \"HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/modules.json HTTP/1.1\" 307 0\n",
      "[DEBUG] urllib3.connectionpool - https://huggingface.co:443 \"HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/modules.json HTTP/1.1\" 200 0\n",
      "[DEBUG] urllib3.connectionpool - https://huggingface.co:443 \"HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/sentence_bert_config.json HTTP/1.1\" 307 0\n",
      "[DEBUG] urllib3.connectionpool - https://huggingface.co:443 \"HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/sentence_bert_config.json HTTP/1.1\" 200 0\n",
      "[DEBUG] urllib3.connectionpool - https://huggingface.co:443 \"HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1\" 307 0\n",
      "[DEBUG] urllib3.connectionpool - https://huggingface.co:443 \"HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json HTTP/1.1\" 200 0\n",
      "[DEBUG] urllib3.connectionpool - https://huggingface.co:443 \"HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1\" 307 0\n",
      "[DEBUG] urllib3.connectionpool - https://huggingface.co:443 \"HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json HTTP/1.1\" 200 0\n",
      "[DEBUG] urllib3.connectionpool - https://huggingface.co:443 \"GET /api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1\" 404 64\n",
      "[DEBUG] urllib3.connectionpool - https://huggingface.co:443 \"GET /api/models/sentence-transformers/all-MiniLM-L6-v2/revision/main HTTP/1.1\" 200 6861\n",
      "[INFO ] sentence_transformers.SentenceTransformer - Use pytorch device_name: cpu\n",
      "[INFO ] PyDI.entitymatching.blocking.embedding.EmbeddingBlocking - Loaded sentence transformer model: sentence-transformers/all-MiniLM-L6-v2\n",
      "[INFO ] PyDI.entitymatching.blocking.embedding.EmbeddingBlocking - created 384d embeddings for first dataset\n",
      "[DEBUG] PyDI.entitymatching.blocking.embedding.EmbeddingBlocking - Creating embeddings for dataset2: 100323 records\n",
      "[INFO ] PyDI.entitymatching.blocking.embedding.EmbeddingBlocking - created 384d embeddings for second dataset\n",
      "[DEBUG] PyDI.entitymatching.blocking.embedding.EmbeddingBlocking - Building similarity index for 100323 vectors\n",
      "[INFO ] PyDI.entitymatching.blocking.embedding.EmbeddingBlocking - created similarity index with 100323 vectors, metric=cosine\n",
      "[INFO ] PyDI.entitymatching.blocking.embedding.EmbeddingBlocking - Debug results written to file: output/debugResultsBlocking_EmbeddingBlocking.csv\n",
      "[DEBUG] PyDI.entitymatching.blocking.embedding.EmbeddingBlocking - Creating candidate record pairs from embedding similarity with threshold 0.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Generated: 1,000,000 candidates\n"
     ]
    }
   ],
   "source": [
    "# 4. Embedding Blocking - Semantic similarity\n",
    "print(\"\\n4Ô∏è‚É£ Embedding Blocking (Semantic Similarity)\")\n",
    "\n",
    "embedding_blocker = EmbeddingBlocking(\n",
    "    actors, golden_globes,\n",
    "    text_cols=['title'],\n",
    "    model=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    index_backend=\"sklearn\",\n",
    "    top_k=10,          # Top 10 most similar\n",
    "    batch_size=500\n",
    ")\n",
    "    \n",
    "embedding_candidates = embedding_blocker.materialize()\n",
    "\n",
    "print()\n",
    "print(f\"  Generated: {len(embedding_candidates):,} candidates\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Evaluation Against Ground Truth\n",
    "\n",
    "PyDI provides evaluation methods for blocking with pair completeness, pair quality, and reduction ratio:\n",
    "- **`evaluate_blocking()`**: Evaluates blocking  \n",
    "- **`evaluate_matching()`**: Evaluates matching results with precision, recall, F1-score, and accuracy\n",
    "\n",
    "For now, let's evaluate our blocking results against a set of provided ground truth correspondences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO ] PyDI.io.loaders - Loaded dataset 'test_set' via read_csv: shape=(82, 3), source=c:\\Users\\Ralph\\dev\\pydi\\PyDI\\tutorial\\input\\movies\\entitymatching\\actors_2_golden_globes_test.csv\n",
      "[INFO ] root - Blocking evaluation complete: Completeness=0.0000 Quality=0.0000 Reduction=0.9979\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Pair Completeness: 0.000\n",
      "  Pair Quality:      0.000\n",
      "  Reduction Ratio:   0.998\n",
      "  True Matches Found: 0/26\n",
      "\n",
      "üí° Evaluating pair quality only makes sense if the test set contains all possible pairs, which is not the case in this example!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'pair_completeness': 0.0,\n",
       " 'pair_quality': 0.0,\n",
       " 'reduction_ratio': 0.9978633955190396,\n",
       " 'total_candidates': 21428220,\n",
       " 'total_possible_pairs': 10029100000,\n",
       " 'true_positives_found': 0,\n",
       " 'total_true_pairs': 26,\n",
       " 'evaluation_timestamp': '2025-09-11T18:15:03.812163'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from PyDI.io import load_csv\n",
    "from PyDI.entitymatching import EntityMatchingEvaluator\n",
    "# Showcase EntityMatchingEvaluator.evaluate_blocking utility\n",
    "\n",
    "# Load test set with proper _id format\n",
    "test_gt = load_csv(\n",
    "    DATA_DIR / \"entitymatching\" / \"actors_2_golden_globes_test.csv\",\n",
    "    name=\"test_set\", header=None, names=['id1', 'id2', 'label'], add_index=False\n",
    ")\n",
    "\n",
    "# Use EntityMatchingEvaluator.evaluate_blocking on Standard Blocking\n",
    "candidates_df = pd.DataFrame(standard_candidates)\n",
    "total_pairs = len(academy_awards) * len(actors)\n",
    "\n",
    "results = EntityMatchingEvaluator.evaluate_blocking(\n",
    "    candidate_pairs=candidates_df[['id1', 'id2']],\n",
    "    test_pairs=test_gt,\n",
    "    total_possible_pairs=total_pairs\n",
    ")\n",
    "\n",
    "print(f\"\\nüí° Evaluating pair quality only makes sense if the test set contains all possible pairs, which is not the case in this example!\")\n",
    "\n",
    "display(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Selecting Best Blocking Method ===\n",
      "Standard\n",
      "  Pair Completeness: 0.979\n",
      "  Pair Quality:      0.001\n",
      "  Reduction Ratio:   0.950\n",
      "  True Matches Found: 46/47\n",
      "SortedNeighbourhood\n",
      "  Pair Completeness: 0.979\n",
      "  Pair Quality:      0.016\n",
      "  Reduction Ratio:   0.996\n",
      "  True Matches Found: 46/47\n",
      "Token\n",
      "  Pair Completeness: 1.000\n",
      "  Pair Quality:      0.001\n",
      "  Reduction Ratio:   0.890\n",
      "  True Matches Found: 47/47\n",
      "Embedding\n",
      "  Pair Completeness: 1.000\n",
      "  Pair Quality:      0.046\n",
      "  Reduction Ratio:   0.998\n",
      "  True Matches Found: 47/47\n",
      "üìä Blocking Method Comparison:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>Candidates</th>\n",
       "      <th>Completeness</th>\n",
       "      <th>Reduction</th>\n",
       "      <th>Time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Standard</td>\n",
       "      <td>34457</td>\n",
       "      <td>0.979</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SortedNeighbourhood</td>\n",
       "      <td>2906</td>\n",
       "      <td>0.979</td>\n",
       "      <td>0.996</td>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Token</td>\n",
       "      <td>75242</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.890</td>\n",
       "      <td>0.146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Embedding</td>\n",
       "      <td>1030</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.998</td>\n",
       "      <td>3.298</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Method  Candidates Completeness Reduction Time (s)\n",
       "0             Standard       34457        0.979     0.950    0.064\n",
       "1  SortedNeighbourhood        2906        0.979     0.996    0.007\n",
       "2                Token       75242        1.000     0.890    0.146\n",
       "3            Embedding        1030        1.000     0.998    3.298"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üèÜ Best Method: Embedding (Completeness: 1.000, Reduction: 0.998)\n",
      "‚úÖ Using 1,030 candidate pairs for matching\n"
     ]
    }
   ],
   "source": [
    "# Evaluate all blocking methods and select the best one based on highest pair completeness, then highest reduction ratio (if tie)\n",
    "print(\"=== Selecting Best Blocking Method ===\")\n",
    "\n",
    "# Evaluate all blocking strategies\n",
    "blocking_methods = {\n",
    "    'Standard': (standard_candidates, standard_time),\n",
    "    'SortedNeighbourhood': (sn_candidates, sn_time), \n",
    "    'Token': (token_candidates, token_time),\n",
    "    'Embedding': (embedding_candidates, embedding_time)\n",
    "}\n",
    "\n",
    "best_method = None\n",
    "best_completeness = -1\n",
    "best_reduction = -1\n",
    "results_summary = []\n",
    "\n",
    "for method, (candidates, time_taken) in blocking_methods.items():\n",
    "    print(method)\n",
    "    candidates_df = pd.DataFrame(candidates)\n",
    "    eval_results = EntityMatchingEvaluator.evaluate_blocking(\n",
    "        candidate_pairs=candidates_df[['id1', 'id2']],\n",
    "        test_pairs=test_gt,\n",
    "        total_possible_pairs=total_pairs\n",
    "    )\n",
    "    \n",
    "    completeness = eval_results['pair_completeness']\n",
    "    reduction = eval_results['reduction_ratio']\n",
    "    \n",
    "    results_summary.append({\n",
    "        'Method': method,\n",
    "        'Candidates': len(candidates),\n",
    "        'Completeness': f\"{completeness:.3f}\",\n",
    "        'Reduction': f\"{reduction:.3f}\",\n",
    "        'Time (s)': f\"{time_taken:.3f}\"\n",
    "    })\n",
    "    \n",
    "    # Select best: highest completeness, then highest reduction ratio (if tie)\n",
    "    if (completeness > best_completeness or \n",
    "        (completeness == best_completeness and reduction > best_reduction)):\n",
    "        best_completeness = completeness\n",
    "        best_reduction = reduction\n",
    "        best_method = method\n",
    "\n",
    "# Display results\n",
    "print(\"üìä Blocking Method Comparison:\")\n",
    "display(pd.DataFrame(results_summary))\n",
    "\n",
    "# Select best candidates\n",
    "best_candidates = blocking_methods[best_method][0]\n",
    "print(f\"\\nüèÜ Best Method: {best_method} (Completeness: {best_completeness:.3f}, Reduction: {best_reduction:.3f})\")\n",
    "print(f\"‚úÖ Using {len(best_candidates):,} candidate pairs for matching\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Entity Matching with Comparators\n",
    "\n",
    "Now we'll use PyDI's matching capabilities to find duplicate movies using multiple attribute comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparators for different attributes\n",
    "comparators = [\n",
    "    # Title similarity - most important for movies\n",
    "    StringComparator(\n",
    "        column='title',\n",
    "        similarity_function='jaro_winkler',  # Good for movie titles\n",
    "        preprocess=str.lower  # Case normalization\n",
    "    ),\n",
    "    \n",
    "    # Date proximity - movies from same year likely same film\n",
    "    DateComparator(\n",
    "        column='date', \n",
    "        max_days_difference=365  # Allow 1 year difference\n",
    "    ),\n",
    "    \n",
    "    # Actor name similarity - supporting evidence\n",
    "    StringComparator(\n",
    "        column='actor_name',\n",
    "        similarity_function='cosine',  # Good for names\n",
    "        preprocess=str.lower\n",
    "    )\n",
    "]\n",
    "\n",
    "# Define attribute weights\n",
    "weights = [0.6, 0.25, 0.15]  # Title most important, then date, then actor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Performing Entity Matching ===\n",
      "Candidate pairs to evaluate: 1,030\n",
      "Applying multi-attribute matching rules with threshold 0.7...\n",
      "\n",
      "Found 114 matches in 0.489 seconds\n"
     ]
    }
   ],
   "source": [
    "# Initialize Rule-Based Matcher\n",
    "matcher = RuleBasedMatcher()\n",
    "\n",
    "print(\"\\n=== Performing Entity Matching ===\")\n",
    "print(f\"Candidate pairs to evaluate: {len(best_candidates):,}\")\n",
    "print(\"Applying multi-attribute matching rules with threshold 0.7...\\n\")\n",
    "\n",
    "candidates_df = pd.DataFrame(best_candidates)\n",
    "\n",
    "# Perform matching with threshold 0.7\n",
    "start_time = time.time()\n",
    "\n",
    "matches = matcher.match(\n",
    "    df_left=left_df,\n",
    "    df_right=right_df, \n",
    "    candidates=[candidates_df],\n",
    "    comparators=comparators,\n",
    "    weights=weights,\n",
    "    threshold=0.7\n",
    ")\n",
    "\n",
    "matching_time = time.time() - start_time\n",
    "\n",
    "print(f\"Found {len(matches):,} matches in {matching_time:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Evaluation Against Ground Truth ===\n",
      "Loading Winter framework's ground truth correspondences...\n",
      "\n",
      "Training ground truth: 335 pairs\n",
      "Test ground truth: 3,347 pairs\n",
      "Training set: 103 positive matches out of 335 pairs (30.7%)\n",
      "Test set: 47 positive matches out of 3,347 pairs (1.4%)\n",
      "\n",
      "üéØ We'll evaluate against the test set (3,347 pairs)\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Evaluation Against Ground Truth ===\")\n",
    "print(\"Loading Winter framework's ground truth correspondences...\\n\")\n",
    "\n",
    "# Load ground truth correspondences\n",
    "gt_train = load_csv(\n",
    "    DATA_DIR / \"entitymatching\" / \"splits\" / \"academy_awards_2_actors_training.csv\",\n",
    "    name=\"ground_truth_train\",\n",
    "    header=None,\n",
    "    names=['id1', 'id2', 'label'],\n",
    "    add_index=False\n",
    ")\n",
    "\n",
    "gt_test = load_csv(\n",
    "    DATA_DIR / \"entitymatching\" / \"splits\" / \"academy_awards_2_actors_test.csv\", \n",
    "    name=\"ground_truth_test\",\n",
    "    header=None,\n",
    "    names=['id1', 'id2', 'label'],\n",
    "    add_index=False\n",
    ")\n",
    "\n",
    "print(f\"Training ground truth: {len(gt_train):,} pairs\")\n",
    "print(f\"Test ground truth: {len(gt_test):,} pairs\")\n",
    "\n",
    "# Analyze label distribution\n",
    "for name, gt in [('Training', gt_train), ('Test', gt_test)]:\n",
    "    true_matches = (gt['label'] == 'TRUE').sum() if 'TRUE' in gt['label'].values else (gt['label'] == True).sum()\n",
    "    total = len(gt)\n",
    "    print(f\"{name} set: {true_matches:,} positive matches out of {total:,} pairs ({true_matches/total*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nüéØ We'll evaluate against the test set ({len(gt_test):,} pairs)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Entity Matching Evaluation Results ===\n",
      "Performance Metrics:\n",
      "  Accuracy:  0.976\n",
      "  Precision: 0.342\n",
      "  Recall:    0.830\n",
      "  F1-Score:  0.484\n",
      "Confusion Matrix:\n",
      "  True Positives:  39\n",
      "  True Negatives:  3299\n",
      "  False Positives: 75\n",
      "  False Negatives: 8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'precision': 0.34210526315789475,\n",
       " 'recall': 0.8297872340425532,\n",
       " 'f1': 0.484472049689441,\n",
       " 'accuracy': 0.9757380882782812,\n",
       " 'true_positives': 39,\n",
       " 'false_positives': 75,\n",
       " 'false_negatives': 8,\n",
       " 'true_negatives': 3299,\n",
       " 'threshold_used': 0.0,\n",
       " 'total_correspondences': 114,\n",
       " 'filtered_correspondences': 114,\n",
       " 'evaluation_timestamp': '2025-09-09T15:12:55.279738',\n",
       " 'output_files': ['c:\\\\Users\\\\Ralph\\\\dev\\\\pydi\\\\output\\\\tutorial\\\\matching_evaluation_summary.json',\n",
       "  'c:\\\\Users\\\\Ralph\\\\dev\\\\pydi\\\\output\\\\tutorial\\\\matching_detailed_results.csv']}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Perform evaluation using PyDI's EntityMatchingEvaluator\n",
    "print(\"\\n=== Entity Matching Evaluation Results ===\")\n",
    "\n",
    "# Use the new evaluate_matching method for cleaner evaluation\n",
    "eval_results = EntityMatchingEvaluator.evaluate_matching(\n",
    "    correspondences=matches,\n",
    "    test_pairs=gt_test,\n",
    "    out_dir=str(OUTPUT_DIR)\n",
    ")\n",
    "\n",
    "display(eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Re-running matcher with debug mode to capture detailed results:\n",
      "  Using 1030 actual candidate pairs from Embedding blocking\n",
      "  Found 114 matches in 0.514 seconds with debug enabled\n",
      "  ‚úÖ Full debug results: debugResultsMatchingRule.csv\n",
      "  ‚úÖ Short debug results: debugResultsMatchingRule.csv_short\n",
      "üìÅ Debug files saved to: c:\\Users\\Ralph\\dev\\pydi\\output\\tutorial\\debug_results\n"
     ]
    }
   ],
   "source": [
    "# Re-run the matcher with debug mode enabled to get detailed debug data\n",
    "print(\"üîç Re-running matcher with debug mode to capture detailed results:\")\n",
    "\n",
    "# Use the same candidates and settings from before\n",
    "candidates_df = pd.DataFrame(best_candidates)\n",
    "print(f\"  Using {len(candidates_df)} actual candidate pairs from {best_method} blocking\")\n",
    "\n",
    "# Re-run matching with debug enabled to capture detailed comparator results\n",
    "start_time = time.time()\n",
    "\n",
    "# Enable debug mode in the matcher to capture detailed results\n",
    "matches, debug_info = matcher.match(\n",
    "    df_left=left_df,\n",
    "    df_right=right_df, \n",
    "    candidates=[candidates_df],\n",
    "    comparators=comparators,\n",
    "    weights=weights,\n",
    "    threshold=0.7,\n",
    "    debug=True  # This enables debug output capture\n",
    ")\n",
    "\n",
    "matching_time = time.time() - start_time\n",
    "print(f\"  Found {len(matches)} matches in {matching_time:.3f} seconds with debug enabled\")\n",
    "\n",
    "debug_output_dir = OUTPUT_DIR / \"debug_results\"\n",
    "debug_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Call the write_debug_results function with actual results\n",
    "full_debug_path, short_debug_path = EntityMatchingEvaluator.write_debug_results(\n",
    "    correspondences=matches,\n",
    "    debug_results=debug_info,\n",
    "    out_dir=str(debug_output_dir),\n",
    "    matcher_instance=matcher\n",
    ")\n",
    "\n",
    "print(f\"  ‚úÖ Full debug results: {Path(full_debug_path).name}\")\n",
    "print(f\"  ‚úÖ Short debug results: {Path(short_debug_path).name}\")\n",
    "\n",
    "print(f\"üìÅ Debug files saved to: {debug_output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Demonstrating Cluster Size Distribution Analysis ===\n",
      "Analyzing cluster size distribution in our entity matching results...\n",
      "\n",
      "üìä Cluster Size Distribution Results:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster_size</th>\n",
       "      <th>frequency</th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>110</td>\n",
       "      <td>98.214286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1.785714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cluster_size  frequency  percentage\n",
       "0             2        110   98.214286\n",
       "1             3          2    1.785714"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"=== Demonstrating Cluster Size Distribution Analysis ===\")\n",
    "print(\"Analyzing cluster size distribution in our entity matching results...\")\n",
    "\n",
    "# Create cluster size distribution from our matches\n",
    "cluster_distribution = EntityMatchingEvaluator.create_cluster_size_distribution(\n",
    "    correspondences=matches,\n",
    "    out_dir=str(OUTPUT_DIR / \"cluster_analysis\")\n",
    ")\n",
    "\n",
    "print(f\"\\nüìä Cluster Size Distribution Results:\")\n",
    "display(cluster_distribution)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write out detailed cluster information with all entity records for debugging purposes\n",
    "\n",
    "# Use the matches we found earlier to demonstrate cluster details\n",
    "cluster_details_path = OUTPUT_DIR / \"cluster_analysis\" / \"detailed_cluster_info.json\"\n",
    "cluster_details_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Call write_cluster_details with our entity matches\n",
    "output_path = EntityMatchingEvaluator.write_cluster_details(\n",
    "    correspondences=matches,\n",
    "    out_path=str(cluster_details_path)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Machine Learning-based Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ML-Based Matching with Similarity Features ===\n",
      "Demonstrating MLBasedMatcher with FeatureExtractor using GridSearchCV\n",
      "Training on gt_train and testing on gt_test\n",
      "\n",
      "\n",
      "üîß Creating Similarity-Based FeatureExtractor...\n",
      "‚úÖ Created FeatureExtractor with 7 similarity features\n",
      "Feature names: ['StringComparator(title, jaro_winkler)', 'StringComparator(title, levenshtein)', 'StringComparator(title, cosine)', 'StringComparator(title, jaccard)', 'DateComparator(date)', 'StringComparator(actor_name, jaro_winkler)', 'StringComparator(actor_name, cosine)']\n",
      "\n",
      "‚öôÔ∏è Extracting Features from Training Pairs...\n",
      "Valid training pairs: 335 out of 335\n",
      "‚úÖ Training features extracted: (335, 10)\n",
      "Feature columns: ['StringComparator(title, jaro_winkler)', 'StringComparator(title, levenshtein)', 'StringComparator(title, cosine)', 'StringComparator(title, jaccard)', 'DateComparator(date)', 'StringComparator(actor_name, jaro_winkler)', 'StringComparator(actor_name, cosine)']\n",
      "Training data: X=(335, 7), y=(335,)\n",
      "Class distribution: {0: 232, 1: 103}\n"
     ]
    }
   ],
   "source": [
    "print(\"=== ML-Based Matching with Similarity Features ===\")\n",
    "print(\"Demonstrating MLBasedMatcher with FeatureExtractor using GridSearchCV\")\n",
    "print(\"Training on gt_train and testing on gt_test\\n\")\n",
    "\n",
    "# Convert string labels to numeric\n",
    "gt_train['label'] = gt_train['label'].map({'TRUE': 1, 'FALSE': 0, True: 1, False: 0})\n",
    "gt_test['label'] = gt_test['label'].map({'TRUE': 1, 'FALSE': 0, True: 1, False: 0})\n",
    "\n",
    "# Create similarity-based FeatureExtractor \n",
    "print(\"\\nüîß Creating Similarity-Based FeatureExtractor...\")\n",
    "\n",
    "similarity_comparators = [\n",
    "    # Title similarity features - most important for movie matching\n",
    "    StringComparator(\"title\", similarity_function=\"jaro_winkler\", preprocess=str.lower),\n",
    "    StringComparator(\"title\", similarity_function=\"levenshtein\", preprocess=str.lower),\n",
    "    StringComparator(\"title\", similarity_function=\"cosine\", preprocess=str.lower),\n",
    "    StringComparator(\"title\", similarity_function=\"jaccard\", preprocess=str.lower),\n",
    "    \n",
    "    # Date proximity features\n",
    "    DateComparator(\"date\", max_days_difference=730),  # 2 years tolerance\n",
    "    \n",
    "    # Actor name similarity\n",
    "    StringComparator(\"actor_name\", similarity_function=\"jaro_winkler\", preprocess=str.lower),\n",
    "    StringComparator(\"actor_name\", similarity_function=\"cosine\", preprocess=str.lower),\n",
    "]\n",
    "\n",
    "feature_extractor = FeatureExtractor(similarity_comparators)\n",
    "print(f\"‚úÖ Created FeatureExtractor with {len(similarity_comparators)} similarity features\")\n",
    "print(f\"Feature names: {feature_extractor.get_feature_names()}\")\n",
    "\n",
    "# Extract training features\n",
    "print(f\"\\n‚öôÔ∏è Extracting Features from Training Pairs...\")\n",
    "\n",
    "# Filter training pairs to ensure both records exist\n",
    "valid_train_pairs = []\n",
    "valid_train_labels = []\n",
    "\n",
    "for _, row in gt_train.iterrows():\n",
    "    id1, id2, label = row['id1'], row['id2'], row['label']\n",
    "    if (id1 in left_df['_id'].values and id2 in right_df['_id'].values):\n",
    "        valid_train_pairs.append({'id1': id1, 'id2': id2})\n",
    "        valid_train_labels.append(label)\n",
    "\n",
    "train_pairs_df = pd.DataFrame(valid_train_pairs)\n",
    "train_labels_series = pd.Series(valid_train_labels)\n",
    "\n",
    "print(f\"Valid training pairs: {len(train_pairs_df)} out of {len(gt_train)}\")\n",
    "\n",
    "# Extract features using FeatureExtractor\n",
    "train_features = feature_extractor.create_features(\n",
    "    left_df, right_df, train_pairs_df, labels=train_labels_series\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Training features extracted: {train_features.shape}\")\n",
    "print(f\"Feature columns: {[col for col in train_features.columns if col not in ['id1', 'id2', 'label']]}\")\n",
    "\n",
    "# Prepare data for ML training\n",
    "feature_columns = [col for col in train_features.columns if col not in ['id1', 'id2', 'label']]\n",
    "\n",
    "X_train = train_features[feature_columns]\n",
    "y_train = train_features['label']\n",
    "\n",
    "print(f\"Training data: X={X_train.shape}, y={y_train.shape}\")\n",
    "print(f\"Class distribution: {y_train.value_counts().to_dict()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Full Scikit-learn integration\n",
    "\n",
    "From here on out, the full scikit-learn library can be used with the features extracted from PyDIs feature extractor without any wrapping as everything in PyDI is based on pandas dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Setting up GridSearchCV...\n",
      "GridSearch setup: 4 models, F1 scoring, 5-fold CV\n",
      "\n",
      "üöÄ Training Models with GridSearchCV...\n",
      "\n",
      "Training RandomForest...\n",
      "  ‚úÖ RandomForest: Best CV F1 = 0.9853\n",
      "     Best params: {'class_weight': 'balanced', 'max_depth': 5, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "\n",
      "Training LogisticRegression...\n",
      "  ‚úÖ LogisticRegression: Best CV F1 = 0.9953\n",
      "     Best params: {'C': 1.0, 'class_weight': 'balanced', 'penalty': 'l2'}\n",
      "\n",
      "Training GradientBoosting...\n",
      "  ‚úÖ GradientBoosting: Best CV F1 = 0.9953\n",
      "     Best params: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100}\n",
      "\n",
      "Training SVM...\n",
      "  ‚úÖ SVM: Best CV F1 = 0.9953\n",
      "     Best params: {'C': 0.1, 'class_weight': 'balanced', 'kernel': 'rbf'}\n",
      "\n",
      "üèÜ Best Overall Model: LogisticRegression (CV F1: 0.9953)\n"
     ]
    }
   ],
   "source": [
    "# Set up GridSearchCV with multiple models and hyperparameters\n",
    "print(f\"\\nüîç Setting up GridSearchCV...\")\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "\n",
    "# Define models and parameter grids\n",
    "param_grids = {\n",
    "    'RandomForest': {\n",
    "        'model': RandomForestClassifier(random_state=42),\n",
    "        'params': {\n",
    "            'n_estimators': [50, 100, 200],\n",
    "            'max_depth': [5, 10, None],\n",
    "            'min_samples_split': [2, 5],\n",
    "            'class_weight': ['balanced', None]\n",
    "        }\n",
    "    },\n",
    "    'LogisticRegression': {\n",
    "        'model': LogisticRegression(random_state=42, max_iter=1000),\n",
    "        'params': {\n",
    "            'C': [0.1, 1.0, 10.0],\n",
    "            'penalty': ['l2'],\n",
    "            'class_weight': ['balanced', None]\n",
    "        }\n",
    "    },\n",
    "    'GradientBoosting': {\n",
    "        'model': GradientBoostingClassifier(random_state=42),\n",
    "        'params': {\n",
    "            'n_estimators': [50, 100],\n",
    "            'learning_rate': [0.1, 0.2],\n",
    "            'max_depth': [3, 5],\n",
    "        }\n",
    "    },\n",
    "    'SVM': {\n",
    "        'model': SVC(random_state=42, probability=True),\n",
    "        'params': {\n",
    "            'C': [0.1, 1.0, 10.0],\n",
    "            'kernel': ['rbf', 'linear'],\n",
    "            'class_weight': ['balanced', None]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Use F1 score as the scoring metric (good for imbalanced data)\n",
    "scorer = make_scorer(f1_score)\n",
    "cv_folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "print(f\"GridSearch setup: {len(param_grids)} models, F1 scoring, 5-fold CV\")\n",
    "\n",
    "# Train models using GridSearchCV\n",
    "print(f\"\\nüöÄ Training Models with GridSearchCV...\")\n",
    "\n",
    "grid_search_results = {}\n",
    "best_overall_score = -1\n",
    "best_overall_model = None\n",
    "best_model_name = None\n",
    "\n",
    "for model_name, config in param_grids.items():\n",
    "    print(f\"\\nTraining {model_name}...\")\n",
    "    \n",
    "\n",
    "    # Create GridSearchCV\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=config['model'],\n",
    "        param_grid=config['params'],\n",
    "        scoring=scorer,\n",
    "        cv=cv_folds,\n",
    "        n_jobs=-1,  # Use all available cores\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    # Fit GridSearchCV\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Store results\n",
    "    grid_search_results[model_name] = {\n",
    "        'grid_search': grid_search,\n",
    "        'best_score': grid_search.best_score_,\n",
    "        'best_params': grid_search.best_params_,\n",
    "        'best_estimator': grid_search.best_estimator_\n",
    "    }\n",
    "    \n",
    "    print(f\"  ‚úÖ {model_name}: Best CV F1 = {grid_search.best_score_:.4f}\")\n",
    "    print(f\"     Best params: {grid_search.best_params_}\")\n",
    "    \n",
    "    # Track overall best model\n",
    "    if grid_search.best_score_ > best_overall_score:\n",
    "        best_overall_score = grid_search.best_score_\n",
    "        best_overall_model = grid_search.best_estimator_\n",
    "        best_model_name = model_name\n",
    "            \n",
    "print(f\"\\nüèÜ Best Overall Model: {best_model_name} (CV F1: {best_overall_score:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéØ Testing Best Model on Test Set...\n",
      "Valid test pairs: 3347 out of 3347\n"
     ]
    }
   ],
   "source": [
    "# Apply best trained model using MLBasedMatcher on test data\n",
    "print(f\"\\nüéØ Testing Best Model on Test Set...\")\n",
    "\n",
    "\n",
    "# Prepare test pairs\n",
    "valid_test_pairs = []\n",
    "valid_test_labels = []\n",
    "\n",
    "for _, row in gt_test.iterrows():\n",
    "    id1, id2, label = row['id1'], row['id2'], row['label']\n",
    "    if (id1 in left_df['_id'].values and id2 in right_df['_id'].values):\n",
    "        valid_test_pairs.append({'id1': id1, 'id2': id2})\n",
    "        valid_test_labels.append(label)\n",
    "\n",
    "test_pairs_df = pd.DataFrame(valid_test_pairs)\n",
    "test_labels_series = pd.Series(valid_test_labels)\n",
    "\n",
    "print(f\"Valid test pairs: {len(test_pairs_df)} out of {len(gt_test)}\")\n",
    "\n",
    "\n",
    "# Create MLBasedMatcher and apply trained model\n",
    "ml_matcher = MLBasedMatcher(feature_extractor)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "matches = ml_matcher.match(\n",
    "    left_df, right_df, [test_pairs_df], best_overall_model\n",
    ")\n",
    "\n",
    "# Show feature importance if available\n",
    "if hasattr(best_overall_model, 'feature_importances_'):\n",
    "    print(f\"\\nüîç Top Feature Importances:\")\n",
    "    importance_df = ml_matcher.get_feature_importance(best_overall_model, feature_columns)\n",
    "    display(importance_df.head(8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's evaluate the ML-based matching with the evaluator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ML-based Entity Matching Evaluation Results ===\n",
      "Performance Metrics:\n",
      "  Accuracy:  0.998\n",
      "  Precision: 0.870\n",
      "  Recall:    1.000\n",
      "  F1-Score:  0.931\n",
      "Confusion Matrix:\n",
      "  True Positives:  47\n",
      "  True Negatives:  3293\n",
      "  False Positives: 7\n",
      "  False Negatives: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'precision': 0.8703703703703703,\n",
       " 'recall': 1.0,\n",
       " 'f1': 0.9306930693069307,\n",
       " 'accuracy': 0.9979085748431431,\n",
       " 'true_positives': 47,\n",
       " 'false_positives': 7,\n",
       " 'false_negatives': 0,\n",
       " 'true_negatives': 3293,\n",
       " 'threshold_used': 0.0,\n",
       " 'total_correspondences': 54,\n",
       " 'filtered_correspondences': 54,\n",
       " 'evaluation_timestamp': '2025-09-09T15:13:01.824437',\n",
       " 'output_files': ['c:\\\\Users\\\\Ralph\\\\dev\\\\pydi\\\\output\\\\tutorial\\\\matching_evaluation_summary.json',\n",
       "  'c:\\\\Users\\\\Ralph\\\\dev\\\\pydi\\\\output\\\\tutorial\\\\matching_detailed_results.csv']}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Cluster Size Distribution Analysis ===\n",
      "\n",
      "üìä Cluster Size Distribution Results:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster_size</th>\n",
       "      <th>frequency</th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>48</td>\n",
       "      <td>94.117647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5.882353</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cluster_size  frequency  percentage\n",
       "0             2         48   94.117647\n",
       "1             3          3    5.882353"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Perform evaluation using PyDI's EntityMatchingEvaluator\n",
    "print(\"\\n=== ML-based Entity Matching Evaluation Results ===\")\n",
    "\n",
    "# Use the new evaluate_matching method for cleaner evaluation\n",
    "eval_results = EntityMatchingEvaluator.evaluate_matching(\n",
    "    correspondences=matches,\n",
    "    test_pairs=gt_test,\n",
    "    out_dir=str(OUTPUT_DIR)\n",
    ")\n",
    "\n",
    "display(eval_results)\n",
    "\n",
    "print(\"=== Cluster Size Distribution Analysis ===\")\n",
    "\n",
    "# Create cluster size distribution from our matches\n",
    "cluster_distribution = EntityMatchingEvaluator.create_cluster_size_distribution(\n",
    "    correspondences=matches,\n",
    "    out_dir=str(OUTPUT_DIR / \"cluster_analysis\")\n",
    ")\n",
    "\n",
    "print(f\"\\nüìä Cluster Size Distribution Results:\")\n",
    "display(cluster_distribution)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively to similarity metrics for each attribute, PyDIs VectorFeatureExtractor can be used to create embeddings using SentenceTransformers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SentenceTransformer features shape: (1030, 3)\n"
     ]
    }
   ],
   "source": [
    "# VectorFeatureExtractor Examples\n",
    "\n",
    "from PyDI.entitymatching import VectorFeatureExtractor\n",
    "\n",
    "# SentenceTransformers embeddings using VectorFeatureExtractor\n",
    "st_extractor = VectorFeatureExtractor(\n",
    "    embedding_model='sentence-transformers/all-MiniLM-L6-v2',\n",
    "    columns=['title', 'actor_name', 'date'],\n",
    "    distance_metrics=['cosine'],\n",
    "    pooling_strategy='concatenate'\n",
    ")\n",
    "\n",
    "st_features = st_extractor.create_features(\n",
    "    left_df, right_df, candidates_df\n",
    ")\n",
    "print(f\"SentenceTransformer features shape: {st_features.shape}\")\n",
    "\n",
    "# Extract features using FeatureExtractor\n",
    "train_features = feature_extractor.create_features(\n",
    "    left_df, right_df, train_pairs_df, labels=train_labels_series\n",
    ")\n",
    "\n",
    "# ready to train ML models with scikit-learn as before\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Data Fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Fusion Input Datasets:\n",
      "  Academy Awards: 4,592 records\n",
      "  Actors: 149 records\n",
      "  Golden Globes: 2,286 records\n",
      "  Total: 7,027 records\n",
      "\n",
      "üéØ Goal: Create single authoritative movie record per entity\n"
     ]
    }
   ],
   "source": [
    "print(\"üìä Fusion Input Datasets:\")\n",
    "for df, name in zip(datasets, names):\n",
    "    print(f\"  {name}: {len(df):,} records\")\n",
    "\n",
    "total_input_records = sum(len(df) for df in datasets)\n",
    "print(f\"  Total: {total_input_records:,} records\")\n",
    "print(f\"\\nüéØ Goal: Create single authoritative movie record per entity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Loading Correspondence Files\n",
    "\n",
    "Data fusion requires correspondence information to group records referring to the same entity. Let's load the pre-computed correspondences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Loading Correspondences for Data Fusion ===\n",
      "Academy Awards ‚Üî Actors correspondences: 150\n",
      "Actors ‚Üî Golden Globes correspondences: 107\n",
      "\n",
      "üìä Correspondence Structure:\n",
      "Academy Awards ‚Üî Actors:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id1</th>\n",
       "      <th>id2</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>academy_awards_4557</td>\n",
       "      <td>actors_1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>academy_awards_4529</td>\n",
       "      <td>actors_2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>academy_awards_4500</td>\n",
       "      <td>actors_3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>academy_awards_4475</td>\n",
       "      <td>actors_4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>academy_awards_4446</td>\n",
       "      <td>actors_5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id1       id2  score\n",
       "0  academy_awards_4557  actors_1    1.0\n",
       "1  academy_awards_4529  actors_2    1.0\n",
       "2  academy_awards_4500  actors_3    1.0\n",
       "3  academy_awards_4475  actors_4    1.0\n",
       "4  academy_awards_4446  actors_5    1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actors ‚Üî Golden Globes:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id1</th>\n",
       "      <th>id2</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>actors_16</td>\n",
       "      <td>golden_globes_2279</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>actors_22</td>\n",
       "      <td>golden_globes_2263</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>actors_23</td>\n",
       "      <td>golden_globes_2252</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>actors_24</td>\n",
       "      <td>golden_globes_2240</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>actors_25</td>\n",
       "      <td>golden_globes_2226</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id1                 id2  score\n",
       "0  actors_16  golden_globes_2279    1.0\n",
       "1  actors_22  golden_globes_2263    1.0\n",
       "2  actors_23  golden_globes_2252    1.0\n",
       "3  actors_24  golden_globes_2240    1.0\n",
       "4  actors_25  golden_globes_2226    1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load pre-computed correspondences from the Winter framework\n",
    "print(\"=== Loading Correspondences for Data Fusion ===\")\n",
    "\n",
    "CORR_DIR = ROOT / \"input\" / \"movies\" / \"fusion\" / \"correspondences\"\n",
    "\n",
    "# Load correspondence files\n",
    "academy_actors_corr = load_csv(\n",
    "    CORR_DIR / \"academy_awards_2_actors_correspondences.csv\",\n",
    "    name=\"academy_actors_correspondences\",\n",
    "    header=None,\n",
    "    names=['id1', 'id2', 'score'],\n",
    "    add_index=False\n",
    ")\n",
    "\n",
    "actors_globes_corr = load_csv(\n",
    "    CORR_DIR / \"actors_2_golden_globes_correspondences.csv\", \n",
    "    name=\"actors_globes_correspondences\",\n",
    "    header=None,\n",
    "    names=['id1', 'id2', 'score'],\n",
    "    add_index=False\n",
    ")\n",
    "\n",
    "print(f\"Academy Awards ‚Üî Actors correspondences: {len(academy_actors_corr):,}\")\n",
    "print(f\"Actors ‚Üî Golden Globes correspondences: {len(actors_globes_corr):,}\")\n",
    "\n",
    "# Preview correspondence structure\n",
    "print(\"\\nüìä Correspondence Structure:\")\n",
    "print(\"Academy Awards ‚Üî Actors:\")\n",
    "display(academy_actors_corr.head())\n",
    "\n",
    "print(\"Actors ‚Üî Golden Globes:\")\n",
    "display(actors_globes_corr.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Running Fusion using correspondences to build record groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total correspondences: 257\n"
     ]
    }
   ],
   "source": [
    "# Combine all correspondences into a single list\n",
    "all_correspondences = []\n",
    "\n",
    "# Add Academy Awards ‚Üî Actors correspondences\n",
    "for _, row in academy_actors_corr.iterrows():\n",
    "    all_correspondences.append((row['id1'], row['id2'], row['score']))\n",
    "    \n",
    "# Add Actors ‚Üî Golden Globes correspondences  \n",
    "for _, row in actors_globes_corr.iterrows():\n",
    "    all_correspondences.append((row['id1'], row['id2'], row['score']))\n",
    "\n",
    "all_correspondences = pd.DataFrame(all_correspondences, columns=['id1', 'id2', 'score'])\n",
    "\n",
    "print(f\"Total correspondences: {len(all_correspondences):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PyDI Data Fusion Framework Demonstration ===\n",
      "\n",
      "‚úÖ Strategy 'movie_fusion' configured with 6 rules\n"
     ]
    }
   ],
   "source": [
    "print(\"=== PyDI Data Fusion Framework Demonstration ===\")\n",
    "\n",
    "# Import additional fusion components needed\n",
    "from PyDI.fusion import AttributeValueFuser\n",
    "\n",
    "# Initialize the fusion strategy\n",
    "fusion_strategy = DataFusionStrategy(\"movie_fusion\")\n",
    "\n",
    "# Title: Use longest string (often more complete)\n",
    "fusion_strategy.add_attribute_fuser(\"title\", AttributeValueFuser(longest_string))\n",
    "\n",
    "# Date: Use most recent (latest data often more accurate)\n",
    "fusion_strategy.add_attribute_fuser(\"date\", AttributeValueFuser(most_recent))\n",
    "\n",
    "# Actor name: Use most complete (non-null, longest)\n",
    "fusion_strategy.add_attribute_fuser(\"actor_name\", AttributeValueFuser(most_complete))\n",
    "\n",
    "# Director name: Use longest string\n",
    "fusion_strategy.add_attribute_fuser(\"director_name\", AttributeValueFuser(longest_string))\n",
    "\n",
    "# Awards: Union all award information\n",
    "fusion_strategy.add_attribute_fuser(\"oscar\", AttributeValueFuser(union))\n",
    "fusion_strategy.add_attribute_fuser(\"globe\", AttributeValueFuser(union))\n",
    "\n",
    "print(f\"\\n‚úÖ Strategy '{fusion_strategy.name}' configured with {len(fusion_strategy.get_registered_attributes())} rules\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input datasets: 3\n",
      "Input records: 7,027\n",
      "Correspondences: 257\n",
      "\n",
      "‚úÖ Fusion Complete!\n",
      "  Total time: 0.287 seconds\n",
      "  Output records: 6,755\n",
      "  Compression ratio: 96.1%\n"
     ]
    }
   ],
   "source": [
    "# Create fusion engine with our strategy\n",
    "fusion_engine = DataFusionEngine(fusion_strategy)\n",
    "\n",
    "print(f\"Input datasets: {len(datasets)}\")\n",
    "print(f\"Input records: {total_input_records:,}\")\n",
    "print(f\"Correspondences: {len(all_correspondences):,}\")\n",
    "\n",
    "# Execute fusion with timing\n",
    "start_time = time.time()\n",
    "\n",
    "fused_dataset, execution_time = fusion_engine.run(\n",
    "    datasets=datasets,\n",
    "    correspondences=all_correspondences, \n",
    "    id_column='id',  # Use original 'id' column for matching\n",
    "    include_singletons=True  # Include unmatched records\n",
    ")\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\n‚úÖ Fusion Complete!\")\n",
    "print(f\"  Total time: {total_time:.3f} seconds\") \n",
    "print(f\"  Output records: {len(fused_dataset):,}\")\n",
    "print(f\"  Compression ratio: {len(fused_dataset)/total_input_records:.1%}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pydi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
