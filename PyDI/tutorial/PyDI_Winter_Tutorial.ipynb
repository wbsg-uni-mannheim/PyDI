{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyDI Data Integration Tutorial\n",
    "\n",
    "This tutorial demonstrates comprehensive data integration using PyDI. We'll work with movie datasets to showcase the data integration pipeline from entity matching to Data Fusion.\n",
    "\n",
    "### What You'll Learn\n",
    "\n",
    "1. **Data Loading & Profiling**: Load and analyze movie datasets with provenance tracking\n",
    "2. **Identity Resolution**: \n",
    "   - Blocking strategies (Standard, Sorted Neighbourhood, Token-based, Embedding-based)\n",
    "   - Multi-attribute similarity matching with custom comparators\n",
    "   - Machine learning-based entity matching\n",
    "3. **Data Fusion**: \n",
    "   - Conflict resolution with custom fusion rules\n",
    "   - Quality assessment against test set\n",
    "   - Provenance-based conflict resolution\n",
    "\n",
    "### Datasets\n",
    "\n",
    "We'll use three movie datasets:\n",
    "- **Academy Awards**: Movies with Oscar information (4,592 records)\n",
    "- **Actors**: Movies with actor details (149 records) \n",
    "- **Golden Globes**: Movies with Golden Globe awards (2,286 records)\n",
    "\n",
    "These datasets contain overlapping movie information but with different attributes, data quality issues, and conflicting values - perfect for demonstrating real-world data integration challenges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Core Python libraries\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import logging\n",
    "# import time\n",
    "# import json\n",
    "# from datetime import datetime\n",
    "\n",
    "# # PyDI imports for data loading and profiling\n",
    "\n",
    "# # PyDI imports for entity matching\n",
    "# from PyDI.entitymatching import (\n",
    "#     # Blocking strategies\n",
    "#     NoBlocking, StandardBlocking, SortedNeighbourhood, \n",
    "#     TokenBlocking, EmbeddingBlocking,\n",
    "#     # Matchers\n",
    "#     RuleBasedMatcher, MLBasedMatcher,\n",
    "#     # Feature extraction for ML\n",
    "#     FeatureExtractor,\n",
    "#     # Comparators\n",
    "#     StringComparator, DateComparator, NumericComparator,\n",
    "#     # Evaluation - NEW: Separate methods for blocking and matching evaluation\n",
    "#     EntityMatchingEvaluator,\n",
    "#     # Utilities\n",
    "#     ensure_record_ids\n",
    "# )\n",
    "\n",
    "# # PyDI imports for data fusion\n",
    "# from PyDI.fusion import (\n",
    "#     DataFusionEngine, DataFusionStrategy, DataFusionEvaluator,\n",
    "#     # Fusion rules\n",
    "#     longest_string, shortest_string, most_recent, earliest,\n",
    "#     average, median, maximum, minimum, most_complete,\n",
    "#     union, intersection, voting,\n",
    "#     # Convenient aliases\n",
    "#     LONGEST, SHORTEST, LATEST, EARLIEST, AVG, MAX, MIN, VOTE, UNION,\n",
    "#     # Analysis and reporting\n",
    "#     FusionReport, FusionQualityMetrics, ProvenanceTracker,\n",
    "#     build_record_groups_from_correspondences,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the PyDI package if not already installed\n",
    "# First navigate to the root directory of the repository in your terminal, then run:\n",
    "# !pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyDI Tutorial\n",
      "Repository root: c:\\Users\\Ralph\\dev\\pydi\n",
      "Output directory: c:\\Users\\Ralph\\dev\\pydi\\PyDI\\tutorial\\output\\movies\n",
      "All systems ready! üöÄ\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Setup paths\n",
    "def get_repo_root():\n",
    "    \"\"\"Get repository root directory.\"\"\"\n",
    "    current = Path.cwd()\n",
    "    while current != current.parent:\n",
    "        if (current / 'pyproject.toml').exists():\n",
    "            return current\n",
    "        current = current.parent\n",
    "    return Path.cwd()\n",
    "\n",
    "ROOT = get_repo_root()\n",
    "OUTPUT_DIR = ROOT / \"PyDI\" / \"tutorial\" / \"output\" / \"movies\"\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"PyDI Tutorial\")\n",
    "print(f\"Repository root: {ROOT}\")\n",
    "print(f\"Output directory: {OUTPUT_DIR}\")\n",
    "print(f\"All systems ready! üöÄ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Data Loading and Profiling\n",
    "\n",
    "PyDI provides provenance-aware data loading that automatically tracks dataset metadata and optionally adds unique identifiers to each record. Let's load our movie datasets and understand their characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Academy Awards:\n",
      "  Records: 4,592\n",
      "  Attributes: 7\n",
      "  Columns: ['_id', 'id', 'title', 'actor_name', 'date', 'director_name', 'oscar']\n",
      "  Dataset name: academy_awards\n",
      "\n",
      "Actors:\n",
      "  Records: 151\n",
      "  Attributes: 7\n",
      "  Columns: ['_id', 'id', 'title', 'actor_name', 'actors_actor_birthday', 'actors_actor_birthplace', 'date']\n",
      "  Dataset name: actors\n",
      "\n",
      "Golden Globes:\n",
      "  Records: 2,286\n",
      "  Attributes: 7\n",
      "  Columns: ['_id', 'id', 'title', 'actor_name', 'date', 'director_name', 'globe']\n",
      "  Dataset name: golden_globes\n",
      "\n",
      "Total records across all datasets: 7,029\n"
     ]
    }
   ],
   "source": [
    "from PyDI.io import load_xml\n",
    "\n",
    "# Define dataset paths\n",
    "DATA_DIR = ROOT / \"PyDI\" / \"tutorial\" / \"input\" / \"movies\"\n",
    "\n",
    "# Load Academy Awards dataset\n",
    "academy_awards = load_xml(\n",
    "    DATA_DIR / \"data\" / \"academy_awards.xml\",\n",
    "    name=\"academy_awards\",\n",
    "    record_tag=\"movie\",\n",
    "    add_index=True,\n",
    "    index_column_name=\"_id\"\n",
    ")\n",
    "\n",
    "# Load Actors dataset  \n",
    "actors = load_xml(\n",
    "    DATA_DIR / \"data\" / \"actors.xml\",\n",
    "    name=\"actors\", \n",
    "    record_tag=\"movie\",\n",
    "    add_index=True,\n",
    "    index_column_name=\"_id\"\n",
    ")\n",
    "\n",
    "# Load Golden Globes dataset\n",
    "golden_globes = load_xml(\n",
    "    DATA_DIR / \"data\" / \"golden_globes.xml\",\n",
    "    name=\"golden_globes\",\n",
    "    record_tag=\"movie\", \n",
    "    add_index=True,\n",
    "    index_column_name=\"_id\"\n",
    ")\n",
    "\n",
    "# Display basic information\n",
    "datasets = [academy_awards, actors, golden_globes]\n",
    "names = [\"Academy Awards\", \"Actors\", \"Golden Globes\"]\n",
    "\n",
    "for df, name in zip(datasets, names):\n",
    "    print(f\"{name}:\")\n",
    "    print(f\"  Records: {len(df):,}\")\n",
    "    print(f\"  Attributes: {len(df.columns)}\")\n",
    "    print(f\"  Columns: {list(df.columns)}\")\n",
    "    print(f\"  Dataset name: {df.attrs.get('dataset_name', 'unknown')}\")\n",
    "    print()\n",
    "\n",
    "total_records = sum(len(df) for df in datasets)\n",
    "print(f\"Total records across all datasets: {total_records:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìΩÔ∏è Academy Awards Dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>actor_name</th>\n",
       "      <th>date</th>\n",
       "      <th>director_name</th>\n",
       "      <th>oscar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>academy_awards-0000</td>\n",
       "      <td>academy_awards_1</td>\n",
       "      <td>Biutiful</td>\n",
       "      <td>Javier Bardem</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>academy_awards-0001</td>\n",
       "      <td>academy_awards_2</td>\n",
       "      <td>True Grit</td>\n",
       "      <td>Jeff Bridges</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>Joel Coen</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>academy_awards-0002</td>\n",
       "      <td>academy_awards_2</td>\n",
       "      <td>True Grit</td>\n",
       "      <td>Jeff Bridges</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>Ethan Coen</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   _id                id      title     actor_name  \\\n",
       "0  academy_awards-0000  academy_awards_1   Biutiful  Javier Bardem   \n",
       "1  academy_awards-0001  academy_awards_2  True Grit   Jeff Bridges   \n",
       "2  academy_awards-0002  academy_awards_2  True Grit   Jeff Bridges   \n",
       "\n",
       "         date director_name oscar  \n",
       "0  2010-01-01           NaN   NaN  \n",
       "1  2010-01-01     Joel Coen   NaN  \n",
       "2  2010-01-01    Ethan Coen   NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üé≠ Actors Dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>actor_name</th>\n",
       "      <th>actors_actor_birthday</th>\n",
       "      <th>actors_actor_birthplace</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>actors-0000</td>\n",
       "      <td>actors_1</td>\n",
       "      <td>7th Heaven</td>\n",
       "      <td>Janet Gaynor</td>\n",
       "      <td>1906-01-01</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>1929-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>actors-0001</td>\n",
       "      <td>actors_2</td>\n",
       "      <td>Coquette</td>\n",
       "      <td>Mary Pickford</td>\n",
       "      <td>1892-01-01</td>\n",
       "      <td>Canada</td>\n",
       "      <td>1930-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>actors-0002</td>\n",
       "      <td>actors_3</td>\n",
       "      <td>The Divorcee</td>\n",
       "      <td>Norma Shearer</td>\n",
       "      <td>1902-01-01</td>\n",
       "      <td>Canada</td>\n",
       "      <td>1931-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           _id        id         title     actor_name actors_actor_birthday  \\\n",
       "0  actors-0000  actors_1    7th Heaven   Janet Gaynor            1906-01-01   \n",
       "1  actors-0001  actors_2      Coquette  Mary Pickford            1892-01-01   \n",
       "2  actors-0002  actors_3  The Divorcee  Norma Shearer            1902-01-01   \n",
       "\n",
       "  actors_actor_birthplace        date  \n",
       "0            Pennsylvania  1929-01-01  \n",
       "1                  Canada  1930-01-01  \n",
       "2                  Canada  1931-01-01  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üèÜ Golden Globes Dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>actor_name</th>\n",
       "      <th>date</th>\n",
       "      <th>director_name</th>\n",
       "      <th>globe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>golden_globes-0000</td>\n",
       "      <td>golden_globes_1</td>\n",
       "      <td>Frankie and Alice</td>\n",
       "      <td>Halle Berry</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>golden_globes-0001</td>\n",
       "      <td>golden_globes_2</td>\n",
       "      <td>Rabbit Hole</td>\n",
       "      <td>Nicole Kidman</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>golden_globes-0002</td>\n",
       "      <td>golden_globes_3</td>\n",
       "      <td>Winter's Bone</td>\n",
       "      <td>Jennifer Lawrence</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  _id               id              title         actor_name  \\\n",
       "0  golden_globes-0000  golden_globes_1  Frankie and Alice        Halle Berry   \n",
       "1  golden_globes-0001  golden_globes_2        Rabbit Hole      Nicole Kidman   \n",
       "2  golden_globes-0002  golden_globes_3      Winter's Bone  Jennifer Lawrence   \n",
       "\n",
       "         date director_name globe  \n",
       "0  2011-01-01           NaN   NaN  \n",
       "1  2011-01-01           NaN   NaN  \n",
       "2  2011-01-01           NaN   NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Preview the data structure\n",
    "\n",
    "print(\"\\nüìΩÔ∏è Academy Awards Dataset:\")\n",
    "display(academy_awards.head(3))\n",
    "\n",
    "print(\"\\nüé≠ Actors Dataset:\")\n",
    "display(actors.head(3))\n",
    "\n",
    "print(\"\\nüèÜ Golden Globes Dataset:\")\n",
    "display(golden_globes.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Quality Analysis\n",
    "\n",
    "Let's use PyDI's profiling capabilities to understand our data quality and identify the best attributes for matching."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Dataset Summary\n",
    "\n",
    "First, let's use the DataProfiler's `summary()` method to get basic statistics for each dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "academy_awards:\n",
      "  Rows: 4,592\n",
      "  Columns: 7\n",
      "  Total nulls: 11,036\n",
      "  Null percentage: 34.3%\n",
      "  Null counts per column:\n",
      "    title: 12 (0.3%)\n",
      "    actor_name: 3,535 (77.0%)\n",
      "    director_name: 4,172 (90.9%)\n",
      "    oscar: 3,317 (72.2%)\n",
      "\n",
      "actors:\n",
      "  Rows: 151\n",
      "  Columns: 7\n",
      "  Total nulls: 0\n",
      "  Null percentage: 0.0%\n",
      "\n",
      "golden_globes:\n",
      "  Rows: 2,286\n",
      "  Columns: 7\n",
      "  Total nulls: 3,681\n",
      "  Null percentage: 23.0%\n",
      "  Null counts per column:\n",
      "    actor_name: 54 (2.4%)\n",
      "    director_name: 1,966 (86.0%)\n",
      "    globe: 1,661 (72.7%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'rows': 2286,\n",
       " 'columns': 7,\n",
       " 'nulls_total': 3681,\n",
       " 'nulls_per_column': {'_id': 0,\n",
       "  'id': 0,\n",
       "  'title': 0,\n",
       "  'actor_name': 54,\n",
       "  'date': 0,\n",
       "  'director_name': 1966,\n",
       "  'globe': 1661},\n",
       " 'dtypes': {'_id': 'string',\n",
       "  'id': 'object',\n",
       "  'title': 'object',\n",
       "  'actor_name': 'object',\n",
       "  'date': 'object',\n",
       "  'director_name': 'object',\n",
       "  'globe': 'object'}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from PyDI.profiling import DataProfiler\n",
    "\n",
    "# Initialize the DataProfiler\n",
    "profiler = DataProfiler()\n",
    "\n",
    "for df, name in zip(datasets, names):\n",
    "    profile = profiler.summary(df) # automatically prints some statistics and returns object containing stats\n",
    "\n",
    "display(profile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attribute Coverage Analysis\n",
    "\n",
    "Next, let's use the `analyze_coverage()` method to understand how attributes overlap across datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Attribute coverage across datasets:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attribute</th>\n",
       "      <th>academy_awards_count</th>\n",
       "      <th>academy_awards_pct</th>\n",
       "      <th>academy_awards_coverage</th>\n",
       "      <th>academy_awards_samples</th>\n",
       "      <th>actors_count</th>\n",
       "      <th>actors_pct</th>\n",
       "      <th>actors_coverage</th>\n",
       "      <th>actors_samples</th>\n",
       "      <th>golden_globes_count</th>\n",
       "      <th>golden_globes_pct</th>\n",
       "      <th>golden_globes_coverage</th>\n",
       "      <th>golden_globes_samples</th>\n",
       "      <th>avg_coverage</th>\n",
       "      <th>max_coverage</th>\n",
       "      <th>datasets_with_attribute</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>_id</td>\n",
       "      <td>4592/4592</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>['academy_awards-0000', 'academy_awards-0001',...</td>\n",
       "      <td>151/151</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['actors-0000', 'actors-0001', 'actors-0002']</td>\n",
       "      <td>2286/2286</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>['golden_globes-0000', 'golden_globes-0001', '...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>actor_name</td>\n",
       "      <td>1057/4592</td>\n",
       "      <td>23.0%</td>\n",
       "      <td>0.230183</td>\n",
       "      <td>['Javier Bardem', 'Jeff Bridges', 'Jeff Bridges']</td>\n",
       "      <td>151/151</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['Janet Gaynor', 'Mary Pickford', 'Norma Shear...</td>\n",
       "      <td>2232/2286</td>\n",
       "      <td>97.6%</td>\n",
       "      <td>0.976378</td>\n",
       "      <td>['Halle Berry', 'Nicole Kidman', 'Jennifer Law...</td>\n",
       "      <td>0.735520</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>actors_actor_birthday</td>\n",
       "      <td>0/0</td>\n",
       "      <td>0%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>N/A</td>\n",
       "      <td>151/151</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['1906-01-01', '1892-01-01', '1902-01-01']</td>\n",
       "      <td>0/0</td>\n",
       "      <td>0%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>actors_actor_birthplace</td>\n",
       "      <td>0/0</td>\n",
       "      <td>0%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>N/A</td>\n",
       "      <td>151/151</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['Pennsylvania', 'Canada', 'Canada']</td>\n",
       "      <td>0/0</td>\n",
       "      <td>0%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>date</td>\n",
       "      <td>4592/4592</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>['2010-01-01', '2010-01-01', '2010-01-01']</td>\n",
       "      <td>151/151</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['1929-01-01', '1930-01-01', '1931-01-01']</td>\n",
       "      <td>2286/2286</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>['2011-01-01', '2011-01-01', '2011-01-01']</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>director_name</td>\n",
       "      <td>420/4592</td>\n",
       "      <td>9.1%</td>\n",
       "      <td>0.091463</td>\n",
       "      <td>['Joel Coen', 'Ethan Coen', 'David Fincher']</td>\n",
       "      <td>0/0</td>\n",
       "      <td>0%</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N/A</td>\n",
       "      <td>320/2286</td>\n",
       "      <td>14.0%</td>\n",
       "      <td>0.139983</td>\n",
       "      <td>['Darren Aronofsky', 'David Fincher', 'Tom Hoo...</td>\n",
       "      <td>0.077149</td>\n",
       "      <td>0.139983</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>globe</td>\n",
       "      <td>0/0</td>\n",
       "      <td>0%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0/0</td>\n",
       "      <td>0%</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N/A</td>\n",
       "      <td>625/2286</td>\n",
       "      <td>27.3%</td>\n",
       "      <td>0.273403</td>\n",
       "      <td>['yes', 'yes', 'yes']</td>\n",
       "      <td>0.091134</td>\n",
       "      <td>0.273403</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>id</td>\n",
       "      <td>4592/4592</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>['academy_awards_1', 'academy_awards_2', 'acad...</td>\n",
       "      <td>151/151</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['actors_1', 'actors_2', 'actors_3']</td>\n",
       "      <td>2286/2286</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>['golden_globes_1', 'golden_globes_2', 'golden...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>oscar</td>\n",
       "      <td>1275/4592</td>\n",
       "      <td>27.8%</td>\n",
       "      <td>0.277657</td>\n",
       "      <td>['yes', 'yes', 'yes']</td>\n",
       "      <td>0/0</td>\n",
       "      <td>0%</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0/0</td>\n",
       "      <td>0%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0.092552</td>\n",
       "      <td>0.277657</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>title</td>\n",
       "      <td>4580/4592</td>\n",
       "      <td>99.7%</td>\n",
       "      <td>0.997387</td>\n",
       "      <td>['Biutiful', 'True Grit', 'True Grit']</td>\n",
       "      <td>151/151</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['7th Heaven', 'Coquette', 'The Divorcee']</td>\n",
       "      <td>2286/2286</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>['Frankie and Alice', 'Rabbit Hole', \"Winter's...</td>\n",
       "      <td>0.999129</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 attribute academy_awards_count academy_awards_pct  \\\n",
       "0                      _id            4592/4592             100.0%   \n",
       "1               actor_name            1057/4592              23.0%   \n",
       "2    actors_actor_birthday                  0/0                 0%   \n",
       "3  actors_actor_birthplace                  0/0                 0%   \n",
       "4                     date            4592/4592             100.0%   \n",
       "5            director_name             420/4592               9.1%   \n",
       "6                    globe                  0/0                 0%   \n",
       "7                       id            4592/4592             100.0%   \n",
       "8                    oscar            1275/4592              27.8%   \n",
       "9                    title            4580/4592              99.7%   \n",
       "\n",
       "   academy_awards_coverage                             academy_awards_samples  \\\n",
       "0                 1.000000  ['academy_awards-0000', 'academy_awards-0001',...   \n",
       "1                 0.230183  ['Javier Bardem', 'Jeff Bridges', 'Jeff Bridges']   \n",
       "2                 0.000000                                                N/A   \n",
       "3                 0.000000                                                N/A   \n",
       "4                 1.000000         ['2010-01-01', '2010-01-01', '2010-01-01']   \n",
       "5                 0.091463       ['Joel Coen', 'Ethan Coen', 'David Fincher']   \n",
       "6                 0.000000                                                N/A   \n",
       "7                 1.000000  ['academy_awards_1', 'academy_awards_2', 'acad...   \n",
       "8                 0.277657                              ['yes', 'yes', 'yes']   \n",
       "9                 0.997387             ['Biutiful', 'True Grit', 'True Grit']   \n",
       "\n",
       "  actors_count actors_pct  actors_coverage  \\\n",
       "0      151/151     100.0%              1.0   \n",
       "1      151/151     100.0%              1.0   \n",
       "2      151/151     100.0%              1.0   \n",
       "3      151/151     100.0%              1.0   \n",
       "4      151/151     100.0%              1.0   \n",
       "5          0/0         0%              0.0   \n",
       "6          0/0         0%              0.0   \n",
       "7      151/151     100.0%              1.0   \n",
       "8          0/0         0%              0.0   \n",
       "9      151/151     100.0%              1.0   \n",
       "\n",
       "                                      actors_samples golden_globes_count  \\\n",
       "0      ['actors-0000', 'actors-0001', 'actors-0002']           2286/2286   \n",
       "1  ['Janet Gaynor', 'Mary Pickford', 'Norma Shear...           2232/2286   \n",
       "2         ['1906-01-01', '1892-01-01', '1902-01-01']                 0/0   \n",
       "3               ['Pennsylvania', 'Canada', 'Canada']                 0/0   \n",
       "4         ['1929-01-01', '1930-01-01', '1931-01-01']           2286/2286   \n",
       "5                                                N/A            320/2286   \n",
       "6                                                N/A            625/2286   \n",
       "7               ['actors_1', 'actors_2', 'actors_3']           2286/2286   \n",
       "8                                                N/A                 0/0   \n",
       "9         ['7th Heaven', 'Coquette', 'The Divorcee']           2286/2286   \n",
       "\n",
       "  golden_globes_pct  golden_globes_coverage  \\\n",
       "0            100.0%                1.000000   \n",
       "1             97.6%                0.976378   \n",
       "2                0%                0.000000   \n",
       "3                0%                0.000000   \n",
       "4            100.0%                1.000000   \n",
       "5             14.0%                0.139983   \n",
       "6             27.3%                0.273403   \n",
       "7            100.0%                1.000000   \n",
       "8                0%                0.000000   \n",
       "9            100.0%                1.000000   \n",
       "\n",
       "                               golden_globes_samples  avg_coverage  \\\n",
       "0  ['golden_globes-0000', 'golden_globes-0001', '...      1.000000   \n",
       "1  ['Halle Berry', 'Nicole Kidman', 'Jennifer Law...      0.735520   \n",
       "2                                                N/A      0.333333   \n",
       "3                                                N/A      0.333333   \n",
       "4         ['2011-01-01', '2011-01-01', '2011-01-01']      1.000000   \n",
       "5  ['Darren Aronofsky', 'David Fincher', 'Tom Hoo...      0.077149   \n",
       "6                              ['yes', 'yes', 'yes']      0.091134   \n",
       "7  ['golden_globes_1', 'golden_globes_2', 'golden...      1.000000   \n",
       "8                                                N/A      0.092552   \n",
       "9  ['Frankie and Alice', 'Rabbit Hole', \"Winter's...      0.999129   \n",
       "\n",
       "   max_coverage  datasets_with_attribute  \n",
       "0      1.000000                        3  \n",
       "1      1.000000                        3  \n",
       "2      1.000000                        1  \n",
       "3      1.000000                        1  \n",
       "4      1.000000                        3  \n",
       "5      0.139983                        2  \n",
       "6      0.273403                        1  \n",
       "7      1.000000                        3  \n",
       "8      0.277657                        1  \n",
       "9      1.000000                        3  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîó Attributes suitable for entity matching:\n",
      "Attributes available in 2+ datasets: ['_id', 'actor_name', 'date', 'director_name', 'id', 'title']\n"
     ]
    }
   ],
   "source": [
    "coverage = profiler.analyze_coverage(\n",
    "    datasets=datasets,\n",
    "    include_samples=True,\n",
    "    sample_count=3  # Show 3 sample values per attribute\n",
    ")\n",
    "\n",
    "print(\"üìä Attribute coverage across datasets:\")\n",
    "display(coverage)\n",
    "\n",
    "# Identify attributes suitable for entity matching\n",
    "print(\"\\nüîó Attributes suitable for entity matching:\")\n",
    "matching_attrs = coverage[coverage['datasets_with_attribute'] >= 2]['attribute'].tolist()\n",
    "print(f\"Attributes available in 2+ datasets: {matching_attrs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detailed Data Profiling\n",
    "\n",
    "Now let's generate comprehensive HTML profiles for each dataset using the `profile()` method. These reports provide in-depth statistical analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Profiling Academy Awards...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <ins><a href=\"https://ydata.ai/register\">Upgrade to ydata-sdk</a></ins>\n",
       "                <p>\n",
       "                    Improve your data and profiling with ydata-sdk, featuring data quality scoring, redundancy detection, outlier identification, text validation, and synthetic data generation.\n",
       "                </p>\n",
       "            </div>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d09be4887ef4d88978dd39a9f0189cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 82.38it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e79cfa7bb0940ac99cb4b2f6b25aeb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate report structure:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3fc248836d847b0b9256661bfd211a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Render HTML:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7815ae969b9b42cca159d73e2d66bafc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Export report to file:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úÖ Profile saved: c:\\Users\\Ralph\\dev\\pydi\\PyDI\\tutorial\\output\\movies\\dataset-profiles\\academy_awards_profile.html\n",
      "üìä Profiling Actors...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f77d38d409c4976852752e02447aca6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 208.81it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "677356a8bc0e4c2da4bc54119c38a864",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate report structure:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52f69ae2cf7546379b29fa1458e8c375",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Render HTML:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "825a8030db204709b9b9c3863398d816",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Export report to file:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úÖ Profile saved: c:\\Users\\Ralph\\dev\\pydi\\PyDI\\tutorial\\output\\movies\\dataset-profiles\\actors_profile.html\n",
      "üìä Profiling Golden Globes...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "922c239989b24b9c9d2ad19bb82551c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 120.70it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b808d9e237494dcebe7ba781b66a59e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate report structure:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ae1fd119c2142288c9290f4bf763561",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Render HTML:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a8e5423f5874b62acfc18fa5c88c115",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Export report to file:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úÖ Profile saved: c:\\Users\\Ralph\\dev\\pydi\\PyDI\\tutorial\\output\\movies\\dataset-profiles\\golden_globes_profile.html\n",
      "\n",
      "üéØ Generated 3 detailed HTML reports\n",
      "üìÅ Location: c:\\Users\\Ralph\\dev\\pydi\\PyDI\\tutorial\\output\\movies\\dataset-profiles\n",
      "\n",
      "üí° Open these HTML files in your browser for interactive exploration:\n",
      "  ‚Ä¢ academy_awards_profile.html\n",
      "  ‚Ä¢ actors_profile.html\n",
      "  ‚Ä¢ golden_globes_profile.html\n"
     ]
    }
   ],
   "source": [
    "# Generate detailed HTML profiles for each dataset\n",
    "\n",
    "profile_dir = OUTPUT_DIR / \"dataset-profiles\"\n",
    "profile_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "profile_paths = []\n",
    "\n",
    "for df, name in zip(datasets, names):\n",
    "    print(f\"üìä Profiling {name}...\")\n",
    "    \n",
    "    profile_path = profiler.profile(df, str(profile_dir))\n",
    "    profile_paths.append(profile_path)\n",
    "    print(f\"  ‚úÖ Profile saved: {profile_path}\")\n",
    "\n",
    "print(f\"\\nüéØ Generated {len(profile_paths)} detailed HTML reports\")\n",
    "print(f\"üìÅ Location: {profile_dir}\")\n",
    "print(\"\\nüí° Open these HTML files in your browser for interactive exploration:\")\n",
    "for path in profile_paths:\n",
    "    print(f\"  ‚Ä¢ {Path(path).name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Comparison\n",
    "\n",
    "Finally, let's use the `compare()` method to create a comparison report between two datasets, highlighting differences and similarities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Comparing Academy Awards vs Golden Globes datasets...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "449e5c6bc3754422a5ac071c6a9c0b21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "                                             |          | [  0%]   00:00 -> (? left)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report c:\\Users\\Ralph\\dev\\pydi\\PyDI\\tutorial\\output\\movies\\dataset-comparisons\\academy_awards_vs_golden_globes_compare.html was generated! NOTEBOOK/COLAB USERS: the web browser MAY not pop up, regardless, the report IS saved in your notebook/colab files.\n",
      "‚úÖ Comparison report saved: c:\\Users\\Ralph\\dev\\pydi\\PyDI\\tutorial\\output\\movies\\dataset-comparisons\\academy_awards_vs_golden_globes_compare.html\n",
      "üîç Comparing Academy Awards vs Golden Globes datasets...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19207a80e1424661bbcfaac9114619dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "                                             |          | [  0%]   00:00 -> (? left)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report c:\\Users\\Ralph\\dev\\pydi\\PyDI\\tutorial\\output\\movies\\dataset-comparisons\\academy_awards_vs_actors_compare.html was generated! NOTEBOOK/COLAB USERS: the web browser MAY not pop up, regardless, the report IS saved in your notebook/colab files.\n",
      "‚úÖ Comparison report saved: c:\\Users\\Ralph\\dev\\pydi\\PyDI\\tutorial\\output\\movies\\dataset-comparisons\\academy_awards_vs_actors_compare.html\n",
      "üîç Comparing Academy Awards vs Golden Globes datasets...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2db135578f634244afd048d3543349ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "                                             |          | [  0%]   00:00 -> (? left)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report c:\\Users\\Ralph\\dev\\pydi\\PyDI\\tutorial\\output\\movies\\dataset-comparisons\\actors_vs_golden_globes_compare.html was generated! NOTEBOOK/COLAB USERS: the web browser MAY not pop up, regardless, the report IS saved in your notebook/colab files.\n",
      "‚úÖ Comparison report saved: c:\\Users\\Ralph\\dev\\pydi\\PyDI\\tutorial\\output\\movies\\dataset-comparisons\\actors_vs_golden_globes_compare.html\n"
     ]
    }
   ],
   "source": [
    "# Compare Academy Awards vs Golden Globes datasets\n",
    "\n",
    "compare_dir = OUTPUT_DIR / \"dataset-comparisons\"\n",
    "compare_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"üîç Comparing Academy Awards vs Golden Globes datasets...\")\n",
    "\n",
    "comparison_path = profiler.compare(academy_awards, golden_globes, compare_dir)\n",
    "print(f\"‚úÖ Comparison report saved: {comparison_path}\")\n",
    "\n",
    "print(\"üîç Comparing Academy Awards vs Golden Globes datasets...\")\n",
    "\n",
    "comparison_path = profiler.compare(academy_awards, actors, compare_dir)\n",
    "print(f\"‚úÖ Comparison report saved: {comparison_path}\")\n",
    "\n",
    "print(\"üîç Comparing Academy Awards vs Golden Globes datasets...\")\n",
    "\n",
    "comparison_path = profiler.compare(actors, golden_globes, compare_dir)\n",
    "print(f\"‚úÖ Comparison report saved: {comparison_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Identity Resolution (Entity Matching)\n",
    "\n",
    "Identity Resolution is the process of identifying records that refer to the same real-world entity. PyDI provides comprehensive blocking and matching capabilities.\n",
    "\n",
    "### Step 1: Blocking Strategies\n",
    "\n",
    "Blocking reduces the number of comparisons from O(n¬≤) to a manageable subset. Let's explore different blocking strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's setup logging first\n",
    "import logging\n",
    "\n",
    "# # Configure logging for INFO level\n",
    "# logging.basicConfig(\n",
    "#     level=logging.INFO,\n",
    "#     format='[%(levelname)-5s] %(name)s - %(message)s',\n",
    "#     handlers=[\n",
    "#           logging.FileHandler('output/logs/pydi.log'),  # Save to file\n",
    "#           logging.StreamHandler()                      # Display on console\n",
    "#       ],\n",
    "#     force=True\n",
    "# )\n",
    "\n",
    "# Configure logging for DEBUG level\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format='[%(levelname)-5s] %(name)s - %(message)s',\n",
    "    handlers=[\n",
    "          logging.FileHandler('output/logs/pydi.log'),  # Save to file\n",
    "          logging.StreamHandler()                      # Display on console\n",
    "      ],\n",
    "    force=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without blocking: 345,186 comparisons required\n",
      "\n",
      "üéØ Goal: Reduce comparisons while maintaining high recall\n",
      "\n",
      "\n",
      " No Blocking\n",
      "  Generated: 345,186 candidates\n"
     ]
    }
   ],
   "source": [
    "from PyDI.entitymatching import NoBlocking, StandardBlocking, SortedNeighbourhood, TokenBlocking, EmbeddingBlocking\n",
    "\n",
    "# We'll focus on Actors and Golden Globes for showcasing blocking strategies\n",
    "\n",
    "max_pairs = len(actors) * len(golden_globes)\n",
    "print(f\"Without blocking: {max_pairs:,} comparisons required\")\n",
    "print(\"\\nüéØ Goal: Reduce comparisons while maintaining high recall\\n\")\n",
    "\n",
    "# No Blocking - compare all possible pairs\n",
    "print(\"\\n No Blocking\")\n",
    "\n",
    "no_blocker = NoBlocking(\n",
    "    actors, golden_globes,\n",
    "    batch_size=1000\n",
    ")\n",
    "\n",
    "# in an actual large-scale application, we do not build a list of all pairs but stream over them like this\n",
    "for batch in no_blocker:\n",
    "    # do something with the pairs\n",
    "    continue\n",
    "\n",
    "# but we can also generate the full set of pairs for smaller datasets\n",
    "no_candidates = no_blocker.materialize()\n",
    "\n",
    "print(f\"  Generated: {len(no_candidates):,} candidates\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use an actual blocker. Note that when instantiating the blocker, it also writes out a corresponding debug file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - Creating blocking key values for dataset1: 151 records\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - Creating blocking key values for dataset2: 2286 records\n",
      "[INFO ] PyDI.entitymatching.blocking.standard.StandardBlocking - created 109 blocking keys for first dataset\n",
      "[INFO ] PyDI.entitymatching.blocking.standard.StandardBlocking - created 792 blocking keys for second dataset\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - Joining blocking key values: 109 x 792 blocks\n",
      "[INFO ] PyDI.entitymatching.blocking.standard.StandardBlocking - created 91 blocks from blocking keys\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - Block size distribution:\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - Frequency   Element\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 19          1\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 13          5\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 10          4\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 9           2\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 6           10\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 5           8\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 5           3\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 4           7\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 4           6\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 2           18\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 2           14\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 2           13\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 2           12\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 1           160\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 1           40\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 1           30\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 1           28\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 1           19\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 1           16\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 1           11\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 1           9\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - Blocking key values:\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - BlockingKeyValue\tFrequency\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - The\t\t\t160\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - Mar\t\t\t40\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - In \t\t\t30\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - My \t\t\t28\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - All\t\t\t19\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - One\t\t\t18\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - Mon\t\t\t18\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - Cha\t\t\t16\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - Com\t\t\t14\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - Ali\t\t\t14\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - Mis\t\t\t13\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - Sta\t\t\t13\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - Chi\t\t\t12\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - Ame\t\t\t12\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - Wal\t\t\t11\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - Mil\t\t\t10\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - To \t\t\t10\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - On \t\t\t10\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - Goo\t\t\t10\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - Har\t\t\t10\n",
      "[INFO ] PyDI.entitymatching.blocking.standard.StandardBlocking - Debug results written to file: output/debugResultsBlocking_StandardBlocking.csv\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - Creating candidate record pairs from 91 blocks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1Ô∏è‚É£ Standard Blocking (First 3 Characters of Title)\n",
      "\n",
      "  Generated: 736 candidates\n"
     ]
    }
   ],
   "source": [
    "# 1. Standard Blocking - First 3 characters of title\n",
    "print(\"\\n1Ô∏è‚É£ Standard Blocking (First 3 Characters of Title)\")\n",
    "\n",
    "# Add title_prefix directly to the original dataframes\n",
    "actors['title_prefix'] = actors['title'].astype(str).str[:3]\n",
    "golden_globes['title_prefix'] = golden_globes['title'].astype(str).str[:3]\n",
    "\n",
    "standard_blocker_a2g = StandardBlocking(\n",
    "    actors, golden_globes,\n",
    "    on=['title_prefix'],  # Block on first 3 characters of title\n",
    "    batch_size=1000\n",
    ")\n",
    "\n",
    "standard_candidates_a2g = standard_blocker_a2g.materialize()\n",
    "\n",
    "print()\n",
    "print(f\"  Generated: {len(standard_candidates_a2g):,} candidates\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[DEBUG] PyDI.entitymatching.blocking.sorted_neighbourhood.SortedNeighbourhood - Creating sort keys for dataset1: 151 records\n",
      "[DEBUG] PyDI.entitymatching.blocking.sorted_neighbourhood.SortedNeighbourhood - Creating sort keys for dataset2: 2286 records\n",
      "[DEBUG] PyDI.entitymatching.blocking.sorted_neighbourhood.SortedNeighbourhood - Sorting combined dataset with 2437 records\n",
      "[INFO ] PyDI.entitymatching.blocking.sorted_neighbourhood.SortedNeighbourhood - created sorted neighbourhood with window size 10\n",
      "[INFO ] PyDI.entitymatching.blocking.sorted_neighbourhood.SortedNeighbourhood - created 1 sorted sequence from 2437 records\n",
      "[INFO ] PyDI.entitymatching.blocking.sorted_neighbourhood.SortedNeighbourhood - Debug results written to file: output/debugResultsBlocking_SortedNeighbourhood.csv\n",
      "[DEBUG] PyDI.entitymatching.blocking.sorted_neighbourhood.SortedNeighbourhood - Creating candidate record pairs from sorted neighbourhood with window 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2Ô∏è‚É£ Sorted Neighbourhood Blocking (Title-based, Window=5)\n",
      "\n",
      "  Generated: 2,360 candidates\n"
     ]
    }
   ],
   "source": [
    "# 2. Sorted Neighbourhood - Sequential similarity\n",
    "print(\"\\n2Ô∏è‚É£ Sorted Neighbourhood Blocking (Title-based, Window=5)\")\n",
    "\n",
    "sn_blocker_a2g = SortedNeighbourhood(\n",
    "    actors, golden_globes,\n",
    "    key='title',  # Sort by title\n",
    "    window=10,     # Compare with 5 neighbors\n",
    "    batch_size=1000\n",
    ")\n",
    "\n",
    "sn_candidates_a2g = sn_blocker_a2g.materialize()\n",
    "\n",
    "print()\n",
    "print(f\"  Generated: {len(sn_candidates_a2g):,} candidates\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - Creating token index for dataset1: 151 records\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - Creating token index for dataset2: 2286 records\n",
      "[INFO ] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - created 178 token keys for first dataset\n",
      "[INFO ] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - created 1776 token keys for second dataset\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - Joining token keys: 178 x 1776 tokens\n",
      "[INFO ] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - created 142 blocks from token keys\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - Token frequency distribution:\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - Frequency   Element\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 74          1\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 29          2\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 16          3\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 4           6\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 4           4\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 2           8\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 2           7\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 2           5\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           56\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           46\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           42\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           15\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           13\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           12\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           11\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           10\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           9\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - Token values:\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - Token\t\t\tFrequency\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - story\t\t\t56\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - woman\t\t\t46\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - night\t\t\t42\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - heart\t\t\t15\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - little\t\t\t13\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - american\t\t\t12\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - street\t\t\t11\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - river\t\t\t10\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - alice\t\t\t9\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - daughter\t\t\t8\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - three\t\t\t8\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - country\t\t\t7\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - golden\t\t\t7\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - great\t\t\t6\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - women\t\t\t6\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - coming\t\t\t6\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - goodbye\t\t\t6\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - heaven\t\t\t5\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - queen\t\t\t5\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - winter\t\t\t4\n",
      "[INFO ] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - Debug results written to file: output/debugResultsBlocking_TokenBlocking.csv\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - Creating candidate record pairs from 142 token blocks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3Ô∏è‚É£ Token Blocking (Title Tokens, Min Length=5)\n",
      "\n",
      "  Generated: 431 candidates\n"
     ]
    }
   ],
   "source": [
    "# 3. Token Blocking - Token-based similarity\n",
    "print(\"\\n3Ô∏è‚É£ Token Blocking (Title Tokens, Min Length=5)\")\n",
    "\n",
    "token_blocker_a2g = TokenBlocking(\n",
    "    actors, golden_globes,\n",
    "    column='title',      # Tokenize titles\n",
    "    min_token_len=5,     # Ignore very short tokens\n",
    "    batch_size=1000\n",
    ")\n",
    "\n",
    "token_candidates_a2g = token_blocker_a2g.materialize()\n",
    "\n",
    "print()\n",
    "print(f\"  Generated: {len(token_candidates_a2g):,} candidates\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO ] PyDI.entitymatching.blocking.embedding.EmbeddingBlocking - Initialized EmbeddingBlocking with sklearn backend, top_k=10, threshold=0.3\n",
      "[DEBUG] PyDI.entitymatching.blocking.embedding.EmbeddingBlocking - Computing embeddings for datasets...\n",
      "[DEBUG] PyDI.entitymatching.blocking.embedding.EmbeddingBlocking - Creating embeddings for dataset1: 151 records\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4Ô∏è‚É£ Embedding Blocking (Semantic Similarity)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO ] sentence_transformers.SentenceTransformer - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n",
      "[DEBUG] urllib3.connectionpool - Starting new HTTPS connection (1): huggingface.co:443\n",
      "[DEBUG] urllib3.connectionpool - https://huggingface.co:443 \"HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/modules.json HTTP/1.1\" 307 0\n",
      "[DEBUG] urllib3.connectionpool - https://huggingface.co:443 \"HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/modules.json HTTP/1.1\" 200 0\n",
      "[DEBUG] urllib3.connectionpool - https://huggingface.co:443 \"HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config_sentence_transformers.json HTTP/1.1\" 307 0\n",
      "[DEBUG] urllib3.connectionpool - https://huggingface.co:443 \"HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config_sentence_transformers.json HTTP/1.1\" 200 0\n",
      "[DEBUG] urllib3.connectionpool - https://huggingface.co:443 \"HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/README.md HTTP/1.1\" 307 0\n",
      "[DEBUG] urllib3.connectionpool - https://huggingface.co:443 \"HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/README.md HTTP/1.1\" 200 0\n",
      "[DEBUG] urllib3.connectionpool - https://huggingface.co:443 \"HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/modules.json HTTP/1.1\" 307 0\n",
      "[DEBUG] urllib3.connectionpool - https://huggingface.co:443 \"HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/modules.json HTTP/1.1\" 200 0\n",
      "[DEBUG] urllib3.connectionpool - https://huggingface.co:443 \"HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/sentence_bert_config.json HTTP/1.1\" 307 0\n",
      "[DEBUG] urllib3.connectionpool - https://huggingface.co:443 \"HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/sentence_bert_config.json HTTP/1.1\" 200 0\n",
      "[DEBUG] urllib3.connectionpool - https://huggingface.co:443 \"HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1\" 307 0\n",
      "[DEBUG] urllib3.connectionpool - https://huggingface.co:443 \"HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json HTTP/1.1\" 200 0\n",
      "[DEBUG] urllib3.connectionpool - https://huggingface.co:443 \"HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1\" 307 0\n",
      "[DEBUG] urllib3.connectionpool - https://huggingface.co:443 \"HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json HTTP/1.1\" 200 0\n",
      "[DEBUG] urllib3.connectionpool - https://huggingface.co:443 \"GET /api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1\" 404 64\n",
      "[DEBUG] urllib3.connectionpool - https://huggingface.co:443 \"GET /api/models/sentence-transformers/all-MiniLM-L6-v2/revision/main HTTP/1.1\" 200 6861\n",
      "[INFO ] sentence_transformers.SentenceTransformer - Use pytorch device_name: cpu\n",
      "[INFO ] PyDI.entitymatching.blocking.embedding.EmbeddingBlocking - Loaded sentence transformer model: sentence-transformers/all-MiniLM-L6-v2\n",
      "[INFO ] PyDI.entitymatching.blocking.embedding.EmbeddingBlocking - created 384d embeddings for first dataset\n",
      "[DEBUG] PyDI.entitymatching.blocking.embedding.EmbeddingBlocking - Creating embeddings for dataset2: 2286 records\n",
      "[INFO ] PyDI.entitymatching.blocking.embedding.EmbeddingBlocking - created 384d embeddings for second dataset\n",
      "[DEBUG] PyDI.entitymatching.blocking.embedding.EmbeddingBlocking - Building similarity index for 2286 vectors\n",
      "[INFO ] PyDI.entitymatching.blocking.embedding.EmbeddingBlocking - created similarity index with 2286 vectors, metric=cosine\n",
      "[INFO ] PyDI.entitymatching.blocking.embedding.EmbeddingBlocking - Debug results written to file: output/debugResultsBlocking_EmbeddingBlocking.csv\n",
      "[DEBUG] PyDI.entitymatching.blocking.embedding.EmbeddingBlocking - Creating candidate record pairs from embedding similarity with threshold 0.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Generated: 1,497 candidates\n"
     ]
    }
   ],
   "source": [
    "# 4. Embedding Blocking - Semantic similarity\n",
    "print(\"\\n4Ô∏è‚É£ Embedding Blocking (Semantic Similarity)\")\n",
    "\n",
    "embedding_blocker_a2g = EmbeddingBlocking(\n",
    "    actors, golden_globes,\n",
    "    text_cols=['title'],\n",
    "    model=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    index_backend=\"sklearn\",\n",
    "    top_k=10,          # Top 10 most similar\n",
    "    batch_size=500\n",
    ")\n",
    "    \n",
    "embedding_candidates_a2g = embedding_blocker_a2g.materialize()\n",
    "\n",
    "print()\n",
    "print(f\"  Generated: {len(embedding_candidates_a2g):,} candidates\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Evaluation Against Ground Truth\n",
    "\n",
    "PyDI provides evaluation methods for blocking with pair completeness, pair quality, and reduction ratio:\n",
    "- **`evaluate_blocking()`**: Evaluates blocking given an already materialized set of pairs.\n",
    "- **`evaluate_blocking_batched()`**: Evaluates blocking by iterating over batches and storing results. Useful for very large datasets \n",
    "\n",
    "Let's first evaluate materialized blocking results against a set of provided ground truth correspondences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO ] root -   Pair Completeness: 0.385\n",
      "[INFO ] root -   Pair Quality:      0.014\n",
      "[INFO ] root -   Reduction Ratio:   0.998\n",
      "[INFO ] root -   True Matches Found: 10/26\n",
      "[INFO ] root - Blocking evaluation complete: Completeness=0.3846 Quality=0.0136 Reduction=0.9979\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üí° Evaluating pair quality only makes sense if the test set contains all possible pairs, which is not the case in this example!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'pair_completeness': 0.38461538461538464,\n",
       " 'pair_quality': 0.01358695652173913,\n",
       " 'reduction_ratio': 0.9978678161918502,\n",
       " 'total_candidates': 736,\n",
       " 'total_possible_pairs': 345186,\n",
       " 'true_positives_found': 10,\n",
       " 'total_true_pairs': 26,\n",
       " 'evaluation_timestamp': '2025-09-12T17:38:40.516562',\n",
       " 'output_files': ['c:\\\\Users\\\\Ralph\\\\dev\\\\pydi\\\\PyDI\\\\tutorial\\\\output\\\\movies\\\\blocking-evaluation\\\\blocking_evaluation_summary.json',\n",
       "  'c:\\\\Users\\\\Ralph\\\\dev\\\\pydi\\\\PyDI\\\\tutorial\\\\output\\\\movies\\\\blocking-evaluation\\\\blocking_detailed_results.csv']}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from PyDI.io import load_csv\n",
    "from PyDI.entitymatching import EntityMatchingEvaluator\n",
    "# Showcase EntityMatchingEvaluator.evaluate_blocking utility\n",
    "\n",
    "# Load test set with proper column names\n",
    "test_gt = load_csv(\n",
    "    DATA_DIR / \"entitymatching\" / \"actors_2_golden_globes_test.csv\",\n",
    "    name=\"test_set\", header=None, names=['id1', 'id2', 'label'], add_index=False\n",
    ")\n",
    "\n",
    "# Use EntityMatchingEvaluator.evaluate_blocking on Standard Blocking\n",
    "results = EntityMatchingEvaluator.evaluate_blocking(\n",
    "    candidate_pairs=standard_candidates_a2g,\n",
    "    blocker=standard_blocker_a2g,\n",
    "    test_pairs=test_gt,\n",
    "    out_dir=OUTPUT_DIR / \"blocking-evaluation\"\n",
    ")\n",
    "\n",
    "print(f\"\\nüí° Evaluating pair quality only makes sense if the test set contains all possible pairs, which is not the case in this example!\")\n",
    "\n",
    "display(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When datasets are huge, it is necessary to use the evaluate_blocking_batched() function to avoid materializing the full set of pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO ] root - Starting batched blocking evaluation...\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - Creating candidate record pairs from 91 blocks\n",
      "[INFO ] root -   Pair Completeness: 0.385\n",
      "[INFO ] root -   Pair Quality:      0.014\n",
      "[INFO ] root -   Reduction Ratio:   0.998\n",
      "[INFO ] root -   True Matches Found: 10/26\n",
      "[INFO ] root -   Batches Processed:  1\n",
      "[INFO ] root - Batched blocking evaluation complete: Completeness=0.3846 Quality=0.0136 Reduction=0.9979 Batches=1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'pair_completeness': 0.38461538461538464,\n",
       " 'pair_quality': 0.01358695652173913,\n",
       " 'reduction_ratio': 0.9978678161918502,\n",
       " 'total_candidates': 736,\n",
       " 'total_possible_pairs': 345186,\n",
       " 'true_positives_found': 10,\n",
       " 'total_true_pairs': 26,\n",
       " 'batches_processed': 1,\n",
       " 'evaluation_timestamp': '2025-09-12T17:38:40.565197',\n",
       " 'output_files': ['c:\\\\Users\\\\Ralph\\\\dev\\\\pydi\\\\PyDI\\\\tutorial\\\\output\\\\movies\\\\blocking-evaluation\\\\blocking_evaluation_summary.json',\n",
       "  'c:\\\\Users\\\\Ralph\\\\dev\\\\pydi\\\\PyDI\\\\tutorial\\\\output\\\\movies\\\\blocking-evaluation\\\\blocking_detailed_results.csv']}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = EntityMatchingEvaluator.evaluate_blocking_batched(\n",
    "    blocker=standard_blocker_a2g,\n",
    "    test_pairs=test_gt,\n",
    "    out_dir=OUTPUT_DIR / \"blocking-evaluation\"\n",
    ")\n",
    "\n",
    "display(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do the same kind of blocking for the dataset combination Academy Awards <-> Actors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - Creating blocking key values for dataset1: 4592 records\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - Creating blocking key values for dataset2: 151 records\n",
      "[INFO ] PyDI.entitymatching.blocking.standard.StandardBlocking - created 1076 blocking keys for first dataset\n",
      "[INFO ] PyDI.entitymatching.blocking.standard.StandardBlocking - created 109 blocking keys for second dataset\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - Joining blocking key values: 1076 x 109 blocks\n",
      "[INFO ] PyDI.entitymatching.blocking.standard.StandardBlocking - created 108 blocks from blocking keys\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - Block size distribution:\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - Frequency   Element\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 13          2\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 13          1\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 11          3\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 9           9\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 9           4\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 7           5\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 6           8\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 6           6\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 4           13\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 4           11\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 4           10\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 3           7\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 2           19\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 2           14\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 2           12\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 1           33472\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 1           88\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 1           66\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 1           48\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 1           46\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 1           42\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 1           27\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 1           26\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 1           24\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 1           23\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 1           22\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 1           21\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - 1           20\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - Blocking key values:\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - BlockingKeyValue\tFrequency\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - The\t\t\t33472\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - To \t\t\t88\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - My \t\t\t66\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - In \t\t\t48\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - Mar\t\t\t46\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - One\t\t\t42\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - Sta\t\t\t27\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - Com\t\t\t26\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - Mon\t\t\t24\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - Cha\t\t\t23\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - On \t\t\t22\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - For\t\t\t21\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - A S\t\t\t20\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - Har\t\t\t19\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - Chi\t\t\t19\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - Wal\t\t\t14\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - Goo\t\t\t14\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - Tra\t\t\t13\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - Cap\t\t\t13\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - All\t\t\t13\n",
      "[INFO ] PyDI.entitymatching.blocking.standard.StandardBlocking - Debug results written to file: output/debugResultsBlocking_StandardBlocking.csv\n",
      "[DEBUG] PyDI.entitymatching.blocking.standard.StandardBlocking - Creating candidate record pairs from 108 blocks\n",
      "[DEBUG] PyDI.entitymatching.blocking.sorted_neighbourhood.SortedNeighbourhood - Creating sort keys for dataset1: 4592 records\n",
      "[DEBUG] PyDI.entitymatching.blocking.sorted_neighbourhood.SortedNeighbourhood - Creating sort keys for dataset2: 151 records\n",
      "[DEBUG] PyDI.entitymatching.blocking.sorted_neighbourhood.SortedNeighbourhood - Sorting combined dataset with 4743 records\n",
      "[INFO ] PyDI.entitymatching.blocking.sorted_neighbourhood.SortedNeighbourhood - created sorted neighbourhood with window size 10\n",
      "[INFO ] PyDI.entitymatching.blocking.sorted_neighbourhood.SortedNeighbourhood - created 1 sorted sequence from 4743 records\n",
      "[INFO ] PyDI.entitymatching.blocking.sorted_neighbourhood.SortedNeighbourhood - Debug results written to file: output/debugResultsBlocking_SortedNeighbourhood.csv\n",
      "[DEBUG] PyDI.entitymatching.blocking.sorted_neighbourhood.SortedNeighbourhood - Creating candidate record pairs from sorted neighbourhood with window 10\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - Creating token index for dataset1: 4592 records\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - Creating token index for dataset2: 151 records\n",
      "[INFO ] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - created 3905 token keys for first dataset\n",
      "[INFO ] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - created 178 token keys for second dataset\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - Joining token keys: 3905 x 178 tokens\n",
      "[INFO ] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - created 172 blocks from token keys\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - Token frequency distribution:\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - Frequency   Element\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 70          1\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 30          2\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 16          3\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 9           4\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 8           5\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 7           6\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 5           12\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 5           7\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 3           18\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 3           8\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 2           24\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 2           9\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           102\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           66\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           50\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           44\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           29\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           28\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           26\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           25\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           21\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           20\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           17\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - 1           10\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - Token values:\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - Token\t\t\tFrequency\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - story\t\t\t102\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - night\t\t\t66\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - woman\t\t\t50\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - little\t\t\t44\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - street\t\t\t29\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - heart\t\t\t28\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - great\t\t\t26\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - children\t\t\t25\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - river\t\t\t24\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - american\t\t\t24\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - three\t\t\t21\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - women\t\t\t20\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - harry\t\t\t18\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - country\t\t\t18\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - daughter\t\t\t18\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - heaven\t\t\t17\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - golden\t\t\t12\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - bridge\t\t\t12\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - holiday\t\t\t12\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - coming\t\t\t12\n",
      "[INFO ] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - Debug results written to file: output/debugResultsBlocking_TokenBlocking.csv\n",
      "[DEBUG] PyDI.entitymatching.blocking.token_blocking.TokenBlocking - Creating candidate record pairs from 172 token blocks\n",
      "[INFO ] PyDI.entitymatching.blocking.embedding.EmbeddingBlocking - Initialized EmbeddingBlocking with sklearn backend, top_k=10, threshold=0.3\n",
      "[DEBUG] PyDI.entitymatching.blocking.embedding.EmbeddingBlocking - Computing embeddings for datasets...\n",
      "[DEBUG] PyDI.entitymatching.blocking.embedding.EmbeddingBlocking - Creating embeddings for dataset1: 4592 records\n",
      "[INFO ] sentence_transformers.SentenceTransformer - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n",
      "[DEBUG] urllib3.connectionpool - https://huggingface.co:443 \"HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/modules.json HTTP/1.1\" 307 0\n",
      "[DEBUG] urllib3.connectionpool - https://huggingface.co:443 \"HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/modules.json HTTP/1.1\" 200 0\n",
      "[DEBUG] urllib3.connectionpool - https://huggingface.co:443 \"HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config_sentence_transformers.json HTTP/1.1\" 307 0\n",
      "[DEBUG] urllib3.connectionpool - https://huggingface.co:443 \"HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config_sentence_transformers.json HTTP/1.1\" 200 0\n",
      "[DEBUG] urllib3.connectionpool - https://huggingface.co:443 \"HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/README.md HTTP/1.1\" 307 0\n",
      "[DEBUG] urllib3.connectionpool - https://huggingface.co:443 \"HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/README.md HTTP/1.1\" 200 0\n",
      "[DEBUG] urllib3.connectionpool - https://huggingface.co:443 \"HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/modules.json HTTP/1.1\" 307 0\n",
      "[DEBUG] urllib3.connectionpool - https://huggingface.co:443 \"HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/modules.json HTTP/1.1\" 200 0\n",
      "[DEBUG] urllib3.connectionpool - https://huggingface.co:443 \"HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/sentence_bert_config.json HTTP/1.1\" 307 0\n",
      "[DEBUG] urllib3.connectionpool - https://huggingface.co:443 \"HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/sentence_bert_config.json HTTP/1.1\" 200 0\n",
      "[DEBUG] urllib3.connectionpool - https://huggingface.co:443 \"HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1\" 307 0\n",
      "[DEBUG] urllib3.connectionpool - https://huggingface.co:443 \"HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json HTTP/1.1\" 200 0\n",
      "[DEBUG] urllib3.connectionpool - https://huggingface.co:443 \"HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1\" 307 0\n",
      "[DEBUG] urllib3.connectionpool - https://huggingface.co:443 \"HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json HTTP/1.1\" 200 0\n",
      "[DEBUG] urllib3.connectionpool - https://huggingface.co:443 \"GET /api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1\" 404 64\n",
      "[DEBUG] urllib3.connectionpool - https://huggingface.co:443 \"GET /api/models/sentence-transformers/all-MiniLM-L6-v2/revision/main HTTP/1.1\" 200 6861\n",
      "[INFO ] sentence_transformers.SentenceTransformer - Use pytorch device_name: cpu\n",
      "[INFO ] PyDI.entitymatching.blocking.embedding.EmbeddingBlocking - Loaded sentence transformer model: sentence-transformers/all-MiniLM-L6-v2\n",
      "[INFO ] PyDI.entitymatching.blocking.embedding.EmbeddingBlocking - created 384d embeddings for first dataset\n",
      "[DEBUG] PyDI.entitymatching.blocking.embedding.EmbeddingBlocking - Creating embeddings for dataset2: 151 records\n",
      "[INFO ] PyDI.entitymatching.blocking.embedding.EmbeddingBlocking - created 384d embeddings for second dataset\n",
      "[DEBUG] PyDI.entitymatching.blocking.embedding.EmbeddingBlocking - Building similarity index for 151 vectors\n",
      "[INFO ] PyDI.entitymatching.blocking.embedding.EmbeddingBlocking - created similarity index with 151 vectors, metric=cosine\n",
      "[INFO ] PyDI.entitymatching.blocking.embedding.EmbeddingBlocking - Debug results written to file: output/debugResultsBlocking_EmbeddingBlocking.csv\n",
      "[DEBUG] PyDI.entitymatching.blocking.embedding.EmbeddingBlocking - Creating candidate record pairs from embedding similarity with threshold 0.3\n"
     ]
    }
   ],
   "source": [
    "# Add title_prefix directly to the original dataframes\n",
    "academy_awards['title_prefix'] = academy_awards['title'].astype(str).str[:3]\n",
    "\n",
    "standard_blocker_aa2a = StandardBlocking(\n",
    "    academy_awards, actors,\n",
    "    on=['title_prefix'],  # Block on first 3 characters of title\n",
    "    batch_size=1000\n",
    ")\n",
    "standard_candidates_aa2a = standard_blocker_aa2a.materialize()\n",
    "\n",
    "sn_blocker_aa2a = SortedNeighbourhood(\n",
    "    academy_awards, actors,\n",
    "    key='title',  # Sort by title\n",
    "    window=10,     # Compare with 5 neighbors\n",
    "    batch_size=1000\n",
    ")\n",
    "sn_candidates_aa2a = sn_blocker_aa2a.materialize()\n",
    "\n",
    "token_blocker_aa2a = TokenBlocking(\n",
    "    academy_awards, actors,\n",
    "    column='title',      # Tokenize titles\n",
    "    min_token_len=5,     # Ignore very short tokens\n",
    "    batch_size=1000\n",
    ")\n",
    "token_candidates_aa2a = token_blocker_aa2a.materialize()\n",
    "\n",
    "embedding_blocker_aa2a = EmbeddingBlocking(\n",
    "    academy_awards, actors,\n",
    "    text_cols=['title'],\n",
    "    model=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    index_backend=\"sklearn\",\n",
    "    top_k=10,          # Top 10 most similar\n",
    "    batch_size=500\n",
    ")\n",
    "embedding_candidates_aa2a = embedding_blocker_aa2a.materialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's evaluate which blocking method we want to use for each dataset combination:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO ] root -   Pair Completeness: 0.385\n",
      "[INFO ] root -   Pair Quality:      0.014\n",
      "[INFO ] root -   Reduction Ratio:   0.998\n",
      "[INFO ] root -   True Matches Found: 10/26\n",
      "[INFO ] root - Blocking evaluation complete: Completeness=0.3846 Quality=0.0136 Reduction=0.9979\n",
      "[INFO ] root -   Pair Completeness: 0.385\n",
      "[INFO ] root -   Pair Quality:      0.004\n",
      "[INFO ] root -   Reduction Ratio:   0.993\n",
      "[INFO ] root -   True Matches Found: 10/26\n",
      "[INFO ] root - Blocking evaluation complete: Completeness=0.3846 Quality=0.0042 Reduction=0.9932\n",
      "[INFO ] root -   Pair Completeness: 0.846\n",
      "[INFO ] root -   Pair Quality:      0.051\n",
      "[INFO ] root -   Reduction Ratio:   0.999\n",
      "[INFO ] root -   True Matches Found: 22/26\n",
      "[INFO ] root - Blocking evaluation complete: Completeness=0.8462 Quality=0.0510 Reduction=0.9988\n",
      "[INFO ] root -   Pair Completeness: 1.000\n",
      "[INFO ] root -   Pair Quality:      0.017\n",
      "[INFO ] root -   Reduction Ratio:   0.996\n",
      "[INFO ] root -   True Matches Found: 26/26\n",
      "[INFO ] root - Blocking evaluation complete: Completeness=1.0000 Quality=0.0174 Reduction=0.9957\n",
      "[INFO ] root -   Pair Completeness: 0.872\n",
      "[INFO ] root -   Pair Quality:      0.001\n",
      "[INFO ] root -   Reduction Ratio:   0.950\n",
      "[INFO ] root -   True Matches Found: 41/47\n",
      "[INFO ] root - Blocking evaluation complete: Completeness=0.8723 Quality=0.0012 Reduction=0.9503\n",
      "[INFO ] root -   Pair Completeness: 0.872\n",
      "[INFO ] root -   Pair Quality:      0.014\n",
      "[INFO ] root -   Reduction Ratio:   0.996\n",
      "[INFO ] root -   True Matches Found: 41/47\n",
      "[INFO ] root - Blocking evaluation complete: Completeness=0.8723 Quality=0.0139 Reduction=0.9958\n",
      "[INFO ] root -   Pair Completeness: 0.681\n",
      "[INFO ] root -   Pair Quality:      0.035\n",
      "[INFO ] root -   Reduction Ratio:   0.999\n",
      "[INFO ] root -   True Matches Found: 32/47\n",
      "[INFO ] root - Blocking evaluation complete: Completeness=0.6809 Quality=0.0350 Reduction=0.9987\n",
      "[INFO ] root -   Pair Completeness: 0.894\n",
      "[INFO ] root -   Pair Quality:      0.001\n",
      "[INFO ] root -   Reduction Ratio:   0.956\n",
      "[INFO ] root -   True Matches Found: 42/47\n",
      "[INFO ] root - Blocking evaluation complete: Completeness=0.8936 Quality=0.0014 Reduction=0.9565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best blocking for a2g: EmbeddingBlocking (PC: 1.000, RR: 0.996)\n",
      "Best blocking for aa2a: EmbeddingBlocking (PC: 0.894, RR: 0.956)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate all blocking methods for both dataset combinations\n",
    "\n",
    "evaluator = EntityMatchingEvaluator()\n",
    "\n",
    "# Create dictionaries of candidates for both dataset combinations\n",
    "a2g_blocking_candidates = {\n",
    "    'StandardBlocking': [standard_candidates_a2g, standard_blocker_a2g],\n",
    "    'SortedNeighbourhood': [sn_candidates_a2g, sn_blocker_a2g],\n",
    "    'TokenBlocking': [token_candidates_a2g,token_blocker_a2g],\n",
    "    'EmbeddingBlocking': [embedding_candidates_a2g,embedding_blocker_a2g]\n",
    "}\n",
    "\n",
    "aa2a_blocking_candidates = {\n",
    "    'StandardBlocking': [standard_candidates_aa2a,standard_blocker_aa2a],\n",
    "    'SortedNeighbourhood': [sn_candidates_aa2a, sn_blocker_aa2a],\n",
    "    'TokenBlocking': [token_candidates_aa2a,token_blocker_aa2a],\n",
    "    'EmbeddingBlocking': [embedding_candidates_aa2a,embedding_blocker_aa2a]\n",
    "}\n",
    "\n",
    "# Load correspondences for evaluation\n",
    "a2g_correspondences = load_csv(\n",
    "    DATA_DIR / \"entitymatching\" / \"actors_2_golden_globes_test.csv\",\n",
    "    name=\"a2g_test\", header=None, names=['id1', 'id2', 'label'], add_index=False\n",
    ")\n",
    "\n",
    "aa2a_correspondences = load_csv(\n",
    "    DATA_DIR / \"entitymatching\" / \"academy_awards_2_actors_test.csv\",\n",
    "    name=\"aa2a_test\", header=None, names=['id1', 'id2', 'label'], add_index=False\n",
    ")\n",
    "\n",
    "# Evaluate blocking for a2g datasets\n",
    "a2g_results = []\n",
    "for method_name, candidates in a2g_blocking_candidates.items():\n",
    "    result = evaluator.evaluate_blocking(candidates[0], a2g_correspondences,candidates[1], out_dir=OUTPUT_DIR / \"blocking-evaluation\")\n",
    "    result['method'] = method_name\n",
    "    result['dataset'] = 'a2g'\n",
    "    a2g_results.append(result)\n",
    "\n",
    "# Evaluate blocking for aa2a datasets  \n",
    "aa2a_results = []\n",
    "for method_name, candidates in aa2a_blocking_candidates.items():\n",
    "    result = evaluator.evaluate_blocking(candidates[0], aa2a_correspondences,candidates[1], out_dir=OUTPUT_DIR / \"blocking-evaluation\")\n",
    "    result['method'] = method_name\n",
    "    result['dataset'] = 'aa2a'\n",
    "    aa2a_results.append(result)\n",
    "\n",
    "# Select best method for each dataset (highest pair_completeness, then highest reduction_ratio)\n",
    "a2g_best = max(a2g_results, key=lambda x: (x['pair_completeness'], x['reduction_ratio']))\n",
    "aa2a_best = max(aa2a_results, key=lambda x: (x['pair_completeness'], x['reduction_ratio']))\n",
    "\n",
    "print(f\"Best blocking for a2g: {a2g_best['method']} (PC: {a2g_best['pair_completeness']:.3f}, RR: {a2g_best['reduction_ratio']:.3f})\")\n",
    "print(f\"Best blocking for aa2a: {aa2a_best['method']} (PC: {aa2a_best['pair_completeness']:.3f}, RR: {aa2a_best['reduction_ratio']:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Entity Matching with Comparators\n",
    "\n",
    "Now we'll use PyDI's linear matching rule capabilities to find duplicate movies using multiple attribute comparisons.\n",
    "\n",
    "First, we define some comparators for attributes relevant to matching:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyDI.entitymatching import StringComparator, DateComparator, NumericComparator\n",
    "\n",
    "# Create comparators for different attributes\n",
    "comparators = [\n",
    "    # Title similarity - most important for movies\n",
    "    StringComparator(\n",
    "        column='title',\n",
    "        similarity_function='jaro_winkler',  # Good for movie titles\n",
    "        preprocess=str.lower  # Case normalization\n",
    "    ),\n",
    "    \n",
    "    # Date proximity - movies from same year likely same film\n",
    "    DateComparator(\n",
    "        column='date', \n",
    "        max_days_difference=365  # Allow 1 year difference\n",
    "    ),\n",
    "    \n",
    "    # Actor name similarity - supporting evidence\n",
    "    StringComparator(\n",
    "        column='actor_name',\n",
    "        similarity_function='cosine',  # Good for names\n",
    "        preprocess=str.lower\n",
    "    )\n",
    "]\n",
    "\n",
    "# Define attribute weights\n",
    "weights = [0.6, 0.25, 0.15]  # Title most important, then date, then actor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we setup the matcher and run the matching with our chosen best blocking method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO ] PyDI.entitymatching.blocking.embedding.EmbeddingBlocking - Initialized EmbeddingBlocking with sklearn backend, top_k=10, threshold=0.3\n",
      "[INFO ] PyDI.entitymatching.rule_based.RuleBasedMatcher - Starting Identity Resolution\n",
      "[INFO ] PyDI.entitymatching.rule_based.RuleBasedMatcher - Blocking 151 x 2286 elements\n",
      "[DEBUG] PyDI.entitymatching.blocking.embedding.EmbeddingBlocking - Computing embeddings for datasets...\n",
      "[DEBUG] PyDI.entitymatching.blocking.embedding.EmbeddingBlocking - Creating embeddings for dataset1: 151 records\n",
      "[INFO ] sentence_transformers.SentenceTransformer - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n",
      "[DEBUG] urllib3.connectionpool - Resetting dropped connection: huggingface.co\n",
      "[DEBUG] urllib3.connectionpool - https://huggingface.co:443 \"HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/modules.json HTTP/1.1\" 307 0\n",
      "[DEBUG] urllib3.connectionpool - https://huggingface.co:443 \"HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/modules.json HTTP/1.1\" 200 0\n",
      "[DEBUG] urllib3.connectionpool - https://huggingface.co:443 \"HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config_sentence_transformers.json HTTP/1.1\" 307 0\n",
      "[DEBUG] urllib3.connectionpool - https://huggingface.co:443 \"HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config_sentence_transformers.json HTTP/1.1\" 200 0\n",
      "[DEBUG] urllib3.connectionpool - https://huggingface.co:443 \"HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/README.md HTTP/1.1\" 307 0\n",
      "[DEBUG] urllib3.connectionpool - https://huggingface.co:443 \"HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/README.md HTTP/1.1\" 200 0\n",
      "[DEBUG] urllib3.connectionpool - https://huggingface.co:443 \"HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/modules.json HTTP/1.1\" 307 0\n",
      "[DEBUG] urllib3.connectionpool - https://huggingface.co:443 \"HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/modules.json HTTP/1.1\" 200 0\n",
      "[DEBUG] urllib3.connectionpool - https://huggingface.co:443 \"HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/sentence_bert_config.json HTTP/1.1\" 307 0\n",
      "[DEBUG] urllib3.connectionpool - https://huggingface.co:443 \"HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/sentence_bert_config.json HTTP/1.1\" 200 0\n",
      "[DEBUG] urllib3.connectionpool - https://huggingface.co:443 \"HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1\" 307 0\n",
      "[DEBUG] urllib3.connectionpool - https://huggingface.co:443 \"HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json HTTP/1.1\" 200 0\n",
      "[DEBUG] urllib3.connectionpool - https://huggingface.co:443 \"HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1\" 307 0\n",
      "[DEBUG] urllib3.connectionpool - https://huggingface.co:443 \"HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json HTTP/1.1\" 200 0\n",
      "[DEBUG] urllib3.connectionpool - https://huggingface.co:443 \"GET /api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1\" 404 64\n",
      "[DEBUG] urllib3.connectionpool - https://huggingface.co:443 \"GET /api/models/sentence-transformers/all-MiniLM-L6-v2/revision/main HTTP/1.1\" 200 6861\n",
      "[INFO ] sentence_transformers.SentenceTransformer - Use pytorch device_name: cpu\n",
      "[INFO ] PyDI.entitymatching.blocking.embedding.EmbeddingBlocking - Loaded sentence transformer model: sentence-transformers/all-MiniLM-L6-v2\n",
      "[INFO ] PyDI.entitymatching.blocking.embedding.EmbeddingBlocking - created 384d embeddings for first dataset\n",
      "[DEBUG] PyDI.entitymatching.blocking.embedding.EmbeddingBlocking - Creating embeddings for dataset2: 2286 records\n",
      "[INFO ] PyDI.entitymatching.blocking.embedding.EmbeddingBlocking - created 384d embeddings for second dataset\n",
      "[DEBUG] PyDI.entitymatching.blocking.embedding.EmbeddingBlocking - Building similarity index for 2286 vectors\n",
      "[INFO ] PyDI.entitymatching.blocking.embedding.EmbeddingBlocking - created similarity index with 2286 vectors, metric=cosine\n",
      "[INFO ] PyDI.entitymatching.blocking.embedding.EmbeddingBlocking - Debug results written to file: output/debugResultsBlocking_EmbeddingBlocking.csv\n",
      "[DEBUG] PyDI.entitymatching.blocking.embedding.EmbeddingBlocking - Creating candidate record pairs from embedding similarity with threshold 0.3\n",
      "[INFO ] PyDI.entitymatching.rule_based.RuleBasedMatcher - Matching 151 x 2286 elements after 0:00:2.314; 1497 blocked pairs (reduction ratio: 0.9956632076619562)\n",
      "[DEBUG] PyDI.entitymatching.blocking.embedding.EmbeddingBlocking - Creating candidate record pairs from embedding similarity with threshold 0.3\n",
      "[INFO ] PyDI.entitymatching.rule_based.RuleBasedMatcher - Identity Resolution finished after 0:00:2.964; found 109 correspondences.\n"
     ]
    }
   ],
   "source": [
    "from PyDI.entitymatching import RuleBasedMatcher\n",
    "\n",
    "# Initialize the blocker\n",
    "embedding_blocker_a2g = EmbeddingBlocking(\n",
    "    actors, golden_globes,\n",
    "    text_cols=['title'],\n",
    "    model=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    index_backend=\"sklearn\",\n",
    "    top_k=10,          # Top 10 most similar\n",
    "    batch_size=500\n",
    ")\n",
    "\n",
    "# Initialize Rule-Based Matcher\n",
    "matcher = RuleBasedMatcher()\n",
    "\n",
    "correspondences_a2g = matcher.match(\n",
    "    df_left=actors,\n",
    "    df_right=golden_globes, \n",
    "    candidates=embedding_blocker_a2g, # pass the blocker, which will internally generate candidate pairs using batching\n",
    "    comparators=comparators,\n",
    "    weights=weights,\n",
    "    threshold=0.7 # set a similarity threshold for a match\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Evaluation Against Ground Truth ===\n",
      "Loading Winter framework's ground truth correspondences...\n",
      "\n",
      "Training ground truth: 335 pairs\n",
      "Test ground truth: 3,347 pairs\n",
      "Training set: 103 positive matches out of 335 pairs (30.7%)\n",
      "Test set: 47 positive matches out of 3,347 pairs (1.4%)\n",
      "\n",
      "üéØ We'll evaluate against the test set (3,347 pairs)\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Evaluation Against Ground Truth ===\")\n",
    "print(\"Loading Winter framework's ground truth correspondences...\\n\")\n",
    "\n",
    "# Load ground truth correspondences\n",
    "gt_train = load_csv(\n",
    "    DATA_DIR / \"entitymatching\" / \"splits\" / \"academy_awards_2_actors_training.csv\",\n",
    "    name=\"ground_truth_train\",\n",
    "    header=None,\n",
    "    names=['id1', 'id2', 'label'],\n",
    "    add_index=False\n",
    ")\n",
    "\n",
    "gt_test = load_csv(\n",
    "    DATA_DIR / \"entitymatching\" / \"splits\" / \"academy_awards_2_actors_test.csv\", \n",
    "    name=\"ground_truth_test\",\n",
    "    header=None,\n",
    "    names=['id1', 'id2', 'label'],\n",
    "    add_index=False\n",
    ")\n",
    "\n",
    "print(f\"Training ground truth: {len(gt_train):,} pairs\")\n",
    "print(f\"Test ground truth: {len(gt_test):,} pairs\")\n",
    "\n",
    "# Analyze label distribution\n",
    "for name, gt in [('Training', gt_train), ('Test', gt_test)]:\n",
    "    true_matches = (gt['label'] == 'TRUE').sum() if 'TRUE' in gt['label'].values else (gt['label'] == True).sum()\n",
    "    total = len(gt)\n",
    "    print(f\"{name} set: {true_matches:,} positive matches out of {total:,} pairs ({true_matches/total*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nüéØ We'll evaluate against the test set ({len(gt_test):,} pairs)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Entity Matching Evaluation Results ===\n",
      "Performance Metrics:\n",
      "  Accuracy:  0.976\n",
      "  Precision: 0.342\n",
      "  Recall:    0.830\n",
      "  F1-Score:  0.484\n",
      "Confusion Matrix:\n",
      "  True Positives:  39\n",
      "  True Negatives:  3299\n",
      "  False Positives: 75\n",
      "  False Negatives: 8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'precision': 0.34210526315789475,\n",
       " 'recall': 0.8297872340425532,\n",
       " 'f1': 0.484472049689441,\n",
       " 'accuracy': 0.9757380882782812,\n",
       " 'true_positives': 39,\n",
       " 'false_positives': 75,\n",
       " 'false_negatives': 8,\n",
       " 'true_negatives': 3299,\n",
       " 'threshold_used': 0.0,\n",
       " 'total_correspondences': 114,\n",
       " 'filtered_correspondences': 114,\n",
       " 'evaluation_timestamp': '2025-09-09T15:12:55.279738',\n",
       " 'output_files': ['c:\\\\Users\\\\Ralph\\\\dev\\\\pydi\\\\output\\\\tutorial\\\\matching_evaluation_summary.json',\n",
       "  'c:\\\\Users\\\\Ralph\\\\dev\\\\pydi\\\\output\\\\tutorial\\\\matching_detailed_results.csv']}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Perform evaluation using PyDI's EntityMatchingEvaluator\n",
    "print(\"\\n=== Entity Matching Evaluation Results ===\")\n",
    "\n",
    "# Use the new evaluate_matching method for cleaner evaluation\n",
    "eval_results = EntityMatchingEvaluator.evaluate_matching(\n",
    "    correspondences=matches,\n",
    "    test_pairs=gt_test,\n",
    "    out_dir=str(OUTPUT_DIR)\n",
    ")\n",
    "\n",
    "display(eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Re-running matcher with debug mode to capture detailed results:\n",
      "  Using 1030 actual candidate pairs from Embedding blocking\n",
      "  Found 114 matches in 0.514 seconds with debug enabled\n",
      "  ‚úÖ Full debug results: debugResultsMatchingRule.csv\n",
      "  ‚úÖ Short debug results: debugResultsMatchingRule.csv_short\n",
      "üìÅ Debug files saved to: c:\\Users\\Ralph\\dev\\pydi\\output\\tutorial\\debug_results\n"
     ]
    }
   ],
   "source": [
    "# Re-run the matcher with debug mode enabled to get detailed debug data\n",
    "print(\"üîç Re-running matcher with debug mode to capture detailed results:\")\n",
    "\n",
    "# Use the same candidates and settings from before\n",
    "candidates_df = pd.DataFrame(best_candidates)\n",
    "print(f\"  Using {len(candidates_df)} actual candidate pairs from {best_method} blocking\")\n",
    "\n",
    "# Re-run matching with debug enabled to capture detailed comparator results\n",
    "start_time = time.time()\n",
    "\n",
    "# Enable debug mode in the matcher to capture detailed results\n",
    "matches, debug_info = matcher.match(\n",
    "    df_left=left_df,\n",
    "    df_right=right_df, \n",
    "    candidates=[candidates_df],\n",
    "    comparators=comparators,\n",
    "    weights=weights,\n",
    "    threshold=0.7,\n",
    "    debug=True  # This enables debug output capture\n",
    ")\n",
    "\n",
    "matching_time = time.time() - start_time\n",
    "print(f\"  Found {len(matches)} matches in {matching_time:.3f} seconds with debug enabled\")\n",
    "\n",
    "debug_output_dir = OUTPUT_DIR / \"debug_results\"\n",
    "debug_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Call the write_debug_results function with actual results\n",
    "full_debug_path, short_debug_path = EntityMatchingEvaluator.write_debug_results(\n",
    "    correspondences=matches,\n",
    "    debug_results=debug_info,\n",
    "    out_dir=str(debug_output_dir),\n",
    "    matcher_instance=matcher\n",
    ")\n",
    "\n",
    "print(f\"  ‚úÖ Full debug results: {Path(full_debug_path).name}\")\n",
    "print(f\"  ‚úÖ Short debug results: {Path(short_debug_path).name}\")\n",
    "\n",
    "print(f\"üìÅ Debug files saved to: {debug_output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Demonstrating Cluster Size Distribution Analysis ===\n",
      "Analyzing cluster size distribution in our entity matching results...\n",
      "\n",
      "üìä Cluster Size Distribution Results:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster_size</th>\n",
       "      <th>frequency</th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>110</td>\n",
       "      <td>98.214286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1.785714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cluster_size  frequency  percentage\n",
       "0             2        110   98.214286\n",
       "1             3          2    1.785714"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"=== Demonstrating Cluster Size Distribution Analysis ===\")\n",
    "print(\"Analyzing cluster size distribution in our entity matching results...\")\n",
    "\n",
    "# Create cluster size distribution from our matches\n",
    "cluster_distribution = EntityMatchingEvaluator.create_cluster_size_distribution(\n",
    "    correspondences=matches,\n",
    "    out_dir=str(OUTPUT_DIR / \"cluster_analysis\")\n",
    ")\n",
    "\n",
    "print(f\"\\nüìä Cluster Size Distribution Results:\")\n",
    "display(cluster_distribution)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write out detailed cluster information with all entity records for debugging purposes\n",
    "\n",
    "# Use the matches we found earlier to demonstrate cluster details\n",
    "cluster_details_path = OUTPUT_DIR / \"cluster_analysis\" / \"detailed_cluster_info.json\"\n",
    "cluster_details_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Call write_cluster_details with our entity matches\n",
    "output_path = EntityMatchingEvaluator.write_cluster_details(\n",
    "    correspondences=matches,\n",
    "    out_path=str(cluster_details_path)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Machine Learning-based Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ML-Based Matching with Similarity Features ===\n",
      "Demonstrating MLBasedMatcher with FeatureExtractor using GridSearchCV\n",
      "Training on gt_train and testing on gt_test\n",
      "\n",
      "\n",
      "üîß Creating Similarity-Based FeatureExtractor...\n",
      "‚úÖ Created FeatureExtractor with 7 similarity features\n",
      "Feature names: ['StringComparator(title, jaro_winkler)', 'StringComparator(title, levenshtein)', 'StringComparator(title, cosine)', 'StringComparator(title, jaccard)', 'DateComparator(date)', 'StringComparator(actor_name, jaro_winkler)', 'StringComparator(actor_name, cosine)']\n",
      "\n",
      "‚öôÔ∏è Extracting Features from Training Pairs...\n",
      "Valid training pairs: 335 out of 335\n",
      "‚úÖ Training features extracted: (335, 10)\n",
      "Feature columns: ['StringComparator(title, jaro_winkler)', 'StringComparator(title, levenshtein)', 'StringComparator(title, cosine)', 'StringComparator(title, jaccard)', 'DateComparator(date)', 'StringComparator(actor_name, jaro_winkler)', 'StringComparator(actor_name, cosine)']\n",
      "Training data: X=(335, 7), y=(335,)\n",
      "Class distribution: {0: 232, 1: 103}\n"
     ]
    }
   ],
   "source": [
    "print(\"=== ML-Based Matching with Similarity Features ===\")\n",
    "print(\"Demonstrating MLBasedMatcher with FeatureExtractor using GridSearchCV\")\n",
    "print(\"Training on gt_train and testing on gt_test\\n\")\n",
    "\n",
    "# Convert string labels to numeric\n",
    "gt_train['label'] = gt_train['label'].map({'TRUE': 1, 'FALSE': 0, True: 1, False: 0})\n",
    "gt_test['label'] = gt_test['label'].map({'TRUE': 1, 'FALSE': 0, True: 1, False: 0})\n",
    "\n",
    "# Create similarity-based FeatureExtractor \n",
    "print(\"\\nüîß Creating Similarity-Based FeatureExtractor...\")\n",
    "\n",
    "similarity_comparators = [\n",
    "    # Title similarity features - most important for movie matching\n",
    "    StringComparator(\"title\", similarity_function=\"jaro_winkler\", preprocess=str.lower),\n",
    "    StringComparator(\"title\", similarity_function=\"levenshtein\", preprocess=str.lower),\n",
    "    StringComparator(\"title\", similarity_function=\"cosine\", preprocess=str.lower),\n",
    "    StringComparator(\"title\", similarity_function=\"jaccard\", preprocess=str.lower),\n",
    "    \n",
    "    # Date proximity features\n",
    "    DateComparator(\"date\", max_days_difference=730),  # 2 years tolerance\n",
    "    \n",
    "    # Actor name similarity\n",
    "    StringComparator(\"actor_name\", similarity_function=\"jaro_winkler\", preprocess=str.lower),\n",
    "    StringComparator(\"actor_name\", similarity_function=\"cosine\", preprocess=str.lower),\n",
    "]\n",
    "\n",
    "feature_extractor = FeatureExtractor(similarity_comparators)\n",
    "print(f\"‚úÖ Created FeatureExtractor with {len(similarity_comparators)} similarity features\")\n",
    "print(f\"Feature names: {feature_extractor.get_feature_names()}\")\n",
    "\n",
    "# Extract training features\n",
    "print(f\"\\n‚öôÔ∏è Extracting Features from Training Pairs...\")\n",
    "\n",
    "# Filter training pairs to ensure both records exist\n",
    "valid_train_pairs = []\n",
    "valid_train_labels = []\n",
    "\n",
    "for _, row in gt_train.iterrows():\n",
    "    id1, id2, label = row['id1'], row['id2'], row['label']\n",
    "    if (id1 in left_df['_id'].values and id2 in right_df['_id'].values):\n",
    "        valid_train_pairs.append({'id1': id1, 'id2': id2})\n",
    "        valid_train_labels.append(label)\n",
    "\n",
    "train_pairs_df = pd.DataFrame(valid_train_pairs)\n",
    "train_labels_series = pd.Series(valid_train_labels)\n",
    "\n",
    "print(f\"Valid training pairs: {len(train_pairs_df)} out of {len(gt_train)}\")\n",
    "\n",
    "# Extract features using FeatureExtractor\n",
    "train_features = feature_extractor.create_features(\n",
    "    left_df, right_df, train_pairs_df, labels=train_labels_series\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Training features extracted: {train_features.shape}\")\n",
    "print(f\"Feature columns: {[col for col in train_features.columns if col not in ['id1', 'id2', 'label']]}\")\n",
    "\n",
    "# Prepare data for ML training\n",
    "feature_columns = [col for col in train_features.columns if col not in ['id1', 'id2', 'label']]\n",
    "\n",
    "X_train = train_features[feature_columns]\n",
    "y_train = train_features['label']\n",
    "\n",
    "print(f\"Training data: X={X_train.shape}, y={y_train.shape}\")\n",
    "print(f\"Class distribution: {y_train.value_counts().to_dict()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Full Scikit-learn integration\n",
    "\n",
    "From here on out, the full scikit-learn library can be used with the features extracted from PyDIs feature extractor without any wrapping as everything in PyDI is based on pandas dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Setting up GridSearchCV...\n",
      "GridSearch setup: 4 models, F1 scoring, 5-fold CV\n",
      "\n",
      "üöÄ Training Models with GridSearchCV...\n",
      "\n",
      "Training RandomForest...\n",
      "  ‚úÖ RandomForest: Best CV F1 = 0.9853\n",
      "     Best params: {'class_weight': 'balanced', 'max_depth': 5, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "\n",
      "Training LogisticRegression...\n",
      "  ‚úÖ LogisticRegression: Best CV F1 = 0.9953\n",
      "     Best params: {'C': 1.0, 'class_weight': 'balanced', 'penalty': 'l2'}\n",
      "\n",
      "Training GradientBoosting...\n",
      "  ‚úÖ GradientBoosting: Best CV F1 = 0.9953\n",
      "     Best params: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100}\n",
      "\n",
      "Training SVM...\n",
      "  ‚úÖ SVM: Best CV F1 = 0.9953\n",
      "     Best params: {'C': 0.1, 'class_weight': 'balanced', 'kernel': 'rbf'}\n",
      "\n",
      "üèÜ Best Overall Model: LogisticRegression (CV F1: 0.9953)\n"
     ]
    }
   ],
   "source": [
    "# Set up GridSearchCV with multiple models and hyperparameters\n",
    "print(f\"\\nüîç Setting up GridSearchCV...\")\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "\n",
    "# Define models and parameter grids\n",
    "param_grids = {\n",
    "    'RandomForest': {\n",
    "        'model': RandomForestClassifier(random_state=42),\n",
    "        'params': {\n",
    "            'n_estimators': [50, 100, 200],\n",
    "            'max_depth': [5, 10, None],\n",
    "            'min_samples_split': [2, 5],\n",
    "            'class_weight': ['balanced', None]\n",
    "        }\n",
    "    },\n",
    "    'LogisticRegression': {\n",
    "        'model': LogisticRegression(random_state=42, max_iter=1000),\n",
    "        'params': {\n",
    "            'C': [0.1, 1.0, 10.0],\n",
    "            'penalty': ['l2'],\n",
    "            'class_weight': ['balanced', None]\n",
    "        }\n",
    "    },\n",
    "    'GradientBoosting': {\n",
    "        'model': GradientBoostingClassifier(random_state=42),\n",
    "        'params': {\n",
    "            'n_estimators': [50, 100],\n",
    "            'learning_rate': [0.1, 0.2],\n",
    "            'max_depth': [3, 5],\n",
    "        }\n",
    "    },\n",
    "    'SVM': {\n",
    "        'model': SVC(random_state=42, probability=True),\n",
    "        'params': {\n",
    "            'C': [0.1, 1.0, 10.0],\n",
    "            'kernel': ['rbf', 'linear'],\n",
    "            'class_weight': ['balanced', None]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Use F1 score as the scoring metric (good for imbalanced data)\n",
    "scorer = make_scorer(f1_score)\n",
    "cv_folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "print(f\"GridSearch setup: {len(param_grids)} models, F1 scoring, 5-fold CV\")\n",
    "\n",
    "# Train models using GridSearchCV\n",
    "print(f\"\\nüöÄ Training Models with GridSearchCV...\")\n",
    "\n",
    "grid_search_results = {}\n",
    "best_overall_score = -1\n",
    "best_overall_model = None\n",
    "best_model_name = None\n",
    "\n",
    "for model_name, config in param_grids.items():\n",
    "    print(f\"\\nTraining {model_name}...\")\n",
    "    \n",
    "\n",
    "    # Create GridSearchCV\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=config['model'],\n",
    "        param_grid=config['params'],\n",
    "        scoring=scorer,\n",
    "        cv=cv_folds,\n",
    "        n_jobs=-1,  # Use all available cores\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    # Fit GridSearchCV\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Store results\n",
    "    grid_search_results[model_name] = {\n",
    "        'grid_search': grid_search,\n",
    "        'best_score': grid_search.best_score_,\n",
    "        'best_params': grid_search.best_params_,\n",
    "        'best_estimator': grid_search.best_estimator_\n",
    "    }\n",
    "    \n",
    "    print(f\"  ‚úÖ {model_name}: Best CV F1 = {grid_search.best_score_:.4f}\")\n",
    "    print(f\"     Best params: {grid_search.best_params_}\")\n",
    "    \n",
    "    # Track overall best model\n",
    "    if grid_search.best_score_ > best_overall_score:\n",
    "        best_overall_score = grid_search.best_score_\n",
    "        best_overall_model = grid_search.best_estimator_\n",
    "        best_model_name = model_name\n",
    "            \n",
    "print(f\"\\nüèÜ Best Overall Model: {best_model_name} (CV F1: {best_overall_score:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéØ Testing Best Model on Test Set...\n",
      "Valid test pairs: 3347 out of 3347\n"
     ]
    }
   ],
   "source": [
    "# Apply best trained model using MLBasedMatcher on test data\n",
    "print(f\"\\nüéØ Testing Best Model on Test Set...\")\n",
    "\n",
    "\n",
    "# Prepare test pairs\n",
    "valid_test_pairs = []\n",
    "valid_test_labels = []\n",
    "\n",
    "for _, row in gt_test.iterrows():\n",
    "    id1, id2, label = row['id1'], row['id2'], row['label']\n",
    "    if (id1 in left_df['_id'].values and id2 in right_df['_id'].values):\n",
    "        valid_test_pairs.append({'id1': id1, 'id2': id2})\n",
    "        valid_test_labels.append(label)\n",
    "\n",
    "test_pairs_df = pd.DataFrame(valid_test_pairs)\n",
    "test_labels_series = pd.Series(valid_test_labels)\n",
    "\n",
    "print(f\"Valid test pairs: {len(test_pairs_df)} out of {len(gt_test)}\")\n",
    "\n",
    "\n",
    "# Create MLBasedMatcher and apply trained model\n",
    "ml_matcher = MLBasedMatcher(feature_extractor)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "matches = ml_matcher.match(\n",
    "    left_df, right_df, [test_pairs_df], best_overall_model\n",
    ")\n",
    "\n",
    "# Show feature importance if available\n",
    "if hasattr(best_overall_model, 'feature_importances_'):\n",
    "    print(f\"\\nüîç Top Feature Importances:\")\n",
    "    importance_df = ml_matcher.get_feature_importance(best_overall_model, feature_columns)\n",
    "    display(importance_df.head(8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's evaluate the ML-based matching with the evaluator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ML-based Entity Matching Evaluation Results ===\n",
      "Performance Metrics:\n",
      "  Accuracy:  0.998\n",
      "  Precision: 0.870\n",
      "  Recall:    1.000\n",
      "  F1-Score:  0.931\n",
      "Confusion Matrix:\n",
      "  True Positives:  47\n",
      "  True Negatives:  3293\n",
      "  False Positives: 7\n",
      "  False Negatives: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'precision': 0.8703703703703703,\n",
       " 'recall': 1.0,\n",
       " 'f1': 0.9306930693069307,\n",
       " 'accuracy': 0.9979085748431431,\n",
       " 'true_positives': 47,\n",
       " 'false_positives': 7,\n",
       " 'false_negatives': 0,\n",
       " 'true_negatives': 3293,\n",
       " 'threshold_used': 0.0,\n",
       " 'total_correspondences': 54,\n",
       " 'filtered_correspondences': 54,\n",
       " 'evaluation_timestamp': '2025-09-09T15:13:01.824437',\n",
       " 'output_files': ['c:\\\\Users\\\\Ralph\\\\dev\\\\pydi\\\\output\\\\tutorial\\\\matching_evaluation_summary.json',\n",
       "  'c:\\\\Users\\\\Ralph\\\\dev\\\\pydi\\\\output\\\\tutorial\\\\matching_detailed_results.csv']}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Cluster Size Distribution Analysis ===\n",
      "\n",
      "üìä Cluster Size Distribution Results:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster_size</th>\n",
       "      <th>frequency</th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>48</td>\n",
       "      <td>94.117647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5.882353</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cluster_size  frequency  percentage\n",
       "0             2         48   94.117647\n",
       "1             3          3    5.882353"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Perform evaluation using PyDI's EntityMatchingEvaluator\n",
    "print(\"\\n=== ML-based Entity Matching Evaluation Results ===\")\n",
    "\n",
    "# Use the new evaluate_matching method for cleaner evaluation\n",
    "eval_results = EntityMatchingEvaluator.evaluate_matching(\n",
    "    correspondences=matches,\n",
    "    test_pairs=gt_test,\n",
    "    out_dir=str(OUTPUT_DIR)\n",
    ")\n",
    "\n",
    "display(eval_results)\n",
    "\n",
    "print(\"=== Cluster Size Distribution Analysis ===\")\n",
    "\n",
    "# Create cluster size distribution from our matches\n",
    "cluster_distribution = EntityMatchingEvaluator.create_cluster_size_distribution(\n",
    "    correspondences=matches,\n",
    "    out_dir=str(OUTPUT_DIR / \"cluster_analysis\")\n",
    ")\n",
    "\n",
    "print(f\"\\nüìä Cluster Size Distribution Results:\")\n",
    "display(cluster_distribution)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively to similarity metrics for each attribute, PyDIs VectorFeatureExtractor can be used to create embeddings using SentenceTransformers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SentenceTransformer features shape: (1030, 3)\n"
     ]
    }
   ],
   "source": [
    "# VectorFeatureExtractor Examples\n",
    "\n",
    "from PyDI.entitymatching import VectorFeatureExtractor\n",
    "\n",
    "# SentenceTransformers embeddings using VectorFeatureExtractor\n",
    "st_extractor = VectorFeatureExtractor(\n",
    "    embedding_model='sentence-transformers/all-MiniLM-L6-v2',\n",
    "    columns=['title', 'actor_name', 'date'],\n",
    "    distance_metrics=['cosine'],\n",
    "    pooling_strategy='concatenate'\n",
    ")\n",
    "\n",
    "st_features = st_extractor.create_features(\n",
    "    left_df, right_df, candidates_df\n",
    ")\n",
    "print(f\"SentenceTransformer features shape: {st_features.shape}\")\n",
    "\n",
    "# Extract features using FeatureExtractor\n",
    "train_features = feature_extractor.create_features(\n",
    "    left_df, right_df, train_pairs_df, labels=train_labels_series\n",
    ")\n",
    "\n",
    "# ready to train ML models with scikit-learn as before\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Data Fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Fusion Input Datasets:\n",
      "  Academy Awards: 4,592 records\n",
      "  Actors: 149 records\n",
      "  Golden Globes: 2,286 records\n",
      "  Total: 7,027 records\n",
      "\n",
      "üéØ Goal: Create single authoritative movie record per entity\n"
     ]
    }
   ],
   "source": [
    "print(\"üìä Fusion Input Datasets:\")\n",
    "for df, name in zip(datasets, names):\n",
    "    print(f\"  {name}: {len(df):,} records\")\n",
    "\n",
    "total_input_records = sum(len(df) for df in datasets)\n",
    "print(f\"  Total: {total_input_records:,} records\")\n",
    "print(f\"\\nüéØ Goal: Create single authoritative movie record per entity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Loading Correspondence Files\n",
    "\n",
    "Data fusion requires correspondence information to group records referring to the same entity. Let's load the pre-computed correspondences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Loading Correspondences for Data Fusion ===\n",
      "Academy Awards ‚Üî Actors correspondences: 150\n",
      "Actors ‚Üî Golden Globes correspondences: 107\n",
      "\n",
      "üìä Correspondence Structure:\n",
      "Academy Awards ‚Üî Actors:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id1</th>\n",
       "      <th>id2</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>academy_awards_4557</td>\n",
       "      <td>actors_1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>academy_awards_4529</td>\n",
       "      <td>actors_2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>academy_awards_4500</td>\n",
       "      <td>actors_3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>academy_awards_4475</td>\n",
       "      <td>actors_4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>academy_awards_4446</td>\n",
       "      <td>actors_5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id1       id2  score\n",
       "0  academy_awards_4557  actors_1    1.0\n",
       "1  academy_awards_4529  actors_2    1.0\n",
       "2  academy_awards_4500  actors_3    1.0\n",
       "3  academy_awards_4475  actors_4    1.0\n",
       "4  academy_awards_4446  actors_5    1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actors ‚Üî Golden Globes:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id1</th>\n",
       "      <th>id2</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>actors_16</td>\n",
       "      <td>golden_globes_2279</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>actors_22</td>\n",
       "      <td>golden_globes_2263</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>actors_23</td>\n",
       "      <td>golden_globes_2252</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>actors_24</td>\n",
       "      <td>golden_globes_2240</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>actors_25</td>\n",
       "      <td>golden_globes_2226</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id1                 id2  score\n",
       "0  actors_16  golden_globes_2279    1.0\n",
       "1  actors_22  golden_globes_2263    1.0\n",
       "2  actors_23  golden_globes_2252    1.0\n",
       "3  actors_24  golden_globes_2240    1.0\n",
       "4  actors_25  golden_globes_2226    1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load pre-computed correspondences from the Winter framework\n",
    "print(\"=== Loading Correspondences for Data Fusion ===\")\n",
    "\n",
    "CORR_DIR = ROOT / \"input\" / \"movies\" / \"fusion\" / \"correspondences\"\n",
    "\n",
    "# Load correspondence files\n",
    "academy_actors_corr = load_csv(\n",
    "    CORR_DIR / \"academy_awards_2_actors_correspondences.csv\",\n",
    "    name=\"academy_actors_correspondences\",\n",
    "    header=None,\n",
    "    names=['id1', 'id2', 'score'],\n",
    "    add_index=False\n",
    ")\n",
    "\n",
    "actors_globes_corr = load_csv(\n",
    "    CORR_DIR / \"actors_2_golden_globes_correspondences.csv\", \n",
    "    name=\"actors_globes_correspondences\",\n",
    "    header=None,\n",
    "    names=['id1', 'id2', 'score'],\n",
    "    add_index=False\n",
    ")\n",
    "\n",
    "print(f\"Academy Awards ‚Üî Actors correspondences: {len(academy_actors_corr):,}\")\n",
    "print(f\"Actors ‚Üî Golden Globes correspondences: {len(actors_globes_corr):,}\")\n",
    "\n",
    "# Preview correspondence structure\n",
    "print(\"\\nüìä Correspondence Structure:\")\n",
    "print(\"Academy Awards ‚Üî Actors:\")\n",
    "display(academy_actors_corr.head())\n",
    "\n",
    "print(\"Actors ‚Üî Golden Globes:\")\n",
    "display(actors_globes_corr.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Running Fusion using correspondences to build record groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total correspondences: 257\n"
     ]
    }
   ],
   "source": [
    "# Combine all correspondences into a single list\n",
    "all_correspondences = []\n",
    "\n",
    "# Add Academy Awards ‚Üî Actors correspondences\n",
    "for _, row in academy_actors_corr.iterrows():\n",
    "    all_correspondences.append((row['id1'], row['id2'], row['score']))\n",
    "    \n",
    "# Add Actors ‚Üî Golden Globes correspondences  \n",
    "for _, row in actors_globes_corr.iterrows():\n",
    "    all_correspondences.append((row['id1'], row['id2'], row['score']))\n",
    "\n",
    "all_correspondences = pd.DataFrame(all_correspondences, columns=['id1', 'id2', 'score'])\n",
    "\n",
    "print(f\"Total correspondences: {len(all_correspondences):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PyDI Data Fusion Framework Demonstration ===\n",
      "\n",
      "‚úÖ Strategy 'movie_fusion' configured with 6 rules\n"
     ]
    }
   ],
   "source": [
    "print(\"=== PyDI Data Fusion Framework Demonstration ===\")\n",
    "\n",
    "# Import additional fusion components needed\n",
    "from PyDI.fusion import AttributeValueFuser\n",
    "\n",
    "# Initialize the fusion strategy\n",
    "fusion_strategy = DataFusionStrategy(\"movie_fusion\")\n",
    "\n",
    "# Title: Use longest string (often more complete)\n",
    "fusion_strategy.add_attribute_fuser(\"title\", AttributeValueFuser(longest_string))\n",
    "\n",
    "# Date: Use most recent (latest data often more accurate)\n",
    "fusion_strategy.add_attribute_fuser(\"date\", AttributeValueFuser(most_recent))\n",
    "\n",
    "# Actor name: Use most complete (non-null, longest)\n",
    "fusion_strategy.add_attribute_fuser(\"actor_name\", AttributeValueFuser(most_complete))\n",
    "\n",
    "# Director name: Use longest string\n",
    "fusion_strategy.add_attribute_fuser(\"director_name\", AttributeValueFuser(longest_string))\n",
    "\n",
    "# Awards: Union all award information\n",
    "fusion_strategy.add_attribute_fuser(\"oscar\", AttributeValueFuser(union))\n",
    "fusion_strategy.add_attribute_fuser(\"globe\", AttributeValueFuser(union))\n",
    "\n",
    "print(f\"\\n‚úÖ Strategy '{fusion_strategy.name}' configured with {len(fusion_strategy.get_registered_attributes())} rules\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input datasets: 3\n",
      "Input records: 7,027\n",
      "Correspondences: 257\n",
      "\n",
      "‚úÖ Fusion Complete!\n",
      "  Total time: 0.287 seconds\n",
      "  Output records: 6,755\n",
      "  Compression ratio: 96.1%\n"
     ]
    }
   ],
   "source": [
    "# Create fusion engine with our strategy\n",
    "fusion_engine = DataFusionEngine(fusion_strategy)\n",
    "\n",
    "print(f\"Input datasets: {len(datasets)}\")\n",
    "print(f\"Input records: {total_input_records:,}\")\n",
    "print(f\"Correspondences: {len(all_correspondences):,}\")\n",
    "\n",
    "# Execute fusion with timing\n",
    "start_time = time.time()\n",
    "\n",
    "fused_dataset, execution_time = fusion_engine.run(\n",
    "    datasets=datasets,\n",
    "    correspondences=all_correspondences, \n",
    "    id_column='id',  # Use original 'id' column for matching\n",
    "    include_singletons=True  # Include unmatched records\n",
    ")\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\n‚úÖ Fusion Complete!\")\n",
    "print(f\"  Total time: {total_time:.3f} seconds\") \n",
    "print(f\"  Output records: {len(fused_dataset):,}\")\n",
    "print(f\"  Compression ratio: {len(fused_dataset)/total_input_records:.1%}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pydi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
