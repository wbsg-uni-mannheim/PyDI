{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def _is_missing_xml(value):\n",
    "    try:\n",
    "        if pd.isna(value):\n",
    "            return True\n",
    "    except Exception:\n",
    "        pass\n",
    "    if isinstance(value, (list, tuple, set)):\n",
    "        return len(value) == 0\n",
    "    try:\n",
    "        import numpy as np\n",
    "        if isinstance(value, np.ndarray):\n",
    "            return value.size == 0 or np.all(pd.isna(value))\n",
    "    except Exception:\n",
    "        pass\n",
    "    return False\n",
    "\n",
    "\n",
    "def dataframe_to_xml(df, path, root_tag=\"movies\", record_tag=\"movie\"):\n",
    "    \"\"\"Export DataFrame to XML format with robust missing-value handling.\"\"\"\n",
    "    from xml.etree.ElementTree import Element, SubElement, tostring\n",
    "    from xml.dom.minidom import parseString\n",
    "\n",
    "    path = Path(path)\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    root = Element(root_tag)\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        movie = SubElement(root, record_tag)\n",
    "        for col, value in row.items():\n",
    "            if col in [\"_fusion_group_id\", \"_fusion_sources\", \"_fusion_confidence\", \"_fusion_metadata\"]:\n",
    "                continue\n",
    "            if _is_missing_xml(value):\n",
    "                continue\n",
    "            elem = SubElement(movie, col.replace(\"_\", \"\"))\n",
    "            elem.text = str(value)\n",
    "\n",
    "    rough_string = tostring(root, 'utf-8')\n",
    "    reparsed = parseString(rough_string)\n",
    "    with open(path, 'w') as f:\n",
    "        f.write(reparsed.toprettyxml(indent=\"  \"))\n",
    "\n",
    "    return len(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyDI Data Fusion Framework - Winter Dataset Showcase\n",
    "\n",
    "This notebook demonstrates the comprehensive data fusion capabilities of PyDI using real datasets from the Winter framework. We'll show:\n",
    "\n",
    "1. **Loading Winter movie datasets using PyDI IO**\n",
    "2. **Creating sophisticated fusion strategies**\n",
    "3. **Running the fusion engine with connected components grouping**\n",
    "4. **Evaluating fusion quality**\n",
    "5. **Generating comprehensive reports**\n",
    "6. **Custom conflict resolution rules**\n",
    "7. **Provenance tracking**\n",
    "\n",
    "The PyDI fusion framework provides Winter-level capabilities with a modern, pandas-first Python API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports successful\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "import time\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configure logging for better visibility\n",
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"Imports successful\")\n",
    "\n",
    "def repo_root():\n",
    "    \"\"\"Return the repository root directory.\"\"\"\n",
    "    \n",
    "    if '__file__' in globals():\n",
    "        return Path(__file__).parent.parent.parent\n",
    "    else:\n",
    "    \n",
    "        current = Path.cwd()\n",
    "        while current != current.parent:\n",
    "            if (current / 'pyproject.toml').exists():\n",
    "                return current\n",
    "            current = current.parent\n",
    "        return Path.cwd()  # fallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyDI components imported successfully\n"
     ]
    }
   ],
   "source": [
    "from PyDI.fusion import (\n",
    "    DataFusionEngine,\n",
    "    DataFusionStrategy,\n",
    "    DataFusionEvaluator,\n",
    "    \n",
    "    longest_string, shortest_string, most_complete,\n",
    "    average, median, maximum, minimum, \n",
    "    most_recent, earliest,\n",
    "    union, intersection, voting,\n",
    "    build_record_groups_from_correspondences,\n",
    "    \n",
    "    # Convenient aliases\n",
    "    LONGEST, SHORTEST, AVG, MAX, MIN, LATEST, UNION, VOTE,\n",
    "    \n",
    "    # Reporting and evaluation\n",
    "    FusionReport,\n",
    "    FusionQualityMetrics,\n",
    "    ProvenanceTracker,\n",
    "    \n",
    "    # Base classes\n",
    "    ConflictResolutionFunction,\n",
    "    AttributeValueFuser,\n",
    "    FusionResult,\n",
    "    \n",
    "    \n",
    "    analyze_attribute_coverage, \n",
    "    AttributeCoverageAnalyzer,\n",
    ")\n",
    "\n",
    "from PyDI.io import load_xml, load_csv\n",
    "\n",
    "print(\"PyDI components imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading Movie Datasets \n",
    "\n",
    "\n",
    "We'll use PyDI's provenance-aware XML loader to load the Winter datasets. This automatically handles XML parsing, flattening, and adds provenance metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directory: /Users/aaronsteiner/Documents/GitHub/PyDI/input/movies/fusion/data\n",
      "Correspondences directory: /Users/aaronsteiner/Documents/GitHub/PyDI/input/movies/fusion/correspondences\n",
      "\n",
      "Available datasets:\n",
      "  - academy_awards.xml\n",
      "  - actors.xml\n",
      "  - golden_globes.xml\n"
     ]
    }
   ],
   "source": [
    "# Set up data and correspondence paths\n",
    "root = repo_root()\n",
    "data_dir = root / \"input\" / \"movies\" / \"fusion\" / \"data\"\n",
    "correspondences_dir = root / \"input\" / \"movies\" / \"fusion\" / \"correspondences\"\n",
    "\n",
    "print(f\"Data directory: {data_dir}\")\n",
    "print(f\"Correspondences directory: {correspondences_dir}\")\n",
    "\n",
    "# List available XML datasets\n",
    "print(f\"\\nAvailable datasets:\")\n",
    "for xml_file in data_dir.glob(\"*.xml\"):\n",
    "    print(f\"  - {xml_file.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Loaded dataset 'academy_awards' via read_xml_flattened: shape=(4592, 7), source=/Users/aaronsteiner/Documents/GitHub/PyDI/input/movies/fusion/data/academy_awards.xml\n",
      "INFO: Loaded dataset 'actors' via read_xml_flattened: shape=(151, 7), source=/Users/aaronsteiner/Documents/GitHub/PyDI/input/movies/fusion/data/actors.xml\n",
      "INFO: Loaded dataset 'golden_globes' via read_xml_flattened: shape=(2286, 7), source=/Users/aaronsteiner/Documents/GitHub/PyDI/input/movies/fusion/data/golden_globes.xml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets loaded successfully!\n",
      "\n",
      " Dataset Overview:\n",
      "  Academy Awards: 4592 records\n",
      "  Actors: 151 records\n",
      "  Golden Globes: 2286 records\n",
      "  Total: 7029 records\n"
     ]
    }
   ],
   "source": [
    "# Load Academy Awards dataset\n",
    "academy_awards_df = load_xml(\n",
    "    data_dir / 'academy_awards.xml',\n",
    "    name='academy_awards',\n",
    "    record_tag='movie',  # Specify the record element\n",
    "    flatten=True,        # Enable automatic XML flattening\n",
    "    add_index=True,      # Add unique IDs\n",
    "    include_provenance_columns=False, \n",
    ")\n",
    "\n",
    "# Load Actors dataset\n",
    "actors_df = load_xml(\n",
    "    data_dir / 'actors.xml',\n",
    "    name='actors',\n",
    "    record_tag='movie',\n",
    "    flatten=True,\n",
    "    add_index=True,\n",
    "    include_provenance_columns=False\n",
    ")\n",
    "\n",
    "# Load Golden Globes dataset\n",
    "golden_globes_df = load_xml(\n",
    "    data_dir / 'golden_globes.xml',\n",
    "    name='golden_globes',\n",
    "    record_tag='movie',\n",
    "    flatten=True,\n",
    "    add_index=True,\n",
    "    include_provenance_columns=False\n",
    ")\n",
    "\n",
    "print(\"Datasets loaded successfully!\")\n",
    "print(f\"\\n Dataset Overview:\")\n",
    "print(f\"  Academy Awards: {len(academy_awards_df)} records\")\n",
    "print(f\"  Actors: {len(actors_df)} records\")\n",
    "print(f\"  Golden Globes: {len(golden_globes_df)} records\")\n",
    "print(f\"  Total: {len(academy_awards_df) + len(actors_df) + len(golden_globes_df)} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>academy_awards_id</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>actor_name</th>\n",
       "      <th>date</th>\n",
       "      <th>director_name</th>\n",
       "      <th>oscar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>academy_awards-0000</td>\n",
       "      <td>academy_awards_1</td>\n",
       "      <td>Biutiful</td>\n",
       "      <td>Javier Bardem</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>academy_awards-0001</td>\n",
       "      <td>academy_awards_2</td>\n",
       "      <td>True Grit</td>\n",
       "      <td>Jeff Bridges</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>Joel Coen</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>academy_awards-0002</td>\n",
       "      <td>academy_awards_2</td>\n",
       "      <td>True Grit</td>\n",
       "      <td>Jeff Bridges</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>Ethan Coen</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>academy_awards-0003</td>\n",
       "      <td>academy_awards_3</td>\n",
       "      <td>The Social Network</td>\n",
       "      <td>Jesse Eisenberg</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>David Fincher</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>academy_awards-0004</td>\n",
       "      <td>academy_awards_4</td>\n",
       "      <td>The King's Speech</td>\n",
       "      <td>Colin Firth</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>Tom Hooper</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4587</th>\n",
       "      <td>academy_awards-4587</td>\n",
       "      <td>academy_awards_4576</td>\n",
       "      <td>Lajos Biro</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1927-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4588</th>\n",
       "      <td>academy_awards-4588</td>\n",
       "      <td>academy_awards_4577</td>\n",
       "      <td>Ben Hecht</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1927-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4589</th>\n",
       "      <td>academy_awards-4589</td>\n",
       "      <td>academy_awards_4578</td>\n",
       "      <td>Gerald Duffy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1927-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4590</th>\n",
       "      <td>academy_awards-4590</td>\n",
       "      <td>academy_awards_4579</td>\n",
       "      <td>Roy Pomeroy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1927-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4591</th>\n",
       "      <td>academy_awards-4591</td>\n",
       "      <td>academy_awards_4580</td>\n",
       "      <td>Metro-Goldwyn-Mayer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1927-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4592 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        academy_awards_id                   id                title  \\\n",
       "0     academy_awards-0000     academy_awards_1             Biutiful   \n",
       "1     academy_awards-0001     academy_awards_2            True Grit   \n",
       "2     academy_awards-0002     academy_awards_2            True Grit   \n",
       "3     academy_awards-0003     academy_awards_3   The Social Network   \n",
       "4     academy_awards-0004     academy_awards_4    The King's Speech   \n",
       "...                   ...                  ...                  ...   \n",
       "4587  academy_awards-4587  academy_awards_4576           Lajos Biro   \n",
       "4588  academy_awards-4588  academy_awards_4577            Ben Hecht   \n",
       "4589  academy_awards-4589  academy_awards_4578         Gerald Duffy   \n",
       "4590  academy_awards-4590  academy_awards_4579          Roy Pomeroy   \n",
       "4591  academy_awards-4591  academy_awards_4580  Metro-Goldwyn-Mayer   \n",
       "\n",
       "           actor_name        date  director_name oscar  \n",
       "0       Javier Bardem  2010-01-01            NaN   NaN  \n",
       "1        Jeff Bridges  2010-01-01      Joel Coen   NaN  \n",
       "2        Jeff Bridges  2010-01-01     Ethan Coen   NaN  \n",
       "3     Jesse Eisenberg  2010-01-01  David Fincher   yes  \n",
       "4         Colin Firth  2010-01-01     Tom Hooper   yes  \n",
       "...               ...         ...            ...   ...  \n",
       "4587              NaN  1927-01-01            NaN   NaN  \n",
       "4588              NaN  1927-01-01            NaN   yes  \n",
       "4589              NaN  1927-01-01            NaN   NaN  \n",
       "4590              NaN  1927-01-01            NaN   yes  \n",
       "4591              NaN  1927-01-01            NaN   NaN  \n",
       "\n",
       "[4592 rows x 7 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "academy_awards_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Academy Awards Dataset:\n",
      "  Shape: (4592, 7)\n",
      "  Columns: ['academy_awards_id', 'id', 'title', 'actor_name', 'date', 'director_name', 'oscar']\n",
      "  Dataset name: academy_awards\n",
      "  Sample records:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>academy_awards_id</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>actor_name</th>\n",
       "      <th>date</th>\n",
       "      <th>director_name</th>\n",
       "      <th>oscar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>academy_awards-0000</td>\n",
       "      <td>academy_awards_1</td>\n",
       "      <td>Biutiful</td>\n",
       "      <td>Javier Bardem</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>academy_awards-0001</td>\n",
       "      <td>academy_awards_2</td>\n",
       "      <td>True Grit</td>\n",
       "      <td>Jeff Bridges</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>Joel Coen</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>academy_awards-0002</td>\n",
       "      <td>academy_awards_2</td>\n",
       "      <td>True Grit</td>\n",
       "      <td>Jeff Bridges</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>Ethan Coen</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     academy_awards_id                id      title     actor_name  \\\n",
       "0  academy_awards-0000  academy_awards_1   Biutiful  Javier Bardem   \n",
       "1  academy_awards-0001  academy_awards_2  True Grit   Jeff Bridges   \n",
       "2  academy_awards-0002  academy_awards_2  True Grit   Jeff Bridges   \n",
       "\n",
       "         date director_name oscar  \n",
       "0  2010-01-01           NaN   NaN  \n",
       "1  2010-01-01     Joel Coen   NaN  \n",
       "2  2010-01-01    Ethan Coen   NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Actors Dataset:\n",
      "  Shape: (151, 7)\n",
      "  Columns: ['actors_id', 'id', 'title', 'actor_name', 'actors_actor_birthday', 'actors_actor_birthplace', 'date']\n",
      "  Dataset name: actors\n",
      "  Sample records:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actors_id</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>actor_name</th>\n",
       "      <th>actors_actor_birthday</th>\n",
       "      <th>actors_actor_birthplace</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>actors-0000</td>\n",
       "      <td>actors_1</td>\n",
       "      <td>7th Heaven</td>\n",
       "      <td>Janet Gaynor</td>\n",
       "      <td>1906-01-01</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>1929-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>actors-0001</td>\n",
       "      <td>actors_2</td>\n",
       "      <td>Coquette</td>\n",
       "      <td>Mary Pickford</td>\n",
       "      <td>1892-01-01</td>\n",
       "      <td>Canada</td>\n",
       "      <td>1930-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>actors-0002</td>\n",
       "      <td>actors_3</td>\n",
       "      <td>The Divorcee</td>\n",
       "      <td>Norma Shearer</td>\n",
       "      <td>1902-01-01</td>\n",
       "      <td>Canada</td>\n",
       "      <td>1931-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     actors_id        id         title     actor_name actors_actor_birthday  \\\n",
       "0  actors-0000  actors_1    7th Heaven   Janet Gaynor            1906-01-01   \n",
       "1  actors-0001  actors_2      Coquette  Mary Pickford            1892-01-01   \n",
       "2  actors-0002  actors_3  The Divorcee  Norma Shearer            1902-01-01   \n",
       "\n",
       "  actors_actor_birthplace        date  \n",
       "0            Pennsylvania  1929-01-01  \n",
       "1                  Canada  1930-01-01  \n",
       "2                  Canada  1931-01-01  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Golden Globes Dataset:\n",
      "  Shape: (2286, 7)\n",
      "  Columns: ['golden_globes_id', 'id', 'title', 'actor_name', 'date', 'director_name', 'globe']\n",
      "  Dataset name: golden_globes\n",
      "  Sample records:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>golden_globes_id</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>actor_name</th>\n",
       "      <th>date</th>\n",
       "      <th>director_name</th>\n",
       "      <th>globe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>golden_globes-0000</td>\n",
       "      <td>golden_globes_1</td>\n",
       "      <td>Frankie and Alice</td>\n",
       "      <td>Halle Berry</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>golden_globes-0001</td>\n",
       "      <td>golden_globes_2</td>\n",
       "      <td>Rabbit Hole</td>\n",
       "      <td>Nicole Kidman</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>golden_globes-0002</td>\n",
       "      <td>golden_globes_3</td>\n",
       "      <td>Winter's Bone</td>\n",
       "      <td>Jennifer Lawrence</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     golden_globes_id               id              title         actor_name  \\\n",
       "0  golden_globes-0000  golden_globes_1  Frankie and Alice        Halle Berry   \n",
       "1  golden_globes-0001  golden_globes_2        Rabbit Hole      Nicole Kidman   \n",
       "2  golden_globes-0002  golden_globes_3      Winter's Bone  Jennifer Lawrence   \n",
       "\n",
       "         date director_name globe  \n",
       "0  2011-01-01           NaN   NaN  \n",
       "1  2011-01-01           NaN   NaN  \n",
       "2  2011-01-01           NaN   NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "datasets = [academy_awards_df, actors_df, golden_globes_df]\n",
    "dataset_names = ['Academy Awards', 'Actors', 'Golden Globes']\n",
    "\n",
    "for i, (df, name) in enumerate(zip(datasets, dataset_names)):\n",
    "    print(f\"\\n{name} Dataset:\")\n",
    "    print(f\"  Shape: {df.shape}\")\n",
    "    print(f\"  Columns: {list(df.columns)}\")\n",
    "    print(f\"  Dataset name: {df.attrs.get('dataset_name', 'N/A')}\")\n",
    "    print(f\"  Sample records:\")\n",
    "    \n",
    "    display(df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Loaded dataset 'aa_actors_correspondences' via read_csv: shape=(150, 3), source=/Users/aaronsteiner/Documents/GitHub/PyDI/input/movies/fusion/correspondences/academy_awards_2_actors_correspondences.csv\n",
      "INFO: Loaded dataset 'actors_gg_correspondences' via read_csv: shape=(107, 3), source=/Users/aaronsteiner/Documents/GitHub/PyDI/input/movies/fusion/correspondences/actors_2_golden_globes_correspondences.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating enhanced correspondences to enable real conflict resolution...\n",
      "Sample correspondences:\n",
      "Academy Awards ↔ Actors:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id1</th>\n",
       "      <th>id2</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>academy_awards_4557</td>\n",
       "      <td>actors_1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>academy_awards_4529</td>\n",
       "      <td>actors_2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>academy_awards_4500</td>\n",
       "      <td>actors_3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id1       id2  score\n",
       "0  academy_awards_4557  actors_1    1.0\n",
       "1  academy_awards_4529  actors_2    1.0\n",
       "2  academy_awards_4500  actors_3    1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actors ↔ Golden Globes:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id1</th>\n",
       "      <th>id2</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>actors_16</td>\n",
       "      <td>golden_globes_2279</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>actors_22</td>\n",
       "      <td>golden_globes_2263</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>actors_23</td>\n",
       "      <td>golden_globes_2252</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id1                 id2  score\n",
       "0  actors_16  golden_globes_2279    1.0\n",
       "1  actors_22  golden_globes_2263    1.0\n",
       "2  actors_23  golden_globes_2252    1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Creating enhanced correspondences to enable real conflict resolution...\")\n",
    "\n",
    "# Load original correspondence files\n",
    "corr_aa_actors = load_csv(\n",
    "    correspondences_dir / 'academy_awards_2_actors_correspondences.csv',\n",
    "    name='aa_actors_correspondences',\n",
    "    add_index=False,\n",
    "    header=None,\n",
    "    names=['id1', 'id2', 'score']\n",
    ")\n",
    "\n",
    "corr_actors_gg = load_csv(\n",
    "    correspondences_dir / 'actors_2_golden_globes_correspondences.csv', \n",
    "    name='actors_gg_correspondences',\n",
    "    add_index=False,\n",
    "    header=None,\n",
    "    names=['id1', 'id2', 'score']\n",
    ")\n",
    "print(\"Sample correspondences:\")\n",
    "print(\"Academy Awards ↔ Actors:\")\n",
    "display(corr_aa_actors.head(3))\n",
    "print(\"Actors ↔ Golden Globes:\")\n",
    "display(corr_actors_gg.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enhanced correspondences: 264 total\n",
      "This creates multi-record groups that will trigger actual conflict resolution!\n",
      "\n",
      "Enhanced correspondences include:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id1</th>\n",
       "      <th>id2</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>actors_150</td>\n",
       "      <td>golden_globes_372</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>academy_awards_1880</td>\n",
       "      <td>golden_globes_1733</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>academy_awards_1430</td>\n",
       "      <td>golden_globes_1330</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>academy_awards_3059</td>\n",
       "      <td>golden_globes_974</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>academy_awards_4080</td>\n",
       "      <td>golden_globes_1131</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>academy_awards_3816</td>\n",
       "      <td>golden_globes_2187</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>academy_awards_1880</td>\n",
       "      <td>academy_awards_1430</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>academy_awards_3816</td>\n",
       "      <td>academy_awards_3910</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id1                  id2  score\n",
       "256           actors_150    golden_globes_372   1.00\n",
       "257  academy_awards_1880   golden_globes_1733   0.95\n",
       "258  academy_awards_1430   golden_globes_1330   0.95\n",
       "259  academy_awards_3059    golden_globes_974   0.95\n",
       "260  academy_awards_4080   golden_globes_1131   0.95\n",
       "261  academy_awards_3816   golden_globes_2187   0.95\n",
       "262  academy_awards_1880  academy_awards_1430   0.75\n",
       "263  academy_awards_3816  academy_awards_3910   0.70"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create enhanced correspondences that will form multi-record groups\n",
    "enhanced_correspondences = []\n",
    "\n",
    "# Add all original pairwise correspondences\n",
    "for _, row in corr_aa_actors.iterrows():\n",
    "    enhanced_correspondences.append({\n",
    "        'id1': row['id1'], 'id2': row['id2'], 'score': row['score']\n",
    "    })\n",
    "\n",
    "for _, row in corr_actors_gg.iterrows():\n",
    "    enhanced_correspondences.append({\n",
    "        'id1': row['id1'], 'id2': row['id2'], 'score': row['score']\n",
    "    })\n",
    "\n",
    "# Add direct Academy ↔ Golden Globe connections to create multi-record groups\n",
    "# This ensures some records will belong to groups with 3+ records from different sources\n",
    "sample_connections = [\n",
    "    # Create specific multi-record groups with known conflicts\n",
    "    ('academy_awards_1880', 'golden_globes_1733', 0.95),  # One Flew Over Cuckoo's Nest\n",
    "    ('academy_awards_1430', 'golden_globes_1330', 0.95),  # Amadeus\n",
    "    ('academy_awards_3059', 'golden_globes_974', 0.95),   # Stalag 17\n",
    "    ('academy_awards_4080', 'golden_globes_1131', 0.95),  # Goodbye, Mr. Chips\n",
    "    ('academy_awards_3816', 'golden_globes_2187', 0.95),  # Mrs. Miniver\n",
    "]\n",
    "\n",
    "for id1, id2, score in sample_connections:\n",
    "    enhanced_correspondences.append({\n",
    "        'id1': id1, 'id2': id2, 'score': score\n",
    "    })\n",
    "\n",
    "# Add some same-source conflicts to demonstrate intra-dataset resolution\n",
    "same_source_conflicts = [\n",
    "    # Link similar movies within Academy Awards to create conflict groups\n",
    "    ('academy_awards_1880', 'academy_awards_1430', 0.75),  # Both Milos Forman films\n",
    "    ('academy_awards_3816', 'academy_awards_3910', 0.70),  # Both 1940s dramas\n",
    "]\n",
    "\n",
    "for id1, id2, score in same_source_conflicts:\n",
    "    enhanced_correspondences.append({\n",
    "        'id1': id1, 'id2': id2, 'score': score\n",
    "    })\n",
    "\n",
    "# Create final correspondences dataframe\n",
    "all_correspondences = pd.DataFrame(enhanced_correspondences)\n",
    "print(f\"Enhanced correspondences: {len(all_correspondences)} total\")\n",
    "print(\"This creates multi-record groups that will trigger actual conflict resolution!\")\n",
    "\n",
    "# Show sample correspondences\n",
    "print(f\"\\nEnhanced correspondences include:\")\n",
    "display(all_correspondences.tail(8))  # Show the new connections we added"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Quality Analysis with Loaded Datasets\n",
    "\n",
    "Now let's analyze the loaded data to understand attribute coverage and potential conflicts.\n",
    "\n",
    "### Method 1: PyDI comes with some integrated Attribute Coverage Analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Analyzed 12 attributes across 3 datasets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coverage analysis complete!\n",
      "   Total attributes analyzed: 12\n",
      "   Datasets analyzed: 3\n",
      "\n",
      "Attribute Coverage Summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attribute</th>\n",
       "      <th>Academy Awards_count</th>\n",
       "      <th>Actors_count</th>\n",
       "      <th>Golden Globes_count</th>\n",
       "      <th>Academy Awards_pct</th>\n",
       "      <th>Actors_pct</th>\n",
       "      <th>Golden Globes_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>academy_awards_id</td>\n",
       "      <td>4592/4592</td>\n",
       "      <td>0/0</td>\n",
       "      <td>0/0</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>actor_name</td>\n",
       "      <td>1057/4592</td>\n",
       "      <td>151/151</td>\n",
       "      <td>2232/2286</td>\n",
       "      <td>23.0%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>97.6%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>actors_actor_birthday</td>\n",
       "      <td>0/0</td>\n",
       "      <td>151/151</td>\n",
       "      <td>0/0</td>\n",
       "      <td>0%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>actors_actor_birthplace</td>\n",
       "      <td>0/0</td>\n",
       "      <td>151/151</td>\n",
       "      <td>0/0</td>\n",
       "      <td>0%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>actors_id</td>\n",
       "      <td>0/0</td>\n",
       "      <td>151/151</td>\n",
       "      <td>0/0</td>\n",
       "      <td>0%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>date</td>\n",
       "      <td>4592/4592</td>\n",
       "      <td>151/151</td>\n",
       "      <td>2286/2286</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>100.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>director_name</td>\n",
       "      <td>420/4592</td>\n",
       "      <td>0/0</td>\n",
       "      <td>320/2286</td>\n",
       "      <td>9.1%</td>\n",
       "      <td>0%</td>\n",
       "      <td>14.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>globe</td>\n",
       "      <td>0/0</td>\n",
       "      <td>0/0</td>\n",
       "      <td>625/2286</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>27.3%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>golden_globes_id</td>\n",
       "      <td>0/0</td>\n",
       "      <td>0/0</td>\n",
       "      <td>2286/2286</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>100.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>id</td>\n",
       "      <td>4592/4592</td>\n",
       "      <td>151/151</td>\n",
       "      <td>2286/2286</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>100.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>oscar</td>\n",
       "      <td>1275/4592</td>\n",
       "      <td>0/0</td>\n",
       "      <td>0/0</td>\n",
       "      <td>27.8%</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>title</td>\n",
       "      <td>4580/4592</td>\n",
       "      <td>151/151</td>\n",
       "      <td>2286/2286</td>\n",
       "      <td>99.7%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>100.0%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  attribute Academy Awards_count Actors_count  \\\n",
       "0         academy_awards_id            4592/4592          0/0   \n",
       "1                actor_name            1057/4592      151/151   \n",
       "2     actors_actor_birthday                  0/0      151/151   \n",
       "3   actors_actor_birthplace                  0/0      151/151   \n",
       "4                 actors_id                  0/0      151/151   \n",
       "5                      date            4592/4592      151/151   \n",
       "6             director_name             420/4592          0/0   \n",
       "7                     globe                  0/0          0/0   \n",
       "8          golden_globes_id                  0/0          0/0   \n",
       "9                        id            4592/4592      151/151   \n",
       "10                    oscar            1275/4592          0/0   \n",
       "11                    title            4580/4592      151/151   \n",
       "\n",
       "   Golden Globes_count Academy Awards_pct Actors_pct Golden Globes_pct  \n",
       "0                  0/0             100.0%         0%                0%  \n",
       "1            2232/2286              23.0%     100.0%             97.6%  \n",
       "2                  0/0                 0%     100.0%                0%  \n",
       "3                  0/0                 0%     100.0%                0%  \n",
       "4                  0/0                 0%     100.0%                0%  \n",
       "5            2286/2286             100.0%     100.0%            100.0%  \n",
       "6             320/2286               9.1%         0%             14.0%  \n",
       "7             625/2286                 0%         0%             27.3%  \n",
       "8            2286/2286                 0%         0%            100.0%  \n",
       "9            2286/2286             100.0%     100.0%            100.0%  \n",
       "10                 0/0              27.8%         0%                0%  \n",
       "11           2286/2286              99.7%     100.0%            100.0%  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "coverage_df = analyze_attribute_coverage(\n",
    "    datasets=datasets,\n",
    "    dataset_names=dataset_names,\n",
    "    include_samples=True\n",
    ")\n",
    "\n",
    "print(f\"Coverage analysis complete!\")\n",
    "print(f\"   Total attributes analyzed: {len(coverage_df)}\")\n",
    "print(f\"   Datasets analyzed: {len(dataset_names)}\")\n",
    "\n",
    "# Display the results (same format as the original notebook code)\n",
    "print(f\"\\nAttribute Coverage Summary:\")\n",
    "display_cols = ['attribute'] + [f'{name}_count' for name in dataset_names] + [f'{name}_pct' for name in dataset_names]\n",
    "available_display_cols = [col for col in display_cols if col in coverage_df.columns]\n",
    "display(coverage_df[available_display_cols])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Analyzed 12 attributes across 3 datasets\n",
      "INFO: Initialized AttributeCoverageAnalyzer for 3 datasets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Method 2: Advanced Coverage Analyzer\n",
      "Attribute Coverage Analysis Summary\n",
      "==================================================\n",
      "\n",
      "Dataset Overview:\n",
      "  1. Academy Awards: 4,592 records, 7 attributes\n",
      "  2. Actors: 151 records, 7 attributes\n",
      "  3. Golden Globes: 2,286 records, 7 attributes\n",
      "  Total: 7,029 records\n",
      "\n",
      "Attribute Statistics:\n",
      "  Total unique attributes: 12\n",
      "  Common across all datasets: 4\n",
      "  Dataset-specific attributes: 8\n",
      "\n",
      "Coverage Distribution:\n",
      "  Low (0-25%): 3 attributes (25.0%)\n",
      "  Medium (25-50%): 5 attributes (41.7%)\n",
      "  High (50-75%): 1 attributes (8.3%)\n",
      "  Very High (75-100%): 3 attributes (25.0%)\n",
      "\n",
      "Top Attributes by Coverage:\n",
      "  1. date: 100.0% avg (3/3 datasets)\n",
      "  2. id: 100.0% avg (3/3 datasets)\n",
      "  3. title: 99.9% avg (3/3 datasets)\n",
      "  4. actor_name: 73.6% avg (3/3 datasets)\n",
      "  5. academy_awards_id: 33.3% avg (1/3 datasets)\n",
      "  6. actors_actor_birthday: 33.3% avg (1/3 datasets)\n",
      "  7. actors_actor_birthplace: 33.3% avg (1/3 datasets)\n",
      "  8. actors_id: 33.3% avg (1/3 datasets)\n",
      "  9. golden_globes_id: 33.3% avg (1/3 datasets)\n",
      "  10. oscar: 9.3% avg (1/3 datasets)\n",
      "\n",
      "Detailed Coverage (Top 12):\n",
      "              attribute Academy Awards_count Academy Awards_pct Actors_count Actors_pct Golden Globes_count Golden Globes_pct avg_coverage  datasets_with_attribute\n",
      "                   date            4592/4592             100.0%      151/151     100.0%           2286/2286            100.0%       100.0%                        3\n",
      "                     id            4592/4592             100.0%      151/151     100.0%           2286/2286            100.0%       100.0%                        3\n",
      "                  title            4580/4592              99.7%      151/151     100.0%           2286/2286            100.0%        99.9%                        3\n",
      "             actor_name            1057/4592              23.0%      151/151     100.0%           2232/2286             97.6%        73.6%                        3\n",
      "      academy_awards_id            4592/4592             100.0%          0/0         0%                 0/0                0%        33.3%                        1\n",
      "  actors_actor_birthday                  0/0                 0%      151/151     100.0%                 0/0                0%        33.3%                        1\n",
      "actors_actor_birthplace                  0/0                 0%      151/151     100.0%                 0/0                0%        33.3%                        1\n",
      "              actors_id                  0/0                 0%      151/151     100.0%                 0/0                0%        33.3%                        1\n",
      "       golden_globes_id                  0/0                 0%          0/0         0%           2286/2286            100.0%        33.3%                        1\n",
      "                  oscar            1275/4592              27.8%          0/0         0%                 0/0                0%         9.3%                        1\n",
      "                  globe                  0/0                 0%          0/0         0%            625/2286             27.3%         9.1%                        1\n",
      "          director_name             420/4592               9.1%          0/0         0%            320/2286             14.0%         7.7%                        2\n",
      "\n",
      "Potential Conflicts Detected:\n",
      "  Attributes with conflicts: 4\n",
      "    title: value distribution\n",
      "    id: value distribution\n",
      "    actor_name: value distribution\n",
      "    date: value distribution\n"
     ]
    }
   ],
   "source": [
    "# Method 2: Advanced analyzer class  \n",
    "print(f\"\\nMethod 2: Advanced Coverage Analyzer\")\n",
    "coverage_analyzer = AttributeCoverageAnalyzer(datasets, dataset_names)\n",
    "\n",
    "# This provides much more detailed analysis\n",
    "coverage_analyzer.print_summary(max_attributes=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Conflict Analysis:\n",
      "   Detected potential conflicts in 4 attributes:\n",
      "     • title: value distribution\n",
      "     • id: value distribution\n",
      "     • actor_name: value distribution\n",
      "     • date: value distribution\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nConflict Analysis:\")\n",
    "conflict_analysis = coverage_analyzer.conflict_analysis\n",
    "if conflict_analysis:\n",
    "    print(f\"   Detected potential conflicts in {len(conflict_analysis)} attributes:\")\n",
    "    for attr, conflicts in list(conflict_analysis.items())[:5]:\n",
    "        conflict_types = []\n",
    "        if conflicts.get('data_type_mismatches'):\n",
    "            conflict_types.append(\"data type\")\n",
    "        if len(conflicts.get('value_distributions', {})) > 1:\n",
    "            conflict_types.append(\"value distribution\")\n",
    "        print(f\"     • {attr}: {', '.join(conflict_types)}\")\n",
    "else:\n",
    "    print(f\"   No significant conflicts detected - data looks compatible!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Executing Data Fusion with Connected Components\n",
    "\n",
    "Now we'll run the fusion engine using PyDI's sophisticated grouping and conflict resolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longest title: 'The Lord of the Rings: Extended Edition' (confidence: 0.731)\n",
      "Most recent date: '2001-12-19' (confidence: 0.500)\n",
      "Average rating: 8.85 (confidence: 0.974)\n"
     ]
    }
   ],
   "source": [
    "sample_titles = [\"The Lord of the Rings\", \"LOTR\", \"The Lord of the Rings: Extended Edition\"]\n",
    "result_title, confidence, metadata = longest_string(sample_titles)\n",
    "print(f\"Longest title: '{result_title}' (confidence: {confidence:.3f})\")\n",
    "\n",
    "sample_dates = [\"2001-01-01\", \"2001-12-19\", \"2001\"]\n",
    "result_date, confidence, metadata = most_recent(sample_dates)\n",
    "print(f\"Most recent date: '{result_date}' (confidence: {confidence:.3f})\")\n",
    "\n",
    "sample_numbers = [8.5, 9.1, 8.8, 9.0]\n",
    "result_avg, confidence, metadata = average(sample_numbers)\n",
    "print(f\"Average rating: {result_avg:.2f} (confidence: {confidence:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Registered fuser for attribute 'title' using rule 'longest_string'\n",
      "INFO: Registered fuser for attribute 'date' using rule 'most_recent'\n",
      "INFO: Registered fuser for attribute 'director_name' using rule 'union'\n",
      "INFO: Registered fuser for attribute 'actor_name' using rule 'voting'\n",
      "INFO: Registered fuser for attribute 'oscar' using rule 'best_award_rule'\n",
      "INFO: Registered fuser for attribute 'globe' using rule 'best_award_rule'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Easy Strategy Creation with Function-Based Rules:\n",
      "Custom strategy created: 6 rules\n",
      "Registered attributes: ['title', 'globe', 'director_name', 'actor_name', 'oscar', 'date']\n"
     ]
    }
   ],
   "source": [
    "# Demonstrate how to create strategies from scratch \n",
    "print(\"Easy Strategy Creation with Function-Based Rules:\")\n",
    "\n",
    "# Create a custom strategy with movie-specific rules\n",
    "fusion_strategy = DataFusionStrategy(\"movies_custom\")\n",
    "\n",
    "# Add rules \n",
    "fusion_strategy.add_attribute_fuser(\"title\", AttributeValueFuser(LONGEST))\n",
    "fusion_strategy.add_attribute_fuser(\"date\", AttributeValueFuser(LATEST)) \n",
    "fusion_strategy.add_attribute_fuser(\"director_name\", AttributeValueFuser(union, separator=\", \"))\n",
    "fusion_strategy.add_attribute_fuser(\"actor_name\", AttributeValueFuser(VOTE))  # Most common name\n",
    "\n",
    "# Add a custom rule for award data\n",
    "def best_award_rule(values, context=None):\n",
    "    \"\"\"Custom rule: prioritize Oscar over Globe, handle award hierarchy.\"\"\"\n",
    "    award_priority = {'yes': 3, 'oscar': 3, 'globe': 2, 'golden globe': 2}\n",
    "    best_award = None\n",
    "    highest_priority = 0\n",
    "    \n",
    "    for value in values:\n",
    "        if pd.notna(value):\n",
    "            value_str = str(value).lower()\n",
    "            priority = award_priority.get(value_str, 1)\n",
    "            if priority > highest_priority:\n",
    "                highest_priority = priority\n",
    "                best_award = value\n",
    "    \n",
    "    confidence = highest_priority / 3.0 if highest_priority > 0 else 0.0\n",
    "    metadata = {\"rule\": \"best_award_rule\", \"priority\": highest_priority}\n",
    "    \n",
    "    return best_award, confidence, metadata\n",
    "\n",
    "# Add award rules\n",
    "fusion_strategy.add_attribute_fuser(\"oscar\", AttributeValueFuser(best_award_rule))\n",
    "fusion_strategy.add_attribute_fuser(\"globe\", AttributeValueFuser(best_award_rule))\n",
    "\n",
    "print(f\"Custom strategy created: {len(fusion_strategy.get_registered_attributes())} rules\")\n",
    "print(f\"Registered attributes: {list(fusion_strategy.get_registered_attributes())}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>academy_awards_id</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>actor_name</th>\n",
       "      <th>date</th>\n",
       "      <th>director_name</th>\n",
       "      <th>oscar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>academy_awards-0000</td>\n",
       "      <td>academy_awards_1</td>\n",
       "      <td>Biutiful</td>\n",
       "      <td>Javier Bardem</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>academy_awards-0001</td>\n",
       "      <td>academy_awards_2</td>\n",
       "      <td>True Grit</td>\n",
       "      <td>Jeff Bridges</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>Joel Coen</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>academy_awards-0002</td>\n",
       "      <td>academy_awards_2</td>\n",
       "      <td>True Grit</td>\n",
       "      <td>Jeff Bridges</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>Ethan Coen</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>academy_awards-0003</td>\n",
       "      <td>academy_awards_3</td>\n",
       "      <td>The Social Network</td>\n",
       "      <td>Jesse Eisenberg</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>David Fincher</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>academy_awards-0004</td>\n",
       "      <td>academy_awards_4</td>\n",
       "      <td>The King's Speech</td>\n",
       "      <td>Colin Firth</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>Tom Hooper</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4587</th>\n",
       "      <td>academy_awards-4587</td>\n",
       "      <td>academy_awards_4576</td>\n",
       "      <td>Lajos Biro</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1927-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4588</th>\n",
       "      <td>academy_awards-4588</td>\n",
       "      <td>academy_awards_4577</td>\n",
       "      <td>Ben Hecht</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1927-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4589</th>\n",
       "      <td>academy_awards-4589</td>\n",
       "      <td>academy_awards_4578</td>\n",
       "      <td>Gerald Duffy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1927-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4590</th>\n",
       "      <td>academy_awards-4590</td>\n",
       "      <td>academy_awards_4579</td>\n",
       "      <td>Roy Pomeroy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1927-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4591</th>\n",
       "      <td>academy_awards-4591</td>\n",
       "      <td>academy_awards_4580</td>\n",
       "      <td>Metro-Goldwyn-Mayer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1927-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4592 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        academy_awards_id                   id                title  \\\n",
       "0     academy_awards-0000     academy_awards_1             Biutiful   \n",
       "1     academy_awards-0001     academy_awards_2            True Grit   \n",
       "2     academy_awards-0002     academy_awards_2            True Grit   \n",
       "3     academy_awards-0003     academy_awards_3   The Social Network   \n",
       "4     academy_awards-0004     academy_awards_4    The King's Speech   \n",
       "...                   ...                  ...                  ...   \n",
       "4587  academy_awards-4587  academy_awards_4576           Lajos Biro   \n",
       "4588  academy_awards-4588  academy_awards_4577            Ben Hecht   \n",
       "4589  academy_awards-4589  academy_awards_4578         Gerald Duffy   \n",
       "4590  academy_awards-4590  academy_awards_4579          Roy Pomeroy   \n",
       "4591  academy_awards-4591  academy_awards_4580  Metro-Goldwyn-Mayer   \n",
       "\n",
       "           actor_name        date  director_name oscar  \n",
       "0       Javier Bardem  2010-01-01            NaN   NaN  \n",
       "1        Jeff Bridges  2010-01-01      Joel Coen   NaN  \n",
       "2        Jeff Bridges  2010-01-01     Ethan Coen   NaN  \n",
       "3     Jesse Eisenberg  2010-01-01  David Fincher   yes  \n",
       "4         Colin Firth  2010-01-01     Tom Hooper   yes  \n",
       "...               ...         ...            ...   ...  \n",
       "4587              NaN  1927-01-01            NaN   NaN  \n",
       "4588              NaN  1927-01-01            NaN   yes  \n",
       "4589              NaN  1927-01-01            NaN   NaN  \n",
       "4590              NaN  1927-01-01            NaN   yes  \n",
       "4591              NaN  1927-01-01            NaN   NaN  \n",
       "\n",
       "[4592 rows x 7 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "academy_awards_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actors_id</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>actor_name</th>\n",
       "      <th>actors_actor_birthday</th>\n",
       "      <th>actors_actor_birthplace</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>actors-0000</td>\n",
       "      <td>actors_1</td>\n",
       "      <td>7th Heaven</td>\n",
       "      <td>Janet Gaynor</td>\n",
       "      <td>1906-01-01</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>1929-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     actors_id        id       title    actor_name actors_actor_birthday  \\\n",
       "0  actors-0000  actors_1  7th Heaven  Janet Gaynor            1906-01-01   \n",
       "\n",
       "  actors_actor_birthplace        date  \n",
       "0            Pennsylvania  1929-01-01  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actors_df[actors_df[\"actors_id\"] == \"actors-0000\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>academy_awards_id</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>actor_name</th>\n",
       "      <th>date</th>\n",
       "      <th>director_name</th>\n",
       "      <th>oscar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4567</th>\n",
       "      <td>academy_awards-4567</td>\n",
       "      <td>academy_awards_4557</td>\n",
       "      <td>7th Heaven</td>\n",
       "      <td>Janet Gaynor</td>\n",
       "      <td>1927-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        academy_awards_id                   id       title    actor_name  \\\n",
       "4567  academy_awards-4567  academy_awards_4557  7th Heaven  Janet Gaynor   \n",
       "\n",
       "            date director_name oscar  \n",
       "4567  1927-01-01           NaN   yes  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "academy_awards_df[academy_awards_df[\"academy_awards_id\"] == \"academy_awards-4567\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id1</th>\n",
       "      <th>id2</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>academy_awards-4567</td>\n",
       "      <td>actors-0000</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>academy_awards-4539</td>\n",
       "      <td>actors-0001</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>academy_awards-4509</td>\n",
       "      <td>actors-0002</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>academy_awards-4484</td>\n",
       "      <td>actors-0003</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>academy_awards-4455</td>\n",
       "      <td>actors-0004</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>academy_awards-3067</td>\n",
       "      <td>golden_globes-0978</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>academy_awards-4089</td>\n",
       "      <td>golden_globes-1135</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>academy_awards-3824</td>\n",
       "      <td>golden_globes-2193</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>academy_awards-1887</td>\n",
       "      <td>academy_awards-1435</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>academy_awards-3824</td>\n",
       "      <td>academy_awards-3918</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>264 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id1                  id2  score\n",
       "0    academy_awards-4567          actors-0000   1.00\n",
       "1    academy_awards-4539          actors-0001   1.00\n",
       "2    academy_awards-4509          actors-0002   1.00\n",
       "3    academy_awards-4484          actors-0003   1.00\n",
       "4    academy_awards-4455          actors-0004   1.00\n",
       "..                   ...                  ...    ...\n",
       "259  academy_awards-3067   golden_globes-0978   0.95\n",
       "260  academy_awards-4089   golden_globes-1135   0.95\n",
       "261  academy_awards-3824   golden_globes-2193   0.95\n",
       "262  academy_awards-1887  academy_awards-1435   0.75\n",
       "263  academy_awards-3824  academy_awards-3918   0.70\n",
       "\n",
       "[264 rows x 3 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We need to transform the ids in the correspondences to match the ids in the datasets\n",
    "def _id_to_pydi_id(id: str, df: pd.DataFrame, lookup_column: str = \"_id\", return_column: str = \"id\"):\n",
    "    values = df[df[lookup_column] == id][return_column].values\n",
    "    if len(values) == 0:\n",
    "        return id\n",
    "    return values[0]\n",
    "\n",
    "# Apply the transformation to the correspondences\n",
    "all_correspondences[\"id1\"] = all_correspondences[\"id1\"].apply(lambda x: _id_to_pydi_id(x, academy_awards_df, \"id\", \"academy_awards_id\"))\n",
    "all_correspondences[\"id2\"] = all_correspondences[\"id2\"].apply(lambda x: _id_to_pydi_id(x, academy_awards_df, \"id\", \"academy_awards_id\"))\n",
    "\n",
    "all_correspondences[\"id2\"] = all_correspondences[\"id2\"].apply(lambda x: _id_to_pydi_id(x, actors_df, \"id\", \"actors_id\"))\n",
    "all_correspondences[\"id2\"] = all_correspondences[\"id2\"].apply(lambda x: _id_to_pydi_id(x, golden_globes_df, \"id\", \"golden_globes_id\"))\n",
    "\n",
    "all_correspondences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id1</th>\n",
       "      <th>id2</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id1, id2, score]\n",
       "Index: []"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_correspondences[all_correspondences[\"id2\"] == \"academy_awards_1880\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Starting data fusion with strategy 'movies_custom'\n",
      "INFO: Correspondence ID coverage: matched 403 of 510 unique IDs\n",
      "INFO: Created 6872 record groups from 264 correspondences\n",
      "INFO: Groups: 146 multi-record, 6726 singleton\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "WARNING: Function resolver best_award_rule failed: best_award_rule() got an unexpected keyword argument 'sources'\n",
      "INFO: Fusion complete: 146 records from 146 groups\n",
      "INFO: Fusion time: 0.28 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fusion runtime: 0.28 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>_fusion_group_id</th>\n",
       "      <th>_fusion_sources</th>\n",
       "      <th>actors_id</th>\n",
       "      <th>id</th>\n",
       "      <th>actors_actor_birthplace</th>\n",
       "      <th>academy_awards_id</th>\n",
       "      <th>title</th>\n",
       "      <th>director_name</th>\n",
       "      <th>actors_actor_birthday</th>\n",
       "      <th>actor_name</th>\n",
       "      <th>oscar</th>\n",
       "      <th>date</th>\n",
       "      <th>_fusion_confidence</th>\n",
       "      <th>_fusion_metadata</th>\n",
       "      <th>golden_globes_id</th>\n",
       "      <th>globe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>academy_awards-1547</td>\n",
       "      <td>group_3</td>\n",
       "      <td>[actors, academy_awards]</td>\n",
       "      <td>actors-0055</td>\n",
       "      <td>academy_awards_1541</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>academy_awards-1547</td>\n",
       "      <td>Sophie's Choice</td>\n",
       "      <td>None</td>\n",
       "      <td>1949-01-01</td>\n",
       "      <td>Meryl Streep</td>\n",
       "      <td>yes</td>\n",
       "      <td>1983-01-01</td>\n",
       "      <td>0.463636</td>\n",
       "      <td>{'actors_id_rule': 'first_non_null', 'id_rule'...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>actors-0098</td>\n",
       "      <td>group_4</td>\n",
       "      <td>[actors, academy_awards]</td>\n",
       "      <td>actors-0098</td>\n",
       "      <td>actors_99</td>\n",
       "      <td>England</td>\n",
       "      <td>academy_awards-3374</td>\n",
       "      <td>Hamlet</td>\n",
       "      <td>[Laurence Olivier]</td>\n",
       "      <td>1907-01-01</td>\n",
       "      <td>Laurence Olivier</td>\n",
       "      <td>yes</td>\n",
       "      <td>1949-01-01</td>\n",
       "      <td>0.554545</td>\n",
       "      <td>{'actors_id_rule': 'first_non_null', 'id_rule'...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>academy_awards-2247</td>\n",
       "      <td>group_6</td>\n",
       "      <td>[actors, academy_awards]</td>\n",
       "      <td>actors-0040</td>\n",
       "      <td>academy_awards_2240</td>\n",
       "      <td>New York</td>\n",
       "      <td>academy_awards-2247</td>\n",
       "      <td>Funny Girl</td>\n",
       "      <td>None</td>\n",
       "      <td>1942-01-01</td>\n",
       "      <td>Barbra Streisand</td>\n",
       "      <td>yes</td>\n",
       "      <td>1969-01-01</td>\n",
       "      <td>0.463636</td>\n",
       "      <td>{'actors_id_rule': 'first_non_null', 'id_rule'...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   _id _fusion_group_id           _fusion_sources  \\\n",
       "0  academy_awards-1547          group_3  [actors, academy_awards]   \n",
       "1          actors-0098          group_4  [actors, academy_awards]   \n",
       "2  academy_awards-2247          group_6  [actors, academy_awards]   \n",
       "\n",
       "     actors_id                   id actors_actor_birthplace  \\\n",
       "0  actors-0055  academy_awards_1541              New Jersey   \n",
       "1  actors-0098            actors_99                 England   \n",
       "2  actors-0040  academy_awards_2240                New York   \n",
       "\n",
       "     academy_awards_id            title       director_name  \\\n",
       "0  academy_awards-1547  Sophie's Choice                None   \n",
       "1  academy_awards-3374           Hamlet  [Laurence Olivier]   \n",
       "2  academy_awards-2247       Funny Girl                None   \n",
       "\n",
       "  actors_actor_birthday        actor_name oscar        date  \\\n",
       "0            1949-01-01      Meryl Streep   yes  1983-01-01   \n",
       "1            1907-01-01  Laurence Olivier   yes  1949-01-01   \n",
       "2            1942-01-01  Barbra Streisand   yes  1969-01-01   \n",
       "\n",
       "   _fusion_confidence                                   _fusion_metadata  \\\n",
       "0            0.463636  {'actors_id_rule': 'first_non_null', 'id_rule'...   \n",
       "1            0.554545  {'actors_id_rule': 'first_non_null', 'id_rule'...   \n",
       "2            0.463636  {'actors_id_rule': 'first_non_null', 'id_rule'...   \n",
       "\n",
       "  golden_globes_id globe  \n",
       "0              NaN   NaN  \n",
       "1              NaN   NaN  \n",
       "2              NaN   NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create the fusion engine\n",
    "fusion_engine = DataFusionEngine(\n",
    "    strategy=fusion_strategy\n",
    ")\n",
    "\n",
    "# Execute the fusion with our custom strategy\n",
    "fusion_result, runtime = fusion_engine.run(\n",
    "    datasets=datasets,\n",
    "    correspondences=all_correspondences,\n",
    "    id_column={\"academy_awards\": \"academy_awards_id\",\n",
    "                \"actors\": \"actors_id\",\n",
    "                \"golden_globes\": \"golden_globes_id\"},\n",
    "    include_singletons=False\n",
    ")\n",
    "\n",
    "print(f\"Fusion runtime: {runtime:.2f} seconds\")\n",
    "display(fusion_result.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fusion execution complete!\n",
      "Input records: 7,029\n",
      "Output records: 146\n",
      "Data reduction: 97.9%\n",
      "\n",
      "Sample Fused Records:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>actor_name</th>\n",
       "      <th>director_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>academy_awards-1547</td>\n",
       "      <td>Sophie's Choice</td>\n",
       "      <td>1983-01-01</td>\n",
       "      <td>Meryl Streep</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>actors-0098</td>\n",
       "      <td>Hamlet</td>\n",
       "      <td>1949-01-01</td>\n",
       "      <td>Laurence Olivier</td>\n",
       "      <td>[Laurence Olivier]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>academy_awards-2247</td>\n",
       "      <td>Funny Girl</td>\n",
       "      <td>1969-01-01</td>\n",
       "      <td>Barbra Streisand</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   _id            title        date        actor_name  \\\n",
       "0  academy_awards-1547  Sophie's Choice  1983-01-01      Meryl Streep   \n",
       "1          actors-0098           Hamlet  1949-01-01  Laurence Olivier   \n",
       "2  academy_awards-2247       Funny Girl  1969-01-01  Barbra Streisand   \n",
       "\n",
       "        director_name  \n",
       "0                None  \n",
       "1  [Laurence Olivier]  \n",
       "2                None  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fusion Quality:\n",
      "Average confidence: 0.506\n",
      "High confidence records (>=0.8): 0 (0.0%)\n"
     ]
    }
   ],
   "source": [
    "# Extract results\n",
    "fused_dataset = fusion_result\n",
    "\n",
    "print(f\"Fusion execution complete!\")\n",
    "print(f\"Input records: {sum(len(df) for df in datasets):,}\")\n",
    "print(f\"Output records: {len(fused_dataset):,}\")\n",
    "print(f\"Data reduction: {((sum(len(df) for df in datasets) - len(fused_dataset))/sum(len(df) for df in datasets)*100):.1f}%\")\n",
    "\n",
    "# Show sample of fused data\n",
    "print(f\"\\nSample Fused Records:\")\n",
    "if len(fused_dataset) > 0:\n",
    "    display_cols = ['_id', 'title', 'date', 'actor_name', 'director_name']\n",
    "    available_cols = [col for col in display_cols if col in fused_dataset.columns]\n",
    "    if available_cols:\n",
    "        display(fused_dataset[available_cols].head(3))\n",
    "    else:\n",
    "        display(fused_dataset.head(3))\n",
    "        \n",
    "    # Show fusion metadata if available\n",
    "    if '_fusion_confidence' in fused_dataset.columns:\n",
    "        avg_confidence = fused_dataset['_fusion_confidence'].mean()\n",
    "        print(f\"\\nFusion Quality:\")\n",
    "        print(f\"Average confidence: {avg_confidence:.3f}\")\n",
    "        print(f\"High confidence records (>=0.8): {(fused_dataset['_fusion_confidence'] >= 0.8).sum()} ({(fused_dataset['_fusion_confidence'] >= 0.8).mean():.1%})\")\n",
    "else:\n",
    "    print(\"No records were fused!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Loaded dataset 'gold_standard' via read_xml_flattened: shape=(20, 6), source=/Users/aaronsteiner/Documents/GitHub/PyDI/input/movies/fusion/splits/gold.xml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Gold Standard for Accuracy Evaluation...\n",
      "==================================================\n",
      "Gold standard loaded: 20 records\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>director_name</th>\n",
       "      <th>actor_name</th>\n",
       "      <th>date</th>\n",
       "      <th>oscar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>academy_awards_1880</td>\n",
       "      <td>One Flew over the Cuckoo's Nest</td>\n",
       "      <td>Milos Forman</td>\n",
       "      <td>Jack Nicholson</td>\n",
       "      <td>1975-01-01</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>academy_awards_3624</td>\n",
       "      <td>Gaslight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Charles Boyer</td>\n",
       "      <td>1944-01-01</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>academy_awards_3548</td>\n",
       "      <td>Mildred Pierce</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Joan Crawford</td>\n",
       "      <td>1945-01-01</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                            title director_name  \\\n",
       "0  academy_awards_1880  One Flew over the Cuckoo's Nest  Milos Forman   \n",
       "1  academy_awards_3624                         Gaslight           NaN   \n",
       "2  academy_awards_3548                   Mildred Pierce           NaN   \n",
       "\n",
       "       actor_name        date oscar  \n",
       "0  Jack Nicholson  1975-01-01   yes  \n",
       "1   Charles Boyer  1944-01-01   yes  \n",
       "2   Joan Crawford  1945-01-01   yes  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load gold standard and perform accuracy evaluation\n",
    "print(\"Loading Gold Standard for Accuracy Evaluation...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Load gold standard dataset\n",
    "gold_standard_path = root / \"input\" / \"movies\" / \"fusion\" / \"splits\" / \"gold.xml\"\n",
    "gold_df = load_xml(\n",
    "    gold_standard_path,\n",
    "    name='gold_standard',\n",
    "    record_tag='movie',\n",
    "    explode=True,\n",
    "    add_index=False, \n",
    "    include_provenance_columns=False\n",
    ")\n",
    "\n",
    "print(f\"Gold standard loaded: {len(gold_df)} records\")\n",
    "display(gold_df.head(3))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>director_name</th>\n",
       "      <th>actor_name</th>\n",
       "      <th>date</th>\n",
       "      <th>oscar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>academy_awards-1887</td>\n",
       "      <td>One Flew over the Cuckoo's Nest</td>\n",
       "      <td>Milos Forman</td>\n",
       "      <td>Jack Nicholson</td>\n",
       "      <td>1975-01-01</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>academy_awards-3632</td>\n",
       "      <td>Gaslight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Charles Boyer</td>\n",
       "      <td>1944-01-01</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>academy_awards-3556</td>\n",
       "      <td>Mildred Pierce</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Joan Crawford</td>\n",
       "      <td>1945-01-01</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                            title director_name  \\\n",
       "0  academy_awards-1887  One Flew over the Cuckoo's Nest  Milos Forman   \n",
       "1  academy_awards-3632                         Gaslight           NaN   \n",
       "2  academy_awards-3556                   Mildred Pierce           NaN   \n",
       "\n",
       "       actor_name        date oscar  \n",
       "0  Jack Nicholson  1975-01-01   yes  \n",
       "1   Charles Boyer  1944-01-01   yes  \n",
       "2   Joan Crawford  1945-01-01   yes  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gold_df[\"id\"] = gold_df[\"id\"].apply(lambda x: _id_to_pydi_id(x, academy_awards_df, \"id\", \"academy_awards_id\"))\n",
    "display(gold_df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Starting fusion evaluation\n",
      "INFO: Evaluation complete: 0.553 overall accuracy (47/85)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy Evaluation Results:\n",
      "===================================\n",
      "  overall_accuracy: 0.553\n",
      "  macro_accuracy: 0.522\n",
      "  micro_accuracy: 0.553\n",
      "  num_evaluated_records: 18\n",
      "  num_evaluated_attributes: 5\n",
      "  total_evaluations: 85\n",
      "  total_correct: 47\n",
      "  title_accuracy: 0.722\n",
      "  title_count: 18\n",
      "  director_name_accuracy: 0.000\n",
      "  director_name_count: 13\n",
      "  actor_name_accuracy: 0.889\n",
      "  actor_name_count: 18\n",
      "  oscar_accuracy: 1.000\n",
      "  oscar_count: 18\n",
      "  date_accuracy: 0.000\n",
      "  date_count: 18\n",
      "\n",
      "Per-Attribute Accuracy:\n",
      "  actor_name: 0.889\n",
      "  date: 0.000\n",
      "  director_name: 0.000\n",
      "  oscar: 1.000\n",
      "  title: 0.722\n"
     ]
    }
   ],
   "source": [
    "# Create evaluator and run against gold standard\n",
    "evaluator = DataFusionEvaluator(fusion_strategy)\n",
    "\n",
    "# Perform evaluation\n",
    "eval_results = evaluator.evaluate(\n",
    "    fused_df=fused_dataset,\n",
    "    fused_id_column=\"academy_awards_id\",\n",
    "    gold_df=gold_df,\n",
    "    gold_id_column=\"id\"  \n",
    ")\n",
    "\n",
    "print(f\"\\nAccuracy Evaluation Results:\")\n",
    "print(f\"=\" * 35)\n",
    "for metric, value in eval_results.items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"  {metric}: {value:.3f}\")\n",
    "    else:\n",
    "        print(f\"  {metric}: {value}\")\n",
    "\n",
    "# Show detailed per-attribute accuracy if available\n",
    "attribute_accuracies = {k: v for k, v in eval_results.items() if k.endswith('_accuracy') and not k.startswith(('overall', 'macro', 'micro'))}\n",
    "if attribute_accuracies:\n",
    "    print(f\"\\nPer-Attribute Accuracy:\")\n",
    "    for attr, accuracy in sorted(attribute_accuracies.items()):\n",
    "        attr_name = attr.replace('_accuracy', '')\n",
    "        print(f\"  {attr_name}: {accuracy:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Analyzed 12 attributes across 3 datasets\n",
      "INFO: Initialized AttributeCoverageAnalyzer for 3 datasets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Comprehensive Fusion Report...\n",
      "==================================================\n",
      "\n",
      "=== PyDI Data Fusion Report ===\n",
      "Generated: 2025-09-02 15:04:38\n",
      "Strategy: movies_custom\n",
      "\n",
      "📊 Data Summary:\n",
      "  Input datasets: 3\n",
      "  Input records: 7029\n",
      "  Output records: 146\n",
      "  Correspondences: 264\n",
      "  Record coverage: 2.08%\n",
      "\n",
      "📈 Quality Metrics:\n",
      "  Mean confidence: 0.506\n",
      "  Multi-source records: 146\n",
      "  Single-source records: 0\n",
      "\n",
      "👥 Group Statistics:\n",
      "  Total groups: 146\n",
      "  Multi-record groups: 146\n",
      "  Average group size: 2.03\n",
      "  Largest group: 3 records\n",
      "\n",
      "🏷️  Attribute Statistics:\n",
      "  Total attributes: 13\n",
      "  Attributes with conflicts: 0\n",
      "  Most conflicted: actors_id\n",
      "\n",
      "⚙️  Rule Usage:\n",
      "  best_award_rule: 150 applications\n",
      "  first_non_null: 880 applications\n",
      "  longest_string: 146 applications\n",
      "  most_recent: 146 applications\n",
      "  union: 146 applications\n",
      "  voting: 146 applications\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fusion_report = FusionReport(\n",
    "    fused_df=fused_dataset,\n",
    "    input_datasets=[academy_awards_df, actors_df, golden_globes_df],\n",
    "    strategy_name=fusion_strategy.name,\n",
    "    correspondences=all_correspondences\n",
    ")\n",
    "\n",
    "print(\"Generating Comprehensive Fusion Report...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "fusion_report.print_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Advanced Quality Metrics:\n",
      "========================================\n",
      "\n",
      "Quality Metrics:\n",
      "  mean_confidence: 0.506\n",
      "  std_confidence: 0.043\n",
      "  min_confidence: 0.418\n",
      "  max_confidence: 0.558\n",
      "  multi_source_records: 146\n",
      "  single_source_records: 0\n",
      "  mean_sources_per_record: 2.027\n",
      "  rule_usage:\n",
      "    first_non_null: 880\n",
      "    longest_string: 146\n",
      "    union: 146\n",
      "    voting: 146\n",
      "    best_award_rule: 150\n",
      "    ... and 1 more\n",
      "  num_unique_rules: 6\n",
      "\n",
      "Coverage Metrics:\n",
      "  record_coverage: 0.021\n",
      "  attribute_coverage: 1.000\n",
      "  total_input_records: 7029\n",
      "  total_output_records: 146\n",
      "  total_input_attributes: 12\n",
      "  total_output_attributes: 13\n",
      "\n",
      "Export Capabilities:\n"
     ]
    }
   ],
   "source": [
    "# Generate detailed quality and coverage metrics\n",
    "quality_metrics = FusionQualityMetrics.calculate_consistency_metrics(fused_dataset)\n",
    "coverage_metrics = FusionQualityMetrics.calculate_coverage_metrics(datasets, fused_dataset)\n",
    "\n",
    "print(\"Advanced Quality Metrics:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "print(f\"\\nQuality Metrics:\")\n",
    "for key, value in quality_metrics.items():\n",
    "    if isinstance(value, dict) and len(value) <= 10:  # Don't overwhelm with huge dicts\n",
    "        print(f\"  {key}:\")\n",
    "        for sub_key, sub_value in list(value.items())[:5]:  # Limit sub-items\n",
    "            print(f\"    {sub_key}: {sub_value}\")\n",
    "        if len(value) > 5:\n",
    "            print(f\"    ... and {len(value)-5} more\")\n",
    "    elif not isinstance(value, dict):\n",
    "        if isinstance(value, float):\n",
    "            print(f\"  {key}: {value:.3f}\")\n",
    "        else:\n",
    "            print(f\"  {key}: {value}\")\n",
    "\n",
    "print(f\"\\nCoverage Metrics:\")\n",
    "for key, value in coverage_metrics.items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"  {key}: {value:.3f}\")\n",
    "    else:\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "# Show sample JSON export structure (without saving)\n",
    "print(f\"\\nExport Capabilities:\")\n",
    "report_json = fusion_report.to_json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Record Grouping Analysis\n",
    "\n",
    "Examine PyDI's connected components algorithm in detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created 7149 record groups from 264 correspondences\n",
      "INFO: Groups: 2 multi-record, 7005 singleton\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected Components Analysis:\n",
      "=============================================\n",
      "\n",
      "Group Statistics:\n",
      "  Total groups created: 7149\n",
      "  Average group size: 0.98\n",
      "  Largest group size: 3\n",
      "\n",
      "Group Size Distribution:\n",
      "  0 record(s): 142 groups (2.0%)\n",
      "  1 record(s): 7005 groups (98.0%)\n",
      "  2 record(s): 1 groups (0.0%)\n",
      "  3 record(s): 1 groups (0.0%)\n",
      "\n",
      "Multi-Record Groups Details:\n",
      "  Count: 2\n",
      "  Percentage: 0.0%\n"
     ]
    }
   ],
   "source": [
    "# Analyze the connected components grouping process\n",
    "record_groups = build_record_groups_from_correspondences(\n",
    "    [academy_awards_df, actors_df, golden_globes_df],\n",
    "    all_correspondences\n",
    ")\n",
    "\n",
    "print(f\"Connected Components Analysis:\")\n",
    "print(f\"=\" * 45)\n",
    "\n",
    "# Group size analysis\n",
    "group_sizes = [len(group.records) for group in record_groups]\n",
    "group_size_distribution = pd.Series(group_sizes).value_counts().sort_index()\n",
    "\n",
    "print(f\"\\nGroup Statistics:\")\n",
    "print(f\"  Total groups created: {len(record_groups)}\")\n",
    "print(f\"  Average group size: {np.mean(group_sizes):.2f}\")\n",
    "print(f\"  Largest group size: {max(group_sizes)}\")\n",
    "\n",
    "print(f\"\\nGroup Size Distribution:\")\n",
    "for size, count in group_size_distribution.items():\n",
    "    percentage = count / len(record_groups) * 100\n",
    "    print(f\"  {size} record(s): {count} groups ({percentage:.1f}%)\")\n",
    "\n",
    "# Focus on multi-record groups (the interesting ones for fusion)\n",
    "multi_record_groups = [g for g in record_groups if len(g.records) > 1]\n",
    "print(f\"\\nMulti-Record Groups Details:\")\n",
    "print(f\"  Count: {len(multi_record_groups)}\")\n",
    "print(f\"  Percentage: {len(multi_record_groups)/len(record_groups):.1%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Provenance and Trust Analysis\n",
    "\n",
    "Demonstrate PyDI's provenance tracking using the loaded Winter datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up Provenance Tracking for Winter Datasets...\n",
      "  Tracked 4592 records from academy_awards\n",
      "  Tracked 151 records from actors\n",
      "  Tracked 2286 records from golden_globes\n",
      "\n",
      "Provenance Analysis:\n",
      "\n",
      "Sample Fusion Provenance Tracking:\n",
      "  Fused record: fused_group_21\n",
      "  Source datasets: []\n",
      "  Operation: winter_movie_fusion\n",
      "  Confidence: 0.850\n",
      "  Timestamp: 2025-09-02 15:04:38.629762\n"
     ]
    }
   ],
   "source": [
    "# Set up comprehensive provenance tracking\n",
    "provenance_tracker = ProvenanceTracker()\n",
    "\n",
    "print(\"Setting up Provenance Tracking for Winter Datasets...\")\n",
    "\n",
    "# Register data sources with differential trust scores based on Winter characteristics\n",
    "# Academy Awards: Generally very reliable, official source\n",
    "provenance_tracker.register_dataset_source('academy_awards', trust_score=0.95)\n",
    "# Golden Globes: Also reliable, but sometimes has minor discrepancies  \n",
    "provenance_tracker.register_dataset_source('golden_globes', trust_score=0.90)\n",
    "# Actors: Useful for cast info, but sometimes inconsistent on dates/details\n",
    "provenance_tracker.register_dataset_source('actors', trust_score=0.85)\n",
    "\n",
    "# Track all input datasets\n",
    "for df in [academy_awards_df, actors_df, golden_globes_df]:\n",
    "    dataset_name = df.attrs.get('dataset_name', 'unknown')\n",
    "    provenance_tracker.track_input_data(df, dataset_name)\n",
    "    print(f\"  Tracked {len(df)} records from {dataset_name}\")\n",
    "\n",
    "print(f\"\\nProvenance Analysis:\")\n",
    "source_stats = provenance_tracker.get_source_statistics()\n",
    "\n",
    "for source, stats in source_stats.items():\n",
    "    print(f\"\\n{source.title()} Dataset:\")\n",
    "    print(f\"  Records tracked: {stats['record_count']:,}\")\n",
    "    print(f\"  Trust score: {stats['trust_score']:.2f}\")\n",
    "    print(f\"  Average confidence: {stats['average_confidence']:.3f}\")\n",
    "    print(f\"  Data contribution: {stats['contribution_ratio']:.1%}\")\n",
    "\n",
    "# Simulate some fusion result tracking\n",
    "if len(multi_record_groups) > 0:\n",
    "    print(f\"\\nSample Fusion Provenance Tracking:\")\n",
    "    \n",
    "    # Track a sample fusion result\n",
    "    sample_group = multi_record_groups[0]\n",
    "    source_ids = [record.get('id', record.get('_id', '')) for record in sample_group.records]\n",
    "    source_ids = [sid for sid in source_ids if sid]  # Remove empty IDs\n",
    "    \n",
    "    if source_ids:\n",
    "        fused_id = f\"fused_{sample_group.group_id}\"\n",
    "        provenance_tracker.track_fusion_result(\n",
    "            fused_id=fused_id,\n",
    "            source_ids=source_ids,\n",
    "            operation=\"winter_movie_fusion\",\n",
    "            confidence=0.85,\n",
    "            metadata={\"fusion_strategy\": fusion_strategy.name, \"rule_count\": len(fusion_strategy.get_registered_attributes())}\n",
    "        )\n",
    "        \n",
    "        # Show provenance for this fused record\n",
    "        fused_provenance = provenance_tracker.get_provenance(fused_id)\n",
    "        if fused_provenance:\n",
    "            print(f\"  Fused record: {fused_id}\")\n",
    "            print(f\"  Source datasets: {list(fused_provenance.sources)}\")\n",
    "            print(f\"  Operation: {fused_provenance.operation}\")\n",
    "            print(f\"  Confidence: {fused_provenance.confidence:.3f}\")\n",
    "            print(f\"  Timestamp: {fused_provenance.timestamp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyDI Fusion Performance Analysis:\n",
      "=============================================\n",
      "\n",
      "Processing Statistics:\n",
      "  Input datasets: 3\n",
      "  Total input records: 7,029\n",
      "  Total input attributes: 21\n",
      "  Correspondences processed: 264\n",
      "  Fusion rules applied: 6\n",
      "  Output records: 146\n",
      "\n",
      "Performance Metrics:\n",
      "  Total processing time: 0.282 seconds\n",
      "  Records per second: 24916\n",
      "  Correspondences per second: 936\n",
      "  Data reduction achieved: 6,883 records (97.9%)\n",
      "\n",
      "Memory Efficiency:\n",
      "  Input datasets: 2.55 MB\n",
      "  Correspondences: 0.03 MB\n",
      "  Output dataset: 0.19 MB\n",
      "  Memory reduction: 2.36 MB (92.6%)\n",
      "\n",
      "Quality vs Performance:\n",
      "  Average confidence: 0.506\n",
      "  High confidence ratio: 0.0%\n",
      "  Quality per second: 12607\n",
      "\n",
      "Scalability Projections:\n",
      "  10K records: ~0.4 seconds\n",
      "  100K records: ~4.0 seconds\n",
      "  1M records: ~0.7 minutes\n"
     ]
    }
   ],
   "source": [
    "# Comprehensive performance analysis\n",
    "print(\"PyDI Fusion Performance Analysis:\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "# Calculate detailed metrics\n",
    "total_input_records = sum(len(df) for df in datasets)\n",
    "total_attributes = sum(len(df.columns) for df in datasets)\n",
    "total_correspondences = len(all_correspondences)\n",
    "fusion_rules = len(fusion_strategy.get_registered_attributes())\n",
    "\n",
    "print(f\"\\nProcessing Statistics:\")\n",
    "print(f\"  Input datasets: {len(datasets)}\")\n",
    "print(f\"  Total input records: {total_input_records:,}\")\n",
    "print(f\"  Total input attributes: {total_attributes}\")\n",
    "print(f\"  Correspondences processed: {total_correspondences:,}\")\n",
    "print(f\"  Fusion rules applied: {fusion_rules}\")\n",
    "print(f\"  Output records: {len(fused_dataset):,}\")\n",
    "\n",
    "print(f\"\\nPerformance Metrics:\")\n",
    "print(f\"  Total processing time: {runtime:.3f} seconds\")\n",
    "print(f\"  Records per second: {total_input_records/runtime:.0f}\")\n",
    "print(f\"  Correspondences per second: {total_correspondences/runtime:.0f}\")\n",
    "print(f\"  Data reduction achieved: {total_input_records - len(fused_dataset):,} records ({(total_input_records - len(fused_dataset))/total_input_records:.1%})\")\n",
    "\n",
    "# Memory efficiency analysis\n",
    "import sys\n",
    "\n",
    "def get_size_mb(obj):\n",
    "    return sys.getsizeof(obj) / (1024 * 1024)\n",
    "\n",
    "input_size = sum(get_size_mb(df) for df in datasets)\n",
    "output_size = get_size_mb(fused_dataset)\n",
    "corr_size = get_size_mb(all_correspondences)\n",
    "\n",
    "print(f\"\\nMemory Efficiency:\")\n",
    "print(f\"  Input datasets: {input_size:.2f} MB\")\n",
    "print(f\"  Correspondences: {corr_size:.2f} MB\") \n",
    "print(f\"  Output dataset: {output_size:.2f} MB\")\n",
    "print(f\"  Memory reduction: {input_size - output_size:.2f} MB ({(input_size - output_size)/input_size:.1%})\")\n",
    "\n",
    "# Quality vs Speed analysis\n",
    "if '_fusion_confidence' in fused_dataset.columns:\n",
    "    avg_confidence = fused_dataset['_fusion_confidence'].mean()\n",
    "    high_confidence_ratio = (fused_dataset['_fusion_confidence'] >= 0.8).mean()\n",
    "    \n",
    "    print(f\"\\nQuality vs Performance:\")\n",
    "    print(f\"  Average confidence: {avg_confidence:.3f}\")\n",
    "    print(f\"  High confidence ratio: {high_confidence_ratio:.1%}\")\n",
    "    print(f\"  Quality per second: {avg_confidence * total_input_records / runtime:.0f}\")\n",
    "    \n",
    "# Scalability projection\n",
    "print(f\"\\nScalability Projections:\")\n",
    "records_per_sec = total_input_records / runtime\n",
    "print(f\"  10K records: ~{10000/records_per_sec:.1f} seconds\")\n",
    "print(f\"  100K records: ~{100000/records_per_sec:.1f} seconds\")\n",
    "print(f\"  1M records: ~{1000000/records_per_sec/60:.1f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comprehensive Export and Artifact Management:\n",
      "==================================================\n",
      "Output directory: output/winter_fusion_20250902_150438\n",
      "\n",
      "Exporting fused dataset...\n",
      "  ✓ Parquet export successful\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[60]\u001b[39m\u001b[32m, line 57\u001b[39m\n\u001b[32m     53\u001b[39m         f.write(reparsed.toprettyxml(indent=\u001b[33m\"\u001b[39m\u001b[33m  \u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m     55\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(df.head(\u001b[32m10\u001b[39m))\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m xml_records = \u001b[43mdataframe_to_xml\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfused_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_base\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdatasets\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfused_movies_sample.xml\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     58\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  ✓ XML export successful (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mxml_records\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m records)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     60\u001b[39m \u001b[38;5;66;03m# Export comprehensive fusion report\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[60]\u001b[39m\u001b[32m, line 44\u001b[39m, in \u001b[36mdataframe_to_xml\u001b[39m\u001b[34m(df, path, root_tag, record_tag)\u001b[39m\n\u001b[32m     42\u001b[39m movie = SubElement(root, record_tag)\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m col, value \u001b[38;5;129;01min\u001b[39;00m row.items():\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m pd.notna(value) \u001b[38;5;129;01mand\u001b[39;00m col \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m'\u001b[39m\u001b[33m_fusion_group_id\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m_fusion_sources\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m_fusion_confidence\u001b[39m\u001b[33m'\u001b[39m]:\n\u001b[32m     45\u001b[39m         elem = SubElement(movie, col.replace(\u001b[33m'\u001b[39m\u001b[33m_\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m))\n\u001b[32m     46\u001b[39m         elem.text = \u001b[38;5;28mstr\u001b[39m(value)\n",
      "\u001b[31mValueError\u001b[39m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "# Export results with proper organization and artifact management\n",
    "from datetime import datetime\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"Comprehensive Export and Artifact Management:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Create organized output directory structure\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "output_base = Path(\"output\") / f\"winter_fusion_{timestamp}\"\n",
    "output_base.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Create subdirectories\n",
    "(output_base / \"datasets\").mkdir(exist_ok=True)\n",
    "(output_base / \"reports\").mkdir(exist_ok=True)\n",
    "(output_base / \"evaluation\").mkdir(exist_ok=True)\n",
    "(output_base / \"provenance\").mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"Output directory: {output_base}\")\n",
    "\n",
    "# Export fused dataset in multiple formats\n",
    "print(\"\\nExporting fused dataset...\")\n",
    "fused_dataset.to_csv(output_base / \"datasets\" / \"fused_movies.csv\", index=False)\n",
    "\n",
    "# Now Parquet should work with pyarrow installed\n",
    "try:\n",
    "    fused_dataset.to_parquet(output_base / \"datasets\" / \"fused_movies.parquet\")\n",
    "    print(\"  ✓ Parquet export successful\")\n",
    "except Exception as e:\n",
    "    print(f\"  ✗ Parquet export failed: {e}\")\n",
    "\n",
    "# Export as XML (demonstrate XML export)\n",
    "def dataframe_to_xml(df, path, root_tag=\"movies\", record_tag=\"movie\"):\n",
    "    \"\"\"Export DataFrame to XML format.\"\"\"\n",
    "    from xml.etree.ElementTree import Element, SubElement, tostring\n",
    "    from xml.dom import minidom\n",
    "    \n",
    "    root = Element(root_tag)\n",
    "    \n",
    "    for _, row in df.head(10).iterrows():  # Limit to first 10 for demo\n",
    "        movie = SubElement(root, record_tag)\n",
    "        for col, value in row.items():\n",
    "            if pd.notna(value) and col not in ['_fusion_group_id', '_fusion_sources', '_fusion_confidence']:\n",
    "                elem = SubElement(movie, col.replace('_', ''))\n",
    "                elem.text = str(value)\n",
    "    \n",
    "    # Pretty print\n",
    "    rough_string = tostring(root, 'unicode')\n",
    "    reparsed = minidom.parseString(rough_string)\n",
    "    \n",
    "    with open(path, 'w', encoding='utf-8') as f:\n",
    "        f.write(reparsed.toprettyxml(indent=\"  \"))\n",
    "    \n",
    "    return len(df.head(10))\n",
    "\n",
    "xml_records = dataframe_to_xml(fused_dataset, output_base / \"datasets\" / \"fused_movies_sample.xml\")\n",
    "print(f\"  ✓ XML export successful ({xml_records} records)\")\n",
    "\n",
    "# Export comprehensive fusion report\n",
    "print(\"\\nExporting fusion reports...\")\n",
    "fusion_report.export_detailed_results(output_base / \"reports\")\n",
    "fusion_report.to_html(output_base / \"reports\" / \"fusion_report.html\")\n",
    "\n",
    "# Export evaluation results\n",
    "print(\"Exporting evaluation results...\")\n",
    "with open(output_base / \"evaluation\" / \"accuracy_results.json\", 'w') as f:\n",
    "    json.dump(eval_results, f, indent=2, default=str)\n",
    "\n",
    "# Export rule usage metrics (capture what rules were actually used)\n",
    "print(\"Capturing rule usage metrics...\")\n",
    "rule_usage_metrics = {\n",
    "    \"strategy_name\": fusion_strategy.name,\n",
    "    \"total_rules_defined\": len(fusion_strategy.get_registered_attributes()),\n",
    "    \"registered_attributes\": list(fusion_strategy.get_registered_attributes()),\n",
    "    \"runtime\": runtime,\n",
    "    \"multi_record_groups\": 0,  # From our analysis above\n",
    "    \"singleton_groups\": len(fused_dataset),\n",
    "    \"rules_applied\": {\n",
    "        \"title\": \"longest_string\",\n",
    "        \"date\": \"most_recent\", \n",
    "        \"director_name\": \"union\",\n",
    "        \"actor_name\": \"voting\",\n",
    "        \"oscar\": \"best_award_rule\",\n",
    "        \"globe\": \"best_award_rule\"\n",
    "    },\n",
    "    \"custom_rules\": [\"best_award_rule\", \"trust_weighted_fusion_rule\"]\n",
    "}\n",
    "\n",
    "with open(output_base / \"evaluation\" / \"rule_usage_metrics.json\", 'w') as f:\n",
    "    json.dump(rule_usage_metrics, f, indent=2)\n",
    "\n",
    "# Export provenance data\n",
    "print(\"Exporting provenance data...\")\n",
    "provenance_data = provenance_tracker.export_provenance()\n",
    "with open(output_base / \"provenance\" / \"provenance_tracking.json\", 'w') as f:\n",
    "    json.dump(provenance_data, f, indent=2, default=str)\n",
    "\n",
    "# Create comprehensive manifest\n",
    "manifest = {\n",
    "    \"experiment\": {\n",
    "        \"name\": \"PyDI Winter Dataset Fusion Showcase\",\n",
    "        \"timestamp\": timestamp,\n",
    "        \"version\": \"1.0\",\n",
    "        \"description\": \"Data fusion demonstration using Winter movie datasets\"\n",
    "    },\n",
    "    \"inputs\": {\n",
    "        \"datasets\": [\"academy_awards.xml\", \"actors.xml\", \"golden_globes.xml\"],\n",
    "        \"correspondences\": [\"academy_awards_2_actors_correspondences.csv\", \"actors_2_golden_globes_correspondences.csv\"],\n",
    "        \"gold_standard\": \"gold.xml\"\n",
    "    },\n",
    "    \"processing\": {\n",
    "        \"fusion_strategy\": fusion_strategy.name,\n",
    "        \"processing_time_seconds\": runtime,\n",
    "        \"total_input_records\": sum(len(df) for df in datasets),\n",
    "        \"total_output_records\": len(fused_dataset),\n",
    "        \"correspondences_processed\": len(all_correspondences)\n",
    "    },\n",
    "    \"outputs\": {\n",
    "        \"datasets\": {\n",
    "            \"fused_movies.csv\": f\"{len(fused_dataset)} records in CSV format\",\n",
    "            \"fused_movies.parquet\": f\"{len(fused_dataset)} records in Parquet format\",  \n",
    "            \"fused_movies_sample.xml\": f\"{xml_records} records in XML format (sample)\"\n",
    "        },\n",
    "    },\n",
    "    \"metrics\": {\n",
    "        \"accuracy\": eval_results.get(\"overall_accuracy\", 0),\n",
    "        \"confidence\": fused_dataset[\"_fusion_confidence\"].mean() if \"_fusion_confidence\" in fused_dataset.columns else None,\n",
    "        \"coverage\": eval_results.get(\"num_evaluated_records\", 0) / len(gold_df) if len(gold_df) > 0 else 0\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(output_base / \"manifest.json\", 'w') as f:\n",
    "    json.dump(manifest, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Report saved to output/winter_fusion/fusion_report.json\n",
      "INFO: HTML report saved to output/winter_fusion/fusion_report.html\n",
      "WARNING: Could not export coverage analysis: 'AttributeCoverageAnalyzer' object has no attribute 'suggest_fusion_rules'\n",
      "INFO: Detailed results exported to output/winter_fusion/\n",
      "INFO: HTML report saved to fusion_report.html\n"
     ]
    }
   ],
   "source": [
    "# Export fused dataset to CSV and Parquet\n",
    "fused_dataset.to_csv('winter_movies_fused.csv', index=False)\n",
    "fused_dataset.to_parquet('winter_movies_fused.parquet')\n",
    "\n",
    "# Export comprehensive fusion report\n",
    "fusion_report.export_detailed_results('output/winter_fusion/')\n",
    "fusion_report.to_html('fusion_report.html')\n",
    "\n",
    "# Export provenance data\n",
    "provenance_data = provenance_tracker.export_provenance()\n",
    "import json\n",
    "with open('provenance.json', 'w') as f:\n",
    "    json.dump(provenance_data, f, indent=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
