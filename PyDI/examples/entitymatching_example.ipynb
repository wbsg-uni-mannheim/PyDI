{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyDI Entity Matching with RuleBasedMatcher Example\n",
    "\n",
    "This notebook demonstrates the comprehensive entity matching capabilities in PyDI using the RuleBasedMatcher.\n",
    "\n",
    "What this shows:\n",
    "- Load datasets with provenance tracking\n",
    "- **Simple candidate generation**: Create candidate pairs for matching without full blocking\n",
    "- **Rule-based entity matching**: Use multiple comparators to find duplicate records\n",
    "- **Different similarity functions**: String, numeric, and date comparators\n",
    "- **Evaluation**: Assess matching quality with precision, recall, and F1 scores\n",
    "- **Threshold tuning**: Find optimal similarity thresholds\n",
    "- **End-to-end workflow**: Complete entity matching pipeline\n",
    "\n",
    "Run cells below in order. Adjust paths if running outside the repo root."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyDI imports\n",
    "from PyDI.io import load_xml\n",
    "from PyDI.entitymatching import (\n",
    "    RuleBasedMatcher,\n",
    "    StringComparator,\n",
    "    NumericComparator,\n",
    "    DateComparator,\n",
    "    EntityMatchingEvaluator,\n",
    "    ensure_record_ids\n",
    ")\n",
    "\n",
    "# Additional imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import itertools\n",
    "from datetime import datetime\n",
    "\n",
    "def repo_root():\n",
    "    \"\"\"Return the repository root directory.\"\"\"\n",
    "    # For notebooks in PyDI/examples/, go up 2 levels to reach repo root\n",
    "    if '__file__' in globals():\n",
    "        return Path(__file__).parent.parent.parent\n",
    "    else:\n",
    "        # In Jupyter, find the pyproject.toml to locate repo root\n",
    "        current = Path.cwd()\n",
    "        while current != current.parent:\n",
    "            if (current / 'pyproject.toml').exists():\n",
    "                return current\n",
    "            current = current.parent\n",
    "        return Path.cwd()  # fallback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load datasets with provenance\n",
    "\n",
    "We'll use the movie datasets - Academy Awards and Actors data. These datasets contain movie information from different sources and are commonly used for entity matching research."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Academy awards data: c:\\Users\\Ralph\\dev\\pydi\\input\\movies\\entitymatching\\data\\academy_awards.xml\n",
      "Actors data: c:\\Users\\Ralph\\dev\\pydi\\input\\movies\\entitymatching\\data\\actors.xml\n",
      "\n",
      "Academy Awards shape: (4592, 7)\n",
      "Academy Awards columns: ['academy_awards_id', 'id', 'title', 'actor_name', 'date', 'director_name', 'oscar']\n",
      "\n",
      "Actors shape: (149, 7)\n",
      "Actors columns: ['actors_id', 'id', 'title', 'actor_name', 'actors_actor_birthday', 'actors_actor_birthplace', 'date']\n"
     ]
    }
   ],
   "source": [
    "root = repo_root()\n",
    "academy_path = root / \"input\" / \"movies\" / \"entitymatching\" / \"data\" / \"academy_awards.xml\"\n",
    "actors_path = root / \"input\" / \"movies\" / \"entitymatching\" / \"data\" / \"actors.xml\"\n",
    "\n",
    "print(f\"Academy awards data: {academy_path}\")\n",
    "print(f\"Actors data: {actors_path}\")\n",
    "\n",
    "# Load datasets using PyDI's provenance-aware XML loader\n",
    "academy_df = load_xml(academy_path, name=\"academy_awards\")\n",
    "actors_df = load_xml(actors_path, name=\"actors\")\n",
    "\n",
    "print(f\"\\nAcademy Awards shape: {academy_df.shape}\")\n",
    "print(f\"Academy Awards columns: {list(academy_df.columns)}\")\n",
    "\n",
    "print(f\"\\nActors shape: {actors_df.shape}\")\n",
    "print(f\"Actors columns: {list(actors_df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Academy Awards Dataset Sample ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>academy_awards_id</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>actor_name</th>\n",
       "      <th>date</th>\n",
       "      <th>director_name</th>\n",
       "      <th>oscar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>academy_awards-0000</td>\n",
       "      <td>academy_awards_1</td>\n",
       "      <td>Biutiful</td>\n",
       "      <td>Javier Bardem</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>academy_awards-0001</td>\n",
       "      <td>academy_awards_2</td>\n",
       "      <td>True Grit</td>\n",
       "      <td>Jeff Bridges</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>Joel Coen</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>academy_awards-0002</td>\n",
       "      <td>academy_awards_2</td>\n",
       "      <td>True Grit</td>\n",
       "      <td>Jeff Bridges</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>Ethan Coen</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     academy_awards_id                id      title     actor_name  \\\n",
       "0  academy_awards-0000  academy_awards_1   Biutiful  Javier Bardem   \n",
       "1  academy_awards-0001  academy_awards_2  True Grit   Jeff Bridges   \n",
       "2  academy_awards-0002  academy_awards_2  True Grit   Jeff Bridges   \n",
       "\n",
       "         date director_name oscar  \n",
       "0  2010-01-01           NaN   NaN  \n",
       "1  2010-01-01     Joel Coen   NaN  \n",
       "2  2010-01-01    Ethan Coen   NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Actors Dataset Sample ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actors_id</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>actor_name</th>\n",
       "      <th>actors_actor_birthday</th>\n",
       "      <th>actors_actor_birthplace</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>actors-0000</td>\n",
       "      <td>actors_1</td>\n",
       "      <td>7th Heaven</td>\n",
       "      <td>Janet Gaynor</td>\n",
       "      <td>1906-01-01</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>1929-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>actors-0001</td>\n",
       "      <td>actors_2</td>\n",
       "      <td>Coquette</td>\n",
       "      <td>Mary Pickford</td>\n",
       "      <td>1892-01-01</td>\n",
       "      <td>Canada</td>\n",
       "      <td>1930-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>actors-0002</td>\n",
       "      <td>actors_3</td>\n",
       "      <td>The Divorcee</td>\n",
       "      <td>Norma Shearer</td>\n",
       "      <td>1902-01-01</td>\n",
       "      <td>Canada</td>\n",
       "      <td>1931-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     actors_id        id         title     actor_name actors_actor_birthday  \\\n",
       "0  actors-0000  actors_1    7th Heaven   Janet Gaynor            1906-01-01   \n",
       "1  actors-0001  actors_2      Coquette  Mary Pickford            1892-01-01   \n",
       "2  actors-0002  actors_3  The Divorcee  Norma Shearer            1902-01-01   \n",
       "\n",
       "  actors_actor_birthplace        date  \n",
       "0            Pennsylvania  1929-01-01  \n",
       "1                  Canada  1930-01-01  \n",
       "2                  Canada  1931-01-01  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Preview the datasets to understand their structure\n",
    "print(\"=== Academy Awards Dataset Sample ===\")\n",
    "display(academy_df.head(3))\n",
    "\n",
    "print(\"\\n=== Actors Dataset Sample ===\") \n",
    "display(actors_df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Academy Awards dataset now has 4592 records with _id column\n",
      "Actors dataset now has 149 records with _id column\n",
      "\n",
      "Sample Academy Awards IDs: ['academy_awards_000000', 'academy_awards_000001', 'academy_awards_000002']\n",
      "Sample Actors IDs: ['actors_000000', 'actors_000001', 'actors_000002']\n"
     ]
    }
   ],
   "source": [
    "# Ensure datasets have record IDs for entity matching\n",
    "academy_df = ensure_record_ids(academy_df)\n",
    "actors_df = ensure_record_ids(actors_df)\n",
    "\n",
    "print(f\"Academy Awards dataset now has {len(academy_df)} records with _id column\")\n",
    "print(f\"Actors dataset now has {len(actors_df)} records with _id column\")\n",
    "\n",
    "print(f\"\\nSample Academy Awards IDs: {academy_df['_id'].head(3).tolist()}\")\n",
    "print(f\"Sample Actors IDs: {actors_df['_id'].head(3).tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Data Exploration and Understanding\n",
    "\n",
    "Let's explore the datasets to understand what attributes we can use for matching and their data quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Academy Awards Dataset Quality Analysis ===\n",
      "Total records: 4592\n",
      "  title: 4580/4592 (99.7% complete)\n",
      "  actor_name: 1057/4592 (23.0% complete)\n",
      "  date: 4592/4592 (100.0% complete)\n",
      "  director_name: 420/4592 (9.1% complete)\n",
      "\n",
      "Sample titles: ['Biutiful', 'True Grit', 'True Grit', 'The Social Network', \"The King's Speech\"]\n",
      "Sample actors: ['Javier Bardem', 'Jeff Bridges', 'Jeff Bridges', 'Jesse Eisenberg', 'Colin Firth']\n",
      "\n",
      "=== Actors Dataset Quality Analysis ===\n",
      "Total records: 149\n",
      "  title: 149/149 (100.0% complete)\n",
      "  actor_name: 149/149 (100.0% complete)\n",
      "  date: 149/149 (100.0% complete)\n",
      "\n",
      "Sample titles: ['7th Heaven', 'Coquette', 'The Divorcee', 'Min and Bill', 'The Sin of Madelon Claudet']\n",
      "Sample actors: ['Janet Gaynor', 'Mary Pickford', 'Norma Shearer', 'Marie Dressler', 'Helen Hayes']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Analyze data completeness and overlap\n",
    "def analyze_dataset_quality(df, name):\n",
    "    print(f\"=== {name} Dataset Quality Analysis ===\")\n",
    "    print(f\"Total records: {len(df)}\")\n",
    "    \n",
    "    # Check key columns for completeness\n",
    "    key_columns = ['title', 'actor_name', 'date', 'director_name']\n",
    "    available_columns = [col for col in key_columns if col in df.columns]\n",
    "    \n",
    "    for col in available_columns:\n",
    "        non_null = df[col].notna().sum()\n",
    "        completeness = (non_null / len(df)) * 100\n",
    "        print(f\"  {col}: {non_null}/{len(df)} ({completeness:.1f}% complete)\")\n",
    "    \n",
    "    # Show some sample values for key attributes\n",
    "    if 'title' in df.columns:\n",
    "        print(f\"\\nSample titles: {df['title'].dropna().head(5).tolist()}\")\n",
    "    \n",
    "    if 'actor_name' in df.columns:\n",
    "        print(f\"Sample actors: {df['actor_name'].dropna().head(5).tolist()}\")\n",
    "        \n",
    "    print()\n",
    "\n",
    "analyze_dataset_quality(academy_df, \"Academy Awards\")\n",
    "analyze_dataset_quality(actors_df, \"Actors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Academy Awards Date Analysis ===\n",
      "Date range: 1927-01-01 to 2010-01-01\n",
      "Sample dates: ['2010-01-01', '2010-01-01', '2010-01-01']\n",
      "Date parsing successful: 4592 dates parsed\n",
      "\n",
      "=== Actors Date Analysis ===\n",
      "Date range: 1929-01-01 to 2005-01-01\n",
      "Sample dates: ['1929-01-01', '1930-01-01', '1931-01-01']\n",
      "Date parsing successful: 149 dates parsed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check date formats and ranges\n",
    "def analyze_dates(df, name):\n",
    "    if 'date' not in df.columns:\n",
    "        print(f\"{name}: No date column\")\n",
    "        return\n",
    "        \n",
    "    print(f\"=== {name} Date Analysis ===\")\n",
    "    date_col = df['date'].dropna()\n",
    "    if len(date_col) > 0:\n",
    "        print(f\"Date range: {date_col.min()} to {date_col.max()}\")\n",
    "        print(f\"Sample dates: {date_col.head(3).tolist()}\")\n",
    "        \n",
    "        # Try to parse dates to check format consistency\n",
    "        try:\n",
    "            parsed_dates = pd.to_datetime(date_col)\n",
    "            print(f\"Date parsing successful: {len(parsed_dates)} dates parsed\")\n",
    "        except Exception as e:\n",
    "            print(f\"Date parsing issues: {e}\")\n",
    "    print()\n",
    "\n",
    "analyze_dates(academy_df, \"Academy Awards\")\n",
    "analyze_dates(actors_df, \"Actors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Simple Candidate Generation\n",
    "\n",
    "Since PyDI doesn't have blocking algorithms implemented yet, we'll create simple candidate generation strategies. In practice, you'd use more sophisticated blocking techniques to reduce the number of candidate pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating candidate pairs...\n",
      "Random candidates: 200 pairs\n",
      "Title-based candidates: 500 pairs\n",
      "\n",
      "Sample candidate pairs:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id1</th>\n",
       "      <th>id2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>academy_awards_000393</td>\n",
       "      <td>actors_000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>academy_awards_002506</td>\n",
       "      <td>actors_000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>academy_awards_004567</td>\n",
       "      <td>actors_000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>academy_awards_000013</td>\n",
       "      <td>actors_000023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>academy_awards_000013</td>\n",
       "      <td>actors_000028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id1            id2\n",
       "0  academy_awards_000393  actors_000000\n",
       "1  academy_awards_002506  actors_000000\n",
       "2  academy_awards_004567  actors_000000\n",
       "3  academy_awards_000013  actors_000023\n",
       "4  academy_awards_000013  actors_000028"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_sample_candidates(df_left, df_right, max_pairs=100, strategy=\"random\"):\n",
    "    \"\"\"Create candidate pairs for entity matching.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df_left, df_right : pandas.DataFrame\n",
    "        Source datasets with _id columns\n",
    "    max_pairs : int\n",
    "        Maximum number of candidate pairs to generate\n",
    "    strategy : str\n",
    "        Strategy for candidate generation: 'random', 'all', 'title_similarity'\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        Candidate pairs with id1, id2 columns\n",
    "    \"\"\"\n",
    "    left_ids = df_left['_id'].tolist()\n",
    "    right_ids = df_right['_id'].tolist()\n",
    "    \n",
    "    if strategy == \"all\":\n",
    "        # Cartesian product (use with caution - can be very large!)\n",
    "        candidates = [(left_id, right_id) for left_id in left_ids for right_id in right_ids]\n",
    "        candidates = candidates[:max_pairs]  # Limit size\n",
    "        \n",
    "    elif strategy == \"random\":\n",
    "        # Random sampling\n",
    "        np.random.seed(42)  # For reproducibility\n",
    "        candidates = []\n",
    "        for _ in range(min(max_pairs, len(left_ids) * len(right_ids))):\n",
    "            left_id = np.random.choice(left_ids)\n",
    "            right_id = np.random.choice(right_ids)\n",
    "            candidates.append((left_id, right_id))\n",
    "            \n",
    "    elif strategy == \"title_similarity\":\n",
    "        # Simple title-based blocking (first character match)\n",
    "        candidates = []\n",
    "        \n",
    "        # Group by first character of title (simple blocking key)\n",
    "        left_groups = df_left.groupby(df_left['title'].str[0].fillna(''))['_id'].apply(list).to_dict()\n",
    "        right_groups = df_right.groupby(df_right['title'].str[0].fillna(''))['_id'].apply(list).to_dict()\n",
    "        \n",
    "        for key in left_groups:\n",
    "            if key in right_groups:\n",
    "                for left_id in left_groups[key]:\n",
    "                    for right_id in right_groups[key]:\n",
    "                        candidates.append((left_id, right_id))\n",
    "                        if len(candidates) >= max_pairs:\n",
    "                            break\n",
    "                    if len(candidates) >= max_pairs:\n",
    "                        break\n",
    "                if len(candidates) >= max_pairs:\n",
    "                    break\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    candidate_df = pd.DataFrame(candidates, columns=['id1', 'id2'])\n",
    "    \n",
    "    # Remove duplicates\n",
    "    candidate_df = candidate_df.drop_duplicates()\n",
    "    \n",
    "    return candidate_df\n",
    "\n",
    "# Create candidate pairs using different strategies\n",
    "print(\"Generating candidate pairs...\")\n",
    "\n",
    "# Random sampling - good for initial exploration\n",
    "random_candidates = create_sample_candidates(academy_df, actors_df, max_pairs=200, strategy=\"random\")\n",
    "print(f\"Random candidates: {len(random_candidates)} pairs\")\n",
    "\n",
    "# Title-based simple blocking - more targeted\n",
    "title_candidates = create_sample_candidates(academy_df, actors_df, max_pairs=500, strategy=\"title_similarity\")\n",
    "print(f\"Title-based candidates: {len(title_candidates)} pairs\")\n",
    "\n",
    "print(f\"\\nSample candidate pairs:\")\n",
    "display(title_candidates.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: RuleBasedMatcher with String Similarity\n",
    "\n",
    "Let's start with simple string-based matching using movie titles. This is often the most discriminative attribute for movie data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title-based matching found 7 matches above threshold 0.7\n",
      "\n",
      "Top matches by similarity score:\n",
      "  Score 1.000: '7th Heaven' <-> '7th Heaven'\n",
      "  Score 0.885: 'American Gangster' <-> 'American Beauty'\n",
      "  Score 0.851: 'American Splendor' <-> 'American Beauty'\n",
      "  Score 0.825: 'Alice in Wonderland' <-> 'Alice Doesn�t live Here Anymor'\n",
      "  Score 0.790: 'Ali' <-> 'Alice Doesn�t live Here Anymor'\n",
      "  Score 0.778: 'Ali' <-> 'All the King's Men'\n",
      "  Score 0.733: 'Avatar' <-> 'Anastasia'\n"
     ]
    }
   ],
   "source": [
    "# Create string comparator for titles\n",
    "title_comparator = StringComparator(\n",
    "    column=\"title\", \n",
    "    similarity_function=\"jaro_winkler\",  # Good for names and titles\n",
    "    preprocess=str.lower  # Normalize case\n",
    ")\n",
    "\n",
    "# Initialize rule-based matcher\n",
    "matcher = RuleBasedMatcher()\n",
    "\n",
    "# Perform title-only matching\n",
    "title_matches = matcher.match(\n",
    "    df_left=academy_df,\n",
    "    df_right=actors_df,\n",
    "    candidates=[title_candidates],  # Use title-based candidates\n",
    "    comparators=[title_comparator],\n",
    "    weights=[1.0],  # Single comparator, full weight\n",
    "    threshold=0.7  # Require 70% similarity\n",
    ")\n",
    "\n",
    "print(f\"Title-based matching found {len(title_matches)} matches above threshold 0.7\")\n",
    "\n",
    "if len(title_matches) > 0:\n",
    "    print(f\"\\nTop matches by similarity score:\")\n",
    "    top_matches = title_matches.sort_values('score', ascending=False).head(10)\n",
    "    \n",
    "    # Show matches with actual titles for verification\n",
    "    for _, match in top_matches.iterrows():\n",
    "        id1, id2, score = match['id1'], match['id2'], match['score']\n",
    "        \n",
    "        # Get titles\n",
    "        title1 = academy_df[academy_df['_id'] == id1]['title'].iloc[0]\n",
    "        title2 = actors_df[actors_df['_id'] == id2]['title'].iloc[0]\n",
    "        \n",
    "        print(f\"  Score {score:.3f}: '{title1}' <-> '{title2}'\")\n",
    "else:\n",
    "    print(\"No matches found with current threshold. Try lowering the threshold.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing different string similarity functions:\n",
      "Using threshold: 0.5\n",
      "\n",
      "JARO_WINKLER:  71 matches\n",
      "               Best: 1.000 - '7th Heaven' <-> '7th Heaven'\n",
      "\n",
      "LEVENSHTEIN :   1 matches\n",
      "               Best: 1.000 - '7th Heaven' <-> '7th Heaven'\n",
      "\n",
      "JACCARD     :   5 matches\n",
      "               Best: 1.000 - '7th Heaven' <-> '7th Heaven'\n",
      "\n",
      "COSINE      :  39 matches\n",
      "               Best: 1.000 - '7th Heaven' <-> '7th Heaven'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's try different similarity functions and thresholds\n",
    "similarity_functions = [\"jaro_winkler\", \"levenshtein\", \"jaccard\", \"cosine\"]\n",
    "threshold = 0.5  # Lower threshold to see more results\n",
    "\n",
    "print(\"Comparing different string similarity functions:\")\n",
    "print(f\"Using threshold: {threshold}\")\n",
    "print()\n",
    "\n",
    "for sim_func in similarity_functions:\n",
    "    comparator = StringComparator(\n",
    "        column=\"title\", \n",
    "        similarity_function=sim_func,\n",
    "        preprocess=str.lower\n",
    "    )\n",
    "    \n",
    "    matches = matcher.match(\n",
    "        df_left=academy_df,\n",
    "        df_right=actors_df,\n",
    "        candidates=[title_candidates[:100]],  # Limit for speed\n",
    "        comparators=[comparator],\n",
    "        threshold=threshold\n",
    "    )\n",
    "    \n",
    "    print(f\"{sim_func.upper():12}: {len(matches):3d} matches\")\n",
    "    \n",
    "    if len(matches) > 0:\n",
    "        best_match = matches.loc[matches['score'].idxmax()]\n",
    "        id1, id2, score = best_match['id1'], best_match['id2'], best_match['score']\n",
    "        title1 = academy_df[academy_df['_id'] == id1]['title'].iloc[0]\n",
    "        title2 = actors_df[actors_df['_id'] == id2]['title'].iloc[0]\n",
    "        print(f\"{'':12}   Best: {score:.3f} - '{title1}' <-> '{title2}'\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Multi-Attribute Matching\n",
    "\n",
    "Now let's combine multiple attributes for more robust matching. We'll use title, date, and actor information where available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-attribute matching with different weight configurations:\n",
      "\n",
      "Title-focused       :   1 matches (weights: [0.6, 0.2, 0.2])\n",
      "                      Best score: 0.800\n",
      "\n",
      "Title+Date balanced :   1 matches (weights: [0.4, 0.4, 0.2])\n",
      "                      Best score: 0.600\n",
      "\n",
      "Equal weights       :   1 matches (weights: [0.33, 0.33, 0.34])\n",
      "                      Best score: 0.670\n",
      "\n",
      "Title+Actor focused :   1 matches (weights: [0.5, 0.1, 0.4])\n",
      "                      Best score: 0.900\n",
      "\n",
      "Best configuration: Title-focused with 1 matches\n"
     ]
    }
   ],
   "source": [
    "# Create multiple comparators for different attributes\n",
    "comparators = [\n",
    "    StringComparator(\"title\", similarity_function=\"jaro_winkler\", preprocess=str.lower),\n",
    "    DateComparator(\"date\", max_days_difference=365),  # Allow 1 year difference\n",
    "    StringComparator(\"actor_name\", similarity_function=\"jaro_winkler\", preprocess=str.lower)\n",
    "]\n",
    "\n",
    "# Different weight configurations to test\n",
    "weight_configs = [\n",
    "    ([0.6, 0.2, 0.2], \"Title-focused\"),\n",
    "    ([0.4, 0.4, 0.2], \"Title+Date balanced\"),  \n",
    "    ([0.33, 0.33, 0.34], \"Equal weights\"),\n",
    "    ([0.5, 0.1, 0.4], \"Title+Actor focused\")\n",
    "]\n",
    "\n",
    "print(\"Multi-attribute matching with different weight configurations:\")\n",
    "print()\n",
    "\n",
    "best_config = None\n",
    "best_count = 0\n",
    "\n",
    "for weights, description in weight_configs:\n",
    "    multi_matches = matcher.match(\n",
    "        df_left=academy_df,\n",
    "        df_right=actors_df,\n",
    "        candidates=[title_candidates[:150]],  # Limit for performance\n",
    "        comparators=comparators,\n",
    "        weights=weights,\n",
    "        threshold=0.6\n",
    "    )\n",
    "    \n",
    "    print(f\"{description:20}: {len(multi_matches):3d} matches (weights: {weights})\")\n",
    "    \n",
    "    if len(multi_matches) > best_count:\n",
    "        best_count = len(multi_matches)\n",
    "        best_config = (weights, description, multi_matches)\n",
    "        \n",
    "    # Show best match for this configuration\n",
    "    if len(multi_matches) > 0:\n",
    "        best = multi_matches.loc[multi_matches['score'].idxmax()]\n",
    "        print(f\"{'':20}  Best score: {best['score']:.3f}\")\n",
    "    print()\n",
    "\n",
    "print(f\"Best configuration: {best_config[1]} with {best_count} matches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Detailed Analysis: Title-focused Configuration ===\n",
      "Weights: [0.6, 0.2, 0.2]\n",
      "Total matches: 1\n",
      "\n",
      "Score distribution:\n",
      "  Mean: 0.800\n",
      "  Std:  nan\n",
      "  Min:  0.800\n",
      "  Max:  0.800\n",
      "\n",
      "Top 5 matches:\n",
      "\n",
      "1. Score: 0.800\n",
      "   Academy: '7th Heaven' (1927-01-01) - Janet Gaynor\n",
      "   Actors:  '7th Heaven' (1929-01-01) - Janet Gaynor\n"
     ]
    }
   ],
   "source": [
    "# Use the best configuration for detailed analysis\n",
    "if best_config:\n",
    "    best_weights, best_desc, best_matches = best_config\n",
    "    \n",
    "    print(f\"=== Detailed Analysis: {best_desc} Configuration ===\")\n",
    "    print(f\"Weights: {best_weights}\")\n",
    "    print(f\"Total matches: {len(best_matches)}\")\n",
    "    \n",
    "    if len(best_matches) > 0:\n",
    "        print(f\"\\nScore distribution:\")\n",
    "        print(f\"  Mean: {best_matches['score'].mean():.3f}\")\n",
    "        print(f\"  Std:  {best_matches['score'].std():.3f}\")\n",
    "        print(f\"  Min:  {best_matches['score'].min():.3f}\")\n",
    "        print(f\"  Max:  {best_matches['score'].max():.3f}\")\n",
    "        \n",
    "        print(f\"\\nTop 5 matches:\")\n",
    "        top_5 = best_matches.sort_values('score', ascending=False).head(5)\n",
    "        \n",
    "        for i, (_, match) in enumerate(top_5.iterrows(), 1):\n",
    "            id1, id2, score = match['id1'], match['id2'], match['score']\n",
    "            \n",
    "            # Get record details\n",
    "            rec1 = academy_df[academy_df['_id'] == id1].iloc[0]\n",
    "            rec2 = actors_df[actors_df['_id'] == id2].iloc[0]\n",
    "            \n",
    "            print(f\"\\n{i}. Score: {score:.3f}\")\n",
    "            print(f\"   Academy: '{rec1.get('title', 'N/A')}' ({rec1.get('date', 'N/A')}) - {rec1.get('actor_name', 'N/A')}\")\n",
    "            print(f\"   Actors:  '{rec2.get('title', 'N/A')}' ({rec2.get('date', 'N/A')}) - {rec2.get('actor_name', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Load Ground Truth and Evaluation\n",
    "\n",
    "Now let's load the ground truth correspondences and evaluate our matching performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training correspondences: 358 pairs\n",
      "Test correspondences: 3347 pairs\n",
      "\n",
      "Training set label distribution:\n",
      "label\n",
      "0    255\n",
      "1    103\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample training correspondences:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id1</th>\n",
       "      <th>id2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>academy_awards_004556</td>\n",
       "      <td>actors_000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>academy_awards_004362</td>\n",
       "      <td>actors_000006</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>academy_awards_004319</td>\n",
       "      <td>actors_000007</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>academy_awards_004206</td>\n",
       "      <td>actors_000009</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>academy_awards_004145</td>\n",
       "      <td>actors_000010</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id1            id2  label\n",
       "0  academy_awards_004556  actors_000000      1\n",
       "1  academy_awards_004362  actors_000006      1\n",
       "2  academy_awards_004319  actors_000007      1\n",
       "3  academy_awards_004206  actors_000009      1\n",
       "4  academy_awards_004145  actors_000010      1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set label distribution:\n",
      "label\n",
      "0    3300\n",
      "1      47\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load ground truth correspondences\n",
    "train_path = root / \"input\" / \"movies\" / \"entitymatching\" / \"splits\" / \"gs_academy_awards_2_actors_training.csv\"\n",
    "test_path = root / \"input\" / \"movies\" / \"entitymatching\" / \"splits\" / \"gs_academy_awards_2_actors_test.csv\"\n",
    "\n",
    "def load_correspondences(file_path):\n",
    "    \"\"\"Load correspondence file and convert to PyDI ID format.\"\"\"\n",
    "    if not file_path.exists():\n",
    "        print(f\"File not found: {file_path}\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Load raw correspondences\n",
    "    corr = pd.read_csv(file_path, names=['id1', 'id2', 'label'])\n",
    "    \n",
    "    # Convert boolean labels to numeric\n",
    "    corr['label'] = corr['label'].map({True: 1, 'TRUE': 1, False: 0, 'FALSE': 0})\n",
    "    \n",
    "    # Convert original XML IDs to PyDI format\n",
    "    # Original IDs like 'academy_awards_1' need to be converted to 'academy_awards_000000'\n",
    "    def convert_id(original_id):\n",
    "        if pd.isna(original_id):\n",
    "            return original_id\n",
    "        \n",
    "        id_str = str(original_id)\n",
    "        if 'academy_awards_' in id_str:\n",
    "            # Extract number and reformat\n",
    "            try:\n",
    "                num = int(id_str.split('_')[-1]) - 1  # Convert to 0-based index\n",
    "                return f\"academy_awards_{num:06d}\"\n",
    "            except:\n",
    "                return id_str\n",
    "        elif 'actors_' in id_str:\n",
    "            # Extract number and reformat\n",
    "            try:\n",
    "                num = int(id_str.split('_')[-1]) - 1  # Convert to 0-based index\n",
    "                return f\"actors_{num:06d}\"\n",
    "            except:\n",
    "                return id_str\n",
    "        \n",
    "        return id_str\n",
    "    \n",
    "    corr['id1'] = corr['id1'].apply(convert_id)\n",
    "    corr['id2'] = corr['id2'].apply(convert_id)\n",
    "    \n",
    "    return corr\n",
    "\n",
    "# Load training and test correspondences\n",
    "train_corr = load_correspondences(train_path)\n",
    "test_corr = load_correspondences(test_path)\n",
    "\n",
    "print(f\"Training correspondences: {len(train_corr)} pairs\")\n",
    "print(f\"Test correspondences: {len(test_corr)} pairs\")\n",
    "\n",
    "if len(train_corr) > 0:\n",
    "    print(f\"\\nTraining set label distribution:\")\n",
    "    print(train_corr['label'].value_counts())\n",
    "    \n",
    "    print(f\"\\nSample training correspondences:\")\n",
    "    display(train_corr.head())\n",
    "\n",
    "if len(test_corr) > 0:\n",
    "    print(f\"\\nTest set label distribution:\")\n",
    "    print(test_corr['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Record not found: academy_awards_000401 or actors_000149\n",
      "WARNING:root:Record not found: academy_awards_000345 or actors_000150\n",
      "WARNING:root:Record not found: academy_awards_001271 or actors_000153\n",
      "WARNING:root:Record not found: academy_awards_001540 or actors_000173\n",
      "WARNING:root:Record not found: academy_awards_001632 or actors_000159\n",
      "WARNING:root:Record not found: academy_awards_001879 or actors_000157\n",
      "WARNING:root:Record not found: academy_awards_002140 or actors_000155\n",
      "WARNING:root:Record not found: academy_awards_002186 or actors_000151\n",
      "WARNING:root:Record not found: academy_awards_002287 or actors_000158\n",
      "WARNING:root:Record not found: academy_awards_002333 or actors_000172\n",
      "WARNING:root:Record not found: academy_awards_002565 or actors_000149\n",
      "WARNING:root:Record not found: academy_awards_002619 or actors_000160\n",
      "WARNING:root:Record not found: academy_awards_002624 or actors_000152\n",
      "WARNING:root:Record not found: academy_awards_003422 or actors_000161\n",
      "WARNING:root:Record not found: academy_awards_003712 or actors_000154\n",
      "WARNING:root:Record not found: academy_awards_003812 or actors_000156\n",
      "WARNING:root:Record not found: academy_awards_004396 or actors_000170\n",
      "WARNING:root:Record not found: academy_awards_004398 or actors_000167\n",
      "WARNING:root:Record not found: academy_awards_004441 or actors_000168\n",
      "WARNING:root:Record not found: academy_awards_004443 or actors_000164\n",
      "WARNING:root:Record not found: academy_awards_004445 or actors_000171\n",
      "WARNING:root:Record not found: academy_awards_004474 or actors_000166\n",
      "WARNING:root:Record not found: academy_awards_004490 or actors_000163\n",
      "WARNING:root:Record not found: academy_awards_004499 or actors_000169\n",
      "WARNING:root:Record not found: academy_awards_004519 or actors_000165\n",
      "WARNING:root:Record not found: academy_awards_004528 or actors_000162\n",
      "WARNING:root:Record not found: academy_awards_000502 or actors_000150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 358 training pairs as candidates\n",
      "Matching found 40 matches above threshold 0.5\n",
      "\n",
      "=== Evaluation Results ===\n",
      "Precision: 0.750\n",
      "Recall:    0.291\n",
      "F1 Score:  0.420\n",
      "\n",
      "Correct matches: 30\n",
      "False positives: 10\n",
      "False negatives: 73\n"
     ]
    }
   ],
   "source": [
    "# Use training correspondences as candidates for evaluation\n",
    "# This simulates having perfect recall from blocking\n",
    "if len(train_corr) > 0:\n",
    "    # Use training pairs as candidates\n",
    "    train_candidates = train_corr[['id1', 'id2']].copy()\n",
    "    \n",
    "    print(f\"Using {len(train_candidates)} training pairs as candidates\")\n",
    "    \n",
    "    # Perform matching with our best configuration\n",
    "    evaluation_matches = matcher.match(\n",
    "        df_left=academy_df,\n",
    "        df_right=actors_df,\n",
    "        candidates=[train_candidates],\n",
    "        comparators=comparators,\n",
    "        weights=best_config[0] if best_config else [0.6, 0.2, 0.2],\n",
    "        threshold=0.5  # Lower threshold for evaluation\n",
    "    )\n",
    "    \n",
    "    print(f\"Matching found {len(evaluation_matches)} matches above threshold 0.5\")\n",
    "    \n",
    "    if len(evaluation_matches) > 0:\n",
    "        # Evaluate against training ground truth\n",
    "        evaluation_results = EntityMatchingEvaluator.evaluate(\n",
    "            corr=evaluation_matches,\n",
    "            test_pairs=train_corr\n",
    "        )\n",
    "        \n",
    "        print(f\"\\n=== Evaluation Results ===\")\n",
    "        print(f\"Precision: {evaluation_results['precision']:.3f}\")\n",
    "        print(f\"Recall:    {evaluation_results['recall']:.3f}\")\n",
    "        print(f\"F1 Score:  {evaluation_results['f1']:.3f}\")\n",
    "        print(f\"\\nCorrect matches: {evaluation_results['true_positives']}\")\n",
    "        print(f\"False positives: {evaluation_results['false_positives']}\")\n",
    "        print(f\"False negatives: {evaluation_results['false_negatives']}\")\n",
    "    else:\n",
    "        print(\"No matches found for evaluation. Try lowering the threshold.\")\n",
    "else:\n",
    "    print(\"No training correspondences available for evaluation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Threshold Analysis and Optimization\n",
    "\n",
    "Let's analyze how different thresholds affect our matching performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Record not found: academy_awards_000401 or actors_000149\n",
      "WARNING:root:Record not found: academy_awards_000345 or actors_000150\n",
      "WARNING:root:Record not found: academy_awards_001271 or actors_000153\n",
      "WARNING:root:Record not found: academy_awards_001540 or actors_000173\n",
      "WARNING:root:Record not found: academy_awards_001632 or actors_000159\n",
      "WARNING:root:Record not found: academy_awards_001879 or actors_000157\n",
      "WARNING:root:Record not found: academy_awards_002140 or actors_000155\n",
      "WARNING:root:Record not found: academy_awards_002186 or actors_000151\n",
      "WARNING:root:Record not found: academy_awards_002287 or actors_000158\n",
      "WARNING:root:Record not found: academy_awards_002333 or actors_000172\n",
      "WARNING:root:Record not found: academy_awards_002565 or actors_000149\n",
      "WARNING:root:Record not found: academy_awards_002619 or actors_000160\n",
      "WARNING:root:Record not found: academy_awards_002624 or actors_000152\n",
      "WARNING:root:Record not found: academy_awards_003422 or actors_000161\n",
      "WARNING:root:Record not found: academy_awards_003712 or actors_000154\n",
      "WARNING:root:Record not found: academy_awards_003812 or actors_000156\n",
      "WARNING:root:Record not found: academy_awards_004396 or actors_000170\n",
      "WARNING:root:Record not found: academy_awards_004398 or actors_000167\n",
      "WARNING:root:Record not found: academy_awards_004441 or actors_000168\n",
      "WARNING:root:Record not found: academy_awards_004443 or actors_000164\n",
      "WARNING:root:Record not found: academy_awards_004445 or actors_000171\n",
      "WARNING:root:Record not found: academy_awards_004474 or actors_000166\n",
      "WARNING:root:Record not found: academy_awards_004490 or actors_000163\n",
      "WARNING:root:Record not found: academy_awards_004499 or actors_000169\n",
      "WARNING:root:Record not found: academy_awards_004519 or actors_000165\n",
      "WARNING:root:Record not found: academy_awards_004528 or actors_000162\n",
      "WARNING:root:Record not found: academy_awards_000502 or actors_000150\n",
      "WARNING:root:Record not found: academy_awards_000401 or actors_000149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Threshold Sweep Analysis ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Record not found: academy_awards_000345 or actors_000150\n",
      "WARNING:root:Record not found: academy_awards_001271 or actors_000153\n",
      "WARNING:root:Record not found: academy_awards_001540 or actors_000173\n",
      "WARNING:root:Record not found: academy_awards_001632 or actors_000159\n",
      "WARNING:root:Record not found: academy_awards_001879 or actors_000157\n",
      "WARNING:root:Record not found: academy_awards_002140 or actors_000155\n",
      "WARNING:root:Record not found: academy_awards_002186 or actors_000151\n",
      "WARNING:root:Record not found: academy_awards_002287 or actors_000158\n",
      "WARNING:root:Record not found: academy_awards_002333 or actors_000172\n",
      "WARNING:root:Record not found: academy_awards_002565 or actors_000149\n",
      "WARNING:root:Record not found: academy_awards_002619 or actors_000160\n",
      "WARNING:root:Record not found: academy_awards_002624 or actors_000152\n",
      "WARNING:root:Record not found: academy_awards_003422 or actors_000161\n",
      "WARNING:root:Record not found: academy_awards_003712 or actors_000154\n",
      "WARNING:root:Record not found: academy_awards_003812 or actors_000156\n",
      "WARNING:root:Record not found: academy_awards_004396 or actors_000170\n",
      "WARNING:root:Record not found: academy_awards_004398 or actors_000167\n",
      "WARNING:root:Record not found: academy_awards_004441 or actors_000168\n",
      "WARNING:root:Record not found: academy_awards_004443 or actors_000164\n",
      "WARNING:root:Record not found: academy_awards_004445 or actors_000171\n",
      "WARNING:root:Record not found: academy_awards_004474 or actors_000166\n",
      "WARNING:root:Record not found: academy_awards_004490 or actors_000163\n",
      "WARNING:root:Record not found: academy_awards_004499 or actors_000169\n",
      "WARNING:root:Record not found: academy_awards_004519 or actors_000165\n",
      "WARNING:root:Record not found: academy_awards_004528 or actors_000162\n",
      "WARNING:root:Record not found: academy_awards_000502 or actors_000150\n",
      "WARNING:root:Record not found: academy_awards_000401 or actors_000149\n",
      "WARNING:root:Record not found: academy_awards_000345 or actors_000150\n",
      "WARNING:root:Record not found: academy_awards_001271 or actors_000153\n",
      "WARNING:root:Record not found: academy_awards_001540 or actors_000173\n",
      "WARNING:root:Record not found: academy_awards_001632 or actors_000159\n",
      "WARNING:root:Record not found: academy_awards_001879 or actors_000157\n",
      "WARNING:root:Record not found: academy_awards_002140 or actors_000155\n",
      "WARNING:root:Record not found: academy_awards_002186 or actors_000151\n",
      "WARNING:root:Record not found: academy_awards_002287 or actors_000158\n",
      "WARNING:root:Record not found: academy_awards_002333 or actors_000172\n",
      "WARNING:root:Record not found: academy_awards_002565 or actors_000149\n",
      "WARNING:root:Record not found: academy_awards_002619 or actors_000160\n",
      "WARNING:root:Record not found: academy_awards_002624 or actors_000152\n",
      "WARNING:root:Record not found: academy_awards_003422 or actors_000161\n",
      "WARNING:root:Record not found: academy_awards_003712 or actors_000154\n",
      "WARNING:root:Record not found: academy_awards_003812 or actors_000156\n",
      "WARNING:root:Record not found: academy_awards_004396 or actors_000170\n",
      "WARNING:root:Record not found: academy_awards_004398 or actors_000167\n",
      "WARNING:root:Record not found: academy_awards_004441 or actors_000168\n",
      "WARNING:root:Record not found: academy_awards_004443 or actors_000164\n",
      "WARNING:root:Record not found: academy_awards_004445 or actors_000171\n",
      "WARNING:root:Record not found: academy_awards_004474 or actors_000166\n",
      "WARNING:root:Record not found: academy_awards_004490 or actors_000163\n",
      "WARNING:root:Record not found: academy_awards_004499 or actors_000169\n",
      "WARNING:root:Record not found: academy_awards_004519 or actors_000165\n",
      "WARNING:root:Record not found: academy_awards_004528 or actors_000162\n",
      "WARNING:root:Record not found: academy_awards_000502 or actors_000150\n",
      "WARNING:root:Record not found: academy_awards_000401 or actors_000149\n",
      "WARNING:root:Record not found: academy_awards_000345 or actors_000150\n",
      "WARNING:root:Record not found: academy_awards_001271 or actors_000153\n",
      "WARNING:root:Record not found: academy_awards_001540 or actors_000173\n",
      "WARNING:root:Record not found: academy_awards_001632 or actors_000159\n",
      "WARNING:root:Record not found: academy_awards_001879 or actors_000157\n",
      "WARNING:root:Record not found: academy_awards_002140 or actors_000155\n",
      "WARNING:root:Record not found: academy_awards_002186 or actors_000151\n",
      "WARNING:root:Record not found: academy_awards_002287 or actors_000158\n",
      "WARNING:root:Record not found: academy_awards_002333 or actors_000172\n",
      "WARNING:root:Record not found: academy_awards_002565 or actors_000149\n",
      "WARNING:root:Record not found: academy_awards_002619 or actors_000160\n",
      "WARNING:root:Record not found: academy_awards_002624 or actors_000152\n",
      "WARNING:root:Record not found: academy_awards_003422 or actors_000161\n",
      "WARNING:root:Record not found: academy_awards_003712 or actors_000154\n",
      "WARNING:root:Record not found: academy_awards_003812 or actors_000156\n",
      "WARNING:root:Record not found: academy_awards_004396 or actors_000170\n",
      "WARNING:root:Record not found: academy_awards_004398 or actors_000167\n",
      "WARNING:root:Record not found: academy_awards_004441 or actors_000168\n",
      "WARNING:root:Record not found: academy_awards_004443 or actors_000164\n",
      "WARNING:root:Record not found: academy_awards_004445 or actors_000171\n",
      "WARNING:root:Record not found: academy_awards_004474 or actors_000166\n",
      "WARNING:root:Record not found: academy_awards_004490 or actors_000163\n",
      "WARNING:root:Record not found: academy_awards_004499 or actors_000169\n",
      "WARNING:root:Record not found: academy_awards_004519 or actors_000165\n",
      "WARNING:root:Record not found: academy_awards_004528 or actors_000162\n",
      "WARNING:root:Record not found: academy_awards_000502 or actors_000150\n",
      "WARNING:root:Record not found: academy_awards_000401 or actors_000149\n",
      "WARNING:root:Record not found: academy_awards_000345 or actors_000150\n",
      "WARNING:root:Record not found: academy_awards_001271 or actors_000153\n",
      "WARNING:root:Record not found: academy_awards_001540 or actors_000173\n",
      "WARNING:root:Record not found: academy_awards_001632 or actors_000159\n",
      "WARNING:root:Record not found: academy_awards_001879 or actors_000157\n",
      "WARNING:root:Record not found: academy_awards_002140 or actors_000155\n",
      "WARNING:root:Record not found: academy_awards_002186 or actors_000151\n",
      "WARNING:root:Record not found: academy_awards_002287 or actors_000158\n",
      "WARNING:root:Record not found: academy_awards_002333 or actors_000172\n",
      "WARNING:root:Record not found: academy_awards_002565 or actors_000149\n",
      "WARNING:root:Record not found: academy_awards_002619 or actors_000160\n",
      "WARNING:root:Record not found: academy_awards_002624 or actors_000152\n",
      "WARNING:root:Record not found: academy_awards_003422 or actors_000161\n",
      "WARNING:root:Record not found: academy_awards_003712 or actors_000154\n",
      "WARNING:root:Record not found: academy_awards_003812 or actors_000156\n",
      "WARNING:root:Record not found: academy_awards_004396 or actors_000170\n",
      "WARNING:root:Record not found: academy_awards_004398 or actors_000167\n",
      "WARNING:root:Record not found: academy_awards_004441 or actors_000168\n",
      "WARNING:root:Record not found: academy_awards_004443 or actors_000164\n",
      "WARNING:root:Record not found: academy_awards_004445 or actors_000171\n",
      "WARNING:root:Record not found: academy_awards_004474 or actors_000166\n",
      "WARNING:root:Record not found: academy_awards_004490 or actors_000163\n",
      "WARNING:root:Record not found: academy_awards_004499 or actors_000169\n",
      "WARNING:root:Record not found: academy_awards_004519 or actors_000165\n",
      "WARNING:root:Record not found: academy_awards_004528 or actors_000162\n",
      "WARNING:root:Record not found: academy_awards_000502 or actors_000150\n",
      "WARNING:root:Record not found: academy_awards_000401 or actors_000149\n",
      "WARNING:root:Record not found: academy_awards_000345 or actors_000150\n",
      "WARNING:root:Record not found: academy_awards_001271 or actors_000153\n",
      "WARNING:root:Record not found: academy_awards_001540 or actors_000173\n",
      "WARNING:root:Record not found: academy_awards_001632 or actors_000159\n",
      "WARNING:root:Record not found: academy_awards_001879 or actors_000157\n",
      "WARNING:root:Record not found: academy_awards_002140 or actors_000155\n",
      "WARNING:root:Record not found: academy_awards_002186 or actors_000151\n",
      "WARNING:root:Record not found: academy_awards_002287 or actors_000158\n",
      "WARNING:root:Record not found: academy_awards_002333 or actors_000172\n",
      "WARNING:root:Record not found: academy_awards_002565 or actors_000149\n",
      "WARNING:root:Record not found: academy_awards_002619 or actors_000160\n",
      "WARNING:root:Record not found: academy_awards_002624 or actors_000152\n",
      "WARNING:root:Record not found: academy_awards_003422 or actors_000161\n",
      "WARNING:root:Record not found: academy_awards_003712 or actors_000154\n",
      "WARNING:root:Record not found: academy_awards_003812 or actors_000156\n",
      "WARNING:root:Record not found: academy_awards_004396 or actors_000170\n",
      "WARNING:root:Record not found: academy_awards_004398 or actors_000167\n",
      "WARNING:root:Record not found: academy_awards_004441 or actors_000168\n",
      "WARNING:root:Record not found: academy_awards_004443 or actors_000164\n",
      "WARNING:root:Record not found: academy_awards_004445 or actors_000171\n",
      "WARNING:root:Record not found: academy_awards_004474 or actors_000166\n",
      "WARNING:root:Record not found: academy_awards_004490 or actors_000163\n",
      "WARNING:root:Record not found: academy_awards_004499 or actors_000169\n",
      "WARNING:root:Record not found: academy_awards_004519 or actors_000165\n",
      "WARNING:root:Record not found: academy_awards_004528 or actors_000162\n",
      "WARNING:root:Record not found: academy_awards_000502 or actors_000150\n",
      "WARNING:root:Record not found: academy_awards_000401 or actors_000149\n",
      "WARNING:root:Record not found: academy_awards_000345 or actors_000150\n",
      "WARNING:root:Record not found: academy_awards_001271 or actors_000153\n",
      "WARNING:root:Record not found: academy_awards_001540 or actors_000173\n",
      "WARNING:root:Record not found: academy_awards_001632 or actors_000159\n",
      "WARNING:root:Record not found: academy_awards_001879 or actors_000157\n",
      "WARNING:root:Record not found: academy_awards_002140 or actors_000155\n",
      "WARNING:root:Record not found: academy_awards_002186 or actors_000151\n",
      "WARNING:root:Record not found: academy_awards_002287 or actors_000158\n",
      "WARNING:root:Record not found: academy_awards_002333 or actors_000172\n",
      "WARNING:root:Record not found: academy_awards_002565 or actors_000149\n",
      "WARNING:root:Record not found: academy_awards_002619 or actors_000160\n",
      "WARNING:root:Record not found: academy_awards_002624 or actors_000152\n",
      "WARNING:root:Record not found: academy_awards_003422 or actors_000161\n",
      "WARNING:root:Record not found: academy_awards_003712 or actors_000154\n",
      "WARNING:root:Record not found: academy_awards_003812 or actors_000156\n",
      "WARNING:root:Record not found: academy_awards_004396 or actors_000170\n",
      "WARNING:root:Record not found: academy_awards_004398 or actors_000167\n",
      "WARNING:root:Record not found: academy_awards_004441 or actors_000168\n",
      "WARNING:root:Record not found: academy_awards_004443 or actors_000164\n",
      "WARNING:root:Record not found: academy_awards_004445 or actors_000171\n",
      "WARNING:root:Record not found: academy_awards_004474 or actors_000166\n",
      "WARNING:root:Record not found: academy_awards_004490 or actors_000163\n",
      "WARNING:root:Record not found: academy_awards_004499 or actors_000169\n",
      "WARNING:root:Record not found: academy_awards_004519 or actors_000165\n",
      "WARNING:root:Record not found: academy_awards_004528 or actors_000162\n",
      "WARNING:root:Record not found: academy_awards_000502 or actors_000150\n",
      "WARNING:root:Record not found: academy_awards_000401 or actors_000149\n",
      "WARNING:root:Record not found: academy_awards_000345 or actors_000150\n",
      "WARNING:root:Record not found: academy_awards_001271 or actors_000153\n",
      "WARNING:root:Record not found: academy_awards_001540 or actors_000173\n",
      "WARNING:root:Record not found: academy_awards_001632 or actors_000159\n",
      "WARNING:root:Record not found: academy_awards_001879 or actors_000157\n",
      "WARNING:root:Record not found: academy_awards_002140 or actors_000155\n",
      "WARNING:root:Record not found: academy_awards_002186 or actors_000151\n",
      "WARNING:root:Record not found: academy_awards_002287 or actors_000158\n",
      "WARNING:root:Record not found: academy_awards_002333 or actors_000172\n",
      "WARNING:root:Record not found: academy_awards_002565 or actors_000149\n",
      "WARNING:root:Record not found: academy_awards_002619 or actors_000160\n",
      "WARNING:root:Record not found: academy_awards_002624 or actors_000152\n",
      "WARNING:root:Record not found: academy_awards_003422 or actors_000161\n",
      "WARNING:root:Record not found: academy_awards_003712 or actors_000154\n",
      "WARNING:root:Record not found: academy_awards_003812 or actors_000156\n",
      "WARNING:root:Record not found: academy_awards_004396 or actors_000170\n",
      "WARNING:root:Record not found: academy_awards_004398 or actors_000167\n",
      "WARNING:root:Record not found: academy_awards_004441 or actors_000168\n",
      "WARNING:root:Record not found: academy_awards_004443 or actors_000164\n",
      "WARNING:root:Record not found: academy_awards_004445 or actors_000171\n",
      "WARNING:root:Record not found: academy_awards_004474 or actors_000166\n",
      "WARNING:root:Record not found: academy_awards_004490 or actors_000163\n",
      "WARNING:root:Record not found: academy_awards_004499 or actors_000169\n",
      "WARNING:root:Record not found: academy_awards_004519 or actors_000165\n",
      "WARNING:root:Record not found: academy_awards_004528 or actors_000162\n",
      "WARNING:root:Record not found: academy_awards_000502 or actors_000150\n",
      "WARNING:root:Record not found: academy_awards_000401 or actors_000149\n",
      "WARNING:root:Record not found: academy_awards_000345 or actors_000150\n",
      "WARNING:root:Record not found: academy_awards_001271 or actors_000153\n",
      "WARNING:root:Record not found: academy_awards_001540 or actors_000173\n",
      "WARNING:root:Record not found: academy_awards_001632 or actors_000159\n",
      "WARNING:root:Record not found: academy_awards_001879 or actors_000157\n",
      "WARNING:root:Record not found: academy_awards_002140 or actors_000155\n",
      "WARNING:root:Record not found: academy_awards_002186 or actors_000151\n",
      "WARNING:root:Record not found: academy_awards_002287 or actors_000158\n",
      "WARNING:root:Record not found: academy_awards_002333 or actors_000172\n",
      "WARNING:root:Record not found: academy_awards_002565 or actors_000149\n",
      "WARNING:root:Record not found: academy_awards_002619 or actors_000160\n",
      "WARNING:root:Record not found: academy_awards_002624 or actors_000152\n",
      "WARNING:root:Record not found: academy_awards_003422 or actors_000161\n",
      "WARNING:root:Record not found: academy_awards_003712 or actors_000154\n",
      "WARNING:root:Record not found: academy_awards_003812 or actors_000156\n",
      "WARNING:root:Record not found: academy_awards_004396 or actors_000170\n",
      "WARNING:root:Record not found: academy_awards_004398 or actors_000167\n",
      "WARNING:root:Record not found: academy_awards_004441 or actors_000168\n",
      "WARNING:root:Record not found: academy_awards_004443 or actors_000164\n",
      "WARNING:root:Record not found: academy_awards_004445 or actors_000171\n",
      "WARNING:root:Record not found: academy_awards_004474 or actors_000166\n",
      "WARNING:root:Record not found: academy_awards_004490 or actors_000163\n",
      "WARNING:root:Record not found: academy_awards_004499 or actors_000169\n",
      "WARNING:root:Record not found: academy_awards_004519 or actors_000165\n",
      "WARNING:root:Record not found: academy_awards_004528 or actors_000162\n",
      "WARNING:root:Record not found: academy_awards_000502 or actors_000150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Threshold Analysis Results:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>matches</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>319</td>\n",
       "      <td>0.313480</td>\n",
       "      <td>0.970874</td>\n",
       "      <td>0.473934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2</td>\n",
       "      <td>316</td>\n",
       "      <td>0.316456</td>\n",
       "      <td>0.970874</td>\n",
       "      <td>0.477327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.3</td>\n",
       "      <td>236</td>\n",
       "      <td>0.372881</td>\n",
       "      <td>0.854369</td>\n",
       "      <td>0.519174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.4</td>\n",
       "      <td>115</td>\n",
       "      <td>0.582609</td>\n",
       "      <td>0.650485</td>\n",
       "      <td>0.614679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5</td>\n",
       "      <td>40</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.291262</td>\n",
       "      <td>0.419580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.019417</td>\n",
       "      <td>0.036697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   threshold  matches  precision    recall        f1\n",
       "0        0.1      319   0.313480  0.970874  0.473934\n",
       "1        0.2      316   0.316456  0.970874  0.477327\n",
       "2        0.3      236   0.372881  0.854369  0.519174\n",
       "3        0.4      115   0.582609  0.650485  0.614679\n",
       "4        0.5       40   0.750000  0.291262  0.419580\n",
       "5        0.6        6   0.333333  0.019417  0.036697\n",
       "6        0.7        0   0.000000  0.000000  0.000000\n",
       "7        0.8        0   0.000000  0.000000  0.000000\n",
       "8        0.9        0   0.000000  0.000000  0.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Optimal Threshold ===\n",
      "Threshold: 0.4\n",
      "F1 Score:  0.615\n",
      "Precision: 0.583\n",
      "Recall:    0.650\n",
      "Matches:   115.0\n"
     ]
    }
   ],
   "source": [
    "# Perform threshold sweep analysis\n",
    "if len(train_corr) > 0:\n",
    "    print(\"=== Threshold Sweep Analysis ===\")\n",
    "    \n",
    "    thresholds = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "    results = []\n",
    "    \n",
    "    for threshold in thresholds:\n",
    "        # Perform matching\n",
    "        matches = matcher.match(\n",
    "            df_left=academy_df,\n",
    "            df_right=actors_df,\n",
    "            candidates=[train_candidates],\n",
    "            comparators=comparators,\n",
    "            weights=best_config[0] if best_config else [0.6, 0.2, 0.2],\n",
    "            threshold=threshold\n",
    "        )\n",
    "        \n",
    "        if len(matches) > 0:\n",
    "            # Evaluate\n",
    "            eval_result = EntityMatchingEvaluator.evaluate(matches, train_corr)\n",
    "            results.append({\n",
    "                'threshold': threshold,\n",
    "                'matches': len(matches),\n",
    "                'precision': eval_result['precision'],\n",
    "                'recall': eval_result['recall'],\n",
    "                'f1': eval_result['f1']\n",
    "            })\n",
    "        else:\n",
    "            results.append({\n",
    "                'threshold': threshold,\n",
    "                'matches': 0,\n",
    "                'precision': 0.0,\n",
    "                'recall': 0.0,\n",
    "                'f1': 0.0\n",
    "            })\n",
    "    \n",
    "    # Convert to DataFrame for analysis\n",
    "    threshold_results = pd.DataFrame(results)\n",
    "    \n",
    "    print(\"\\nThreshold Analysis Results:\")\n",
    "    display(threshold_results)\n",
    "    \n",
    "    # Find optimal threshold (best F1 score)\n",
    "    if len(threshold_results) > 0:\n",
    "        best_threshold_idx = threshold_results['f1'].idxmax()\n",
    "        best_threshold_row = threshold_results.loc[best_threshold_idx]\n",
    "        \n",
    "        print(f\"\\n=== Optimal Threshold ===\")\n",
    "        print(f\"Threshold: {best_threshold_row['threshold']}\")\n",
    "        print(f\"F1 Score:  {best_threshold_row['f1']:.3f}\")\n",
    "        print(f\"Precision: {best_threshold_row['precision']:.3f}\")\n",
    "        print(f\"Recall:    {best_threshold_row['recall']:.3f}\")\n",
    "        print(f\"Matches:   {best_threshold_row['matches']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Advanced Comparator Examples\n",
    "\n",
    "Let's explore different types of comparators and their specific use cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Advanced Comparator Configuration ===\n",
      "Dictionary format comparators: 1 matches\n",
      "Custom function comparators: 1 matches\n",
      "\n",
      "Top custom matches:\n",
      "  0.880: '7th Heaven' (1927-01-01) <-> '7th Heaven' (1929-01-01)\n"
     ]
    }
   ],
   "source": [
    "# Dictionary format comparators with embedded weights\n",
    "print(\"=== Advanced Comparator Configuration ===\")\n",
    "\n",
    "# Method 1: Dictionary format with embedded weights\n",
    "dict_comparators = [\n",
    "    {\"comparator\": StringComparator(\"title\", \"jaro_winkler\", str.lower), \"weight\": 0.5},\n",
    "    {\"comparator\": DateComparator(\"date\", max_days_difference=730), \"weight\": 0.3},\n",
    "    {\"comparator\": StringComparator(\"actor_name\", \"cosine\", str.lower), \"weight\": 0.2}\n",
    "]\n",
    "\n",
    "dict_matches = matcher.match(\n",
    "    df_left=academy_df,\n",
    "    df_right=actors_df,\n",
    "    candidates=[title_candidates[:100]],\n",
    "    comparators=dict_comparators,\n",
    "    # No weights parameter needed - they're embedded in comparators\n",
    "    threshold=0.6\n",
    ")\n",
    "\n",
    "print(f\"Dictionary format comparators: {len(dict_matches)} matches\")\n",
    "\n",
    "# Method 2: Custom comparator functions\n",
    "def custom_title_comparator(record1, record2):\n",
    "    \"\"\"Custom comparator that handles missing values and applies fuzzy matching.\"\"\"\n",
    "    title1 = record1.get('title', '')\n",
    "    title2 = record2.get('title', '')\n",
    "    \n",
    "    # Handle empty titles\n",
    "    if not title1 or not title2:\n",
    "        return 0.0\n",
    "    \n",
    "    # Simple word overlap approach\n",
    "    words1 = set(str(title1).lower().split())\n",
    "    words2 = set(str(title2).lower().split())\n",
    "    \n",
    "    if not words1 or not words2:\n",
    "        return 0.0\n",
    "    \n",
    "    # Jaccard similarity\n",
    "    intersection = len(words1 & words2)\n",
    "    union = len(words1 | words2)\n",
    "    \n",
    "    return intersection / union if union > 0 else 0.0\n",
    "\n",
    "def custom_year_comparator(record1, record2):\n",
    "    \"\"\"Custom year-based comparator with flexible tolerance.\"\"\"\n",
    "    try:\n",
    "        date1 = pd.to_datetime(record1.get('date', ''))\n",
    "        date2 = pd.to_datetime(record2.get('date', ''))\n",
    "        \n",
    "        year_diff = abs(date1.year - date2.year)\n",
    "        \n",
    "        # Exact year match = 1.0, 1 year diff = 0.8, 2 years = 0.6, etc.\n",
    "        if year_diff == 0:\n",
    "            return 1.0\n",
    "        elif year_diff == 1:\n",
    "            return 0.8\n",
    "        elif year_diff == 2:\n",
    "            return 0.6\n",
    "        elif year_diff <= 5:\n",
    "            return 0.4\n",
    "        else:\n",
    "            return 0.0\n",
    "            \n",
    "    except:\n",
    "        return 0.0\n",
    "\n",
    "# Use custom comparators\n",
    "custom_matches = matcher.match(\n",
    "    df_left=academy_df,\n",
    "    df_right=actors_df,\n",
    "    candidates=[title_candidates[:100]],\n",
    "    comparators=[custom_title_comparator, custom_year_comparator],\n",
    "    weights=[0.7, 0.3],\n",
    "    threshold=0.5\n",
    ")\n",
    "\n",
    "print(f\"Custom function comparators: {len(custom_matches)} matches\")\n",
    "\n",
    "# Show some examples of custom comparator results\n",
    "if len(custom_matches) > 0:\n",
    "    print(f\"\\nTop custom matches:\")\n",
    "    for _, match in custom_matches.sort_values('score', ascending=False).head(3).iterrows():\n",
    "        id1, id2, score = match['id1'], match['id2'], match['score']\n",
    "        rec1 = academy_df[academy_df['_id'] == id1].iloc[0]\n",
    "        rec2 = actors_df[actors_df['_id'] == id2].iloc[0]\n",
    "        print(f\"  {score:.3f}: '{rec1.get('title')}' ({rec1.get('date')}) <-> '{rec2.get('title')}' ({rec2.get('date')})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Complete End-to-End Workflow\n",
    "\n",
    "Let's put everything together in a complete entity matching pipeline with output generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Complete Entity Matching Pipeline ===\n",
      "Left dataset: academy_awards (4592 records)\n",
      "Right dataset: actors (149 records)\n",
      "\n",
      "1. Generating candidates...\n",
      "   Generated 300 candidate pairs\n",
      "\n",
      "2. Setting up comparators...\n",
      "   Using 3 comparators with weights [0.6, 0.25, 0.15]\n",
      "\n",
      "3. Performing entity matching...\n",
      "   Found 2 matches above threshold 0.5\n",
      "\n",
      "4. Evaluating results...\n",
      "   Precision: 0.000\n",
      "   Recall:    0.000\n",
      "   F1 Score:  0.000\n",
      "\n",
      "5. Saving outputs to c:\\Users\\Ralph\\dev\\pydi\\output\\examples\\entitymatching...\n",
      "   Saved matches: c:\\Users\\Ralph\\dev\\pydi\\output\\examples\\entitymatching\\entity_matches.csv\n",
      "   Saved detailed matches: c:\\Users\\Ralph\\dev\\pydi\\output\\examples\\entitymatching\\detailed_matches.csv\n",
      "   Saved evaluation: c:\\Users\\Ralph\\dev\\pydi\\output\\examples\\entitymatching\\evaluation_results.json\n",
      "\n",
      "=== Pipeline Complete ===\n",
      "Check c:\\Users\\Ralph\\dev\\pydi\\output\\examples\\entitymatching for outputs\n"
     ]
    }
   ],
   "source": [
    "def complete_entity_matching_pipeline(df_left, df_right, ground_truth=None, output_dir=None):\n",
    "    \"\"\"Complete entity matching pipeline with evaluation and outputs.\"\"\"\n",
    "    \n",
    "    print(\"=== Complete Entity Matching Pipeline ===\")\n",
    "    print(f\"Left dataset: {df_left.attrs.get('dataset_name', 'unknown')} ({len(df_left)} records)\")\n",
    "    print(f\"Right dataset: {df_right.attrs.get('dataset_name', 'unknown')} ({len(df_right)} records)\")\n",
    "    \n",
    "    # Step 1: Candidate Generation\n",
    "    print(\"\\n1. Generating candidates...\")\n",
    "    candidates = create_sample_candidates(df_left, df_right, max_pairs=300, strategy=\"title_similarity\")\n",
    "    print(f\"   Generated {len(candidates)} candidate pairs\")\n",
    "    \n",
    "    # Step 2: Configure Comparators\n",
    "    print(\"\\n2. Setting up comparators...\")\n",
    "    comparators = [\n",
    "        StringComparator(\"title\", \"jaro_winkler\", str.lower),\n",
    "        DateComparator(\"date\", max_days_difference=365),\n",
    "        StringComparator(\"actor_name\", \"jaro_winkler\", str.lower)\n",
    "    ]\n",
    "    weights = [0.6, 0.25, 0.15]  # Title most important, then date, then actor\n",
    "    print(f\"   Using {len(comparators)} comparators with weights {weights}\")\n",
    "    \n",
    "    # Step 3: Matching\n",
    "    print(\"\\n3. Performing entity matching...\")\n",
    "    matcher = RuleBasedMatcher()\n",
    "    matches = matcher.match(\n",
    "        df_left=df_left,\n",
    "        df_right=df_right,\n",
    "        candidates=[candidates],\n",
    "        comparators=comparators,\n",
    "        weights=weights,\n",
    "        threshold=0.5\n",
    "    )\n",
    "    \n",
    "    print(f\"   Found {len(matches)} matches above threshold 0.5\")\n",
    "    \n",
    "    # Step 4: Evaluation (if ground truth available)\n",
    "    evaluation_results = None\n",
    "    if ground_truth is not None and len(ground_truth) > 0 and len(matches) > 0:\n",
    "        print(\"\\n4. Evaluating results...\")\n",
    "        evaluation_results = EntityMatchingEvaluator.evaluate(matches, ground_truth)\n",
    "        \n",
    "        print(f\"   Precision: {evaluation_results['precision']:.3f}\")\n",
    "        print(f\"   Recall:    {evaluation_results['recall']:.3f}\")\n",
    "        print(f\"   F1 Score:  {evaluation_results['f1']:.3f}\")\n",
    "    \n",
    "    # Step 5: Output Generation\n",
    "    if output_dir:\n",
    "        print(f\"\\n5. Saving outputs to {output_dir}...\")\n",
    "        output_path = Path(output_dir)\n",
    "        output_path.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Save matches\n",
    "        matches_file = output_path / \"entity_matches.csv\"\n",
    "        matches.to_csv(matches_file, index=False)\n",
    "        print(f\"   Saved matches: {matches_file}\")\n",
    "        \n",
    "        # Save detailed match information\n",
    "        if len(matches) > 0:\n",
    "            detailed_matches = []\n",
    "            for _, match in matches.iterrows():\n",
    "                id1, id2, score = match['id1'], match['id2'], match['score']\n",
    "                rec1 = df_left[df_left['_id'] == id1].iloc[0]\n",
    "                rec2 = df_right[df_right['_id'] == id2].iloc[0]\n",
    "                \n",
    "                detailed_matches.append({\n",
    "                    'id1': id1,\n",
    "                    'id2': id2,\n",
    "                    'score': score,\n",
    "                    'title1': rec1.get('title', ''),\n",
    "                    'title2': rec2.get('title', ''),\n",
    "                    'date1': rec1.get('date', ''),\n",
    "                    'date2': rec2.get('date', ''),\n",
    "                    'actor1': rec1.get('actor_name', ''),\n",
    "                    'actor2': rec2.get('actor_name', '')\n",
    "                })\n",
    "            \n",
    "            detailed_df = pd.DataFrame(detailed_matches)\n",
    "            detailed_file = output_path / \"detailed_matches.csv\"\n",
    "            detailed_df.to_csv(detailed_file, index=False)\n",
    "            print(f\"   Saved detailed matches: {detailed_file}\")\n",
    "        \n",
    "        # Save evaluation results\n",
    "        if evaluation_results:\n",
    "            eval_file = output_path / \"evaluation_results.json\"\n",
    "            import json\n",
    "            with open(eval_file, 'w') as f:\n",
    "                json.dump(evaluation_results, f, indent=2)\n",
    "            print(f\"   Saved evaluation: {eval_file}\")\n",
    "    \n",
    "    return {\n",
    "        'matches': matches,\n",
    "        'candidates': candidates,\n",
    "        'evaluation': evaluation_results,\n",
    "        'comparators': comparators,\n",
    "        'weights': weights\n",
    "    }\n",
    "\n",
    "# Run complete pipeline\n",
    "output_dir = root / \"output\" / \"examples\" / \"entitymatching\"\n",
    "\n",
    "pipeline_results = complete_entity_matching_pipeline(\n",
    "    df_left=academy_df,\n",
    "    df_right=actors_df,\n",
    "    ground_truth=train_corr if len(train_corr) > 0 else None,\n",
    "    output_dir=str(output_dir)\n",
    ")\n",
    "\n",
    "print(f\"\\n=== Pipeline Complete ===\")\n",
    "print(f\"Check {output_dir} for outputs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Key Takeaways\n",
    "\n",
    "This notebook demonstrated the complete entity matching workflow in PyDI using the RuleBasedMatcher:\n",
    "\n",
    "### Key Features Demonstrated:\n",
    "\n",
    "1. **Data Loading**: Provenance-aware loading of XML datasets with automatic ID generation\n",
    "2. **Candidate Generation**: Simple blocking strategies to reduce comparison space\n",
    "3. **RuleBasedMatcher**: Weighted combination of multiple attribute comparators\n",
    "4. **Multiple Comparator Types**:\n",
    "   - StringComparator with different similarity functions (Jaro-Winkler, Levenshtein, etc.)\n",
    "   - DateComparator with configurable tolerance\n",
    "   - NumericComparator for numerical attributes\n",
    "5. **Flexible Configuration**: Multiple ways to specify comparators and weights\n",
    "6. **Evaluation**: Precision, recall, and F1 score calculation against ground truth\n",
    "7. **Threshold Analysis**: Finding optimal similarity thresholds\n",
    "8. **Output Generation**: Structured results saved to CSV and JSON files\n",
    "\n",
    "### Best Practices:\n",
    "\n",
    "- **Use domain knowledge** to weight attributes appropriately (titles usually most important for movies)\n",
    "- **Tune thresholds** based on precision/recall trade-offs for your use case\n",
    "- **Combine multiple attributes** for more robust matching than single-attribute approaches\n",
    "- **Evaluate systematically** using held-out ground truth data\n",
    "- **Generate good candidates** - blocking is crucial for scalability in real applications\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "- Implement more sophisticated blocking algorithms (sorted neighborhood, LSH, etc.)\n",
    "- Try machine learning-based approaches with the MLBasedMatcher\n",
    "- Experiment with ensemble methods combining multiple matchers\n",
    "- Apply to your own datasets with domain-specific comparators"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pydi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
