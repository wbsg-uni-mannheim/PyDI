{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# PyDI Data Loading Example\n",
        "\n",
        "This notebook mirrors `PyDI/examples/data_loading_example.py` and demonstrates provenance-aware data loading.\n",
        "\n",
        "It shows how to load:\n",
        "- CSV (with provenance)\n",
        "- XML (flattened)\n",
        "- JSON (flattened)\n",
        "\n",
        "Run cells below in order. Adjust paths if needed.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 0: Imports and setup\n",
        "import logging\n",
        "from pathlib import Path\n",
        "\n",
        "from PyDI.io import load_csv, load_xml, load_json\n",
        "\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "root = Path.cwd().parents[1]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: CSV loading with provenance\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:PyDI.io.loaders:Loaded dataset 'movies' via read_csv: shape=(656, 23), source=/Users/aaronsteiner/Documents/GitHub/PyDI/input/schemamatching/data/movie_list.csv\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 656 rows from movie_list.csv\n",
            "Dataset name: movies\n",
            "Columns: ['movies_id', 'id', 'year', 'exclude', 'Film', 'Lead Studio', 'Rotten Tomatoes', 'Audience Score'] ...\n"
          ]
        }
      ],
      "source": [
        "csv_path = root / \"input/schemamatching/data/movie_list.csv\"\n",
        "if csv_path.exists():\n",
        "    df_csv = load_csv(csv_path, name=\"movies\")\n",
        "    print(f\"Loaded {len(df_csv)} rows from {csv_path.name}\")\n",
        "    prov = df_csv.attrs.get('provenance', {})\n",
        "    print(f\"Dataset name: {prov.get('dataset_name', 'N/A')}\")\n",
        "    print(f\"Columns: {list(df_csv.columns)[:8]} ...\")\n",
        "    df_csv.head(3)\n",
        "else:\n",
        "    print(f\"CSV file not found: {csv_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: XML loading and flattening\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:PyDI.io.loaders:Loaded dataset 'academy_awards' via read_xml_flattened: shape=(4592, 7), source=/Users/aaronsteiner/Documents/GitHub/PyDI/input/entitymatching/data/academy_awards.xml\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 4592 rows from academy_awards.xml\n",
            "Columns: ['academy_awards_id', 'id', 'title', 'actor_name', 'date', 'director_name', 'oscar'] ...\n"
          ]
        }
      ],
      "source": [
        "xml_path = root / \"input/entitymatching/data/academy_awards.xml\"\n",
        "if xml_path.exists():\n",
        "    df_xml = load_xml(xml_path, name=\"academy_awards\")\n",
        "    print(f\"Loaded {len(df_xml)} rows from {xml_path.name}\")\n",
        "    print(f\"Columns: {list(df_xml.columns)[:10]} ...\")\n",
        "    df_xml.head(6)\n",
        "else:\n",
        "    print(f\"XML file not found: {xml_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: JSON loading and flattening\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:PyDI.io.loaders:Loaded dataset 'hockey_stats' via read_json: shape=(25, 3), source=/Users/aaronsteiner/Documents/GitHub/PyDI/winter/winter-framework/src/test/resource/testTable.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 25 rows from testTable.json\n",
            "Columns: ['hockey_stats_id', 'table', 'mapping'] ...\n"
          ]
        }
      ],
      "source": [
        "json_path = root / \"winter/winter-framework/src/test/resource/testTable.json\"\n",
        "if json_path.exists():\n",
        "    try:\n",
        "        df_json = load_json(json_path, name=\"hockey_stats\")\n",
        "        print(f\"Loaded {len(df_json)} rows from {json_path.name}\")\n",
        "        print(f\"Columns: {list(df_json.columns)[:8]} ...\")\n",
        "        df_json.head(3)\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to load JSON file: {e}\")\n",
        "else:\n",
        "    print(f\"JSON file not found: {json_path}\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
