"""
Blocking evaluation utilities.

This module provides an evaluator to assess blocking strategies independent of
matching. It mirrors the style of EntityMatchingEvaluator by returning metrics
as dictionaries and optionally writing artifacts to disk.

Key metrics:
- candidate_recall: fraction of gold positive pairs covered by candidates
- pair_reduction: 1 - (candidate_pairs / total_possible_pairs)
- unique_pairs: number of unique candidate pairs (deduplicated)
- duplicates: number of duplicate pairs found in candidates
- coverage_left/right: number of unique left/right ids covered by candidates
- block_key_stats (if block_key present): per-key pair counts and densities
"""

from __future__ import annotations

from typing import Dict, Iterable, List, Optional, Tuple, Union
import logging
import os

import pandas as pd


CandidateInput = Union[pd.DataFrame, Iterable[pd.DataFrame]]


class BlockingEvaluator:
    """Static methods for evaluating blocking results.

    The evaluator accepts candidate pairs generated by blockers and compares
    them to a gold standard set of positive pairs to compute candidate recall
    and pair reduction. It also generates block-level statistics when the
    candidate pairs include a ``block_key`` column.
    """

    @staticmethod
    def evaluate(
        candidates: CandidateInput,
        *,
        gold_pairs: Optional[pd.DataFrame] = None,
        gold_id1_col: str = "id1",
        gold_id2_col: str = "id2",
        gold_label_col: Optional[str] = None,
        left_id_map: Optional[pd.Series] = None,
        right_id_map: Optional[pd.Series] = None,
        total_possible_pairs: Optional[int] = None,
        out_dir: Optional[str] = None,
        sample_size: int = 1000,
    ) -> Dict[str, Union[int, float, str, List[str]]]:
        """Evaluate blocking candidates against an optional gold standard.

        Parameters
        ----------
        candidates : DataFrame or Iterable[DataFrame]
            Candidate pairs with columns ``id1``, ``id2`` and optional
            ``block_key``. Can be a single DataFrame or an iterable of batches.
        gold_pairs : DataFrame, optional
            Gold standard pairs. Must have ``gold_id1_col`` and
            ``gold_id2_col`` columns. If ``gold_label_col`` is provided, only
            rows with truthy/1/"TRUE" are considered positive.
        gold_id1_col, gold_id2_col : str
            Column names in ``gold_pairs`` for the two ids.
        gold_label_col : str, optional
            Label column name in ``gold_pairs`` (boolean/int/string). If not
            provided, all rows are considered positive.
        left_id_map, right_id_map : pandas.Series, optional
            Optional mappings to convert internal candidate ids (e.g., ``_id``)
            to the id scheme used in the gold standard. Each series should be
            indexed by internal id and contain the gold id string as values.
        total_possible_pairs : int, optional
            Total size of the Cartesian product |L|*|R| for pair reduction.
        out_dir : str, optional
            If provided, writes summary JSON/CSV artifacts into this directory.
        sample_size : int
            Number of candidate pairs to sample for the preview CSV.

        Returns
        -------
        dict
            Summary metrics including counts, candidate_recall (if gold
            provided), and pair_reduction (if ``total_possible_pairs`` provided).
        """
        cand_df = BlockingEvaluator._materialize_candidates(candidates)

        if cand_df.empty:
            logging.warning("No candidate pairs provided to BlockingEvaluator")

        # Basic candidate stats
        # Use sorted tuple to normalize order for uniqueness
        unique_pairs_set = set((str(a), str(b)) for a, b in cand_df[[
                               "id1", "id2"]].itertuples(index=False))
        unique_pairs = len(unique_pairs_set)
        duplicates = max(len(cand_df) - unique_pairs, 0)

        # Coverage of entities
        covered_left = cand_df["id1"].nunique() if not cand_df.empty else 0
        covered_right = cand_df["id2"].nunique() if not cand_df.empty else 0

        results: Dict[str, Union[int, float, str, List[str]]] = {
            "total_candidates": int(len(cand_df)),
            "unique_candidates": int(unique_pairs),
            "duplicate_pairs": int(duplicates),
            "covered_left_entities": int(covered_left),
            "covered_right_entities": int(covered_right),
        }

        # Pair reduction
        if total_possible_pairs is not None and total_possible_pairs > 0:
            pair_reduction = 1.0 - (unique_pairs / total_possible_pairs)
            results["pair_reduction"] = float(pair_reduction)
            results["total_possible_pairs"] = int(total_possible_pairs)

        # Candidate recall vs. gold
        if gold_pairs is not None and not gold_pairs.empty:
            gold_pos = BlockingEvaluator._select_positive_gold(
                gold_pairs, gold_id1_col, gold_id2_col, gold_label_col
            )

            # Map candidate ids to gold id scheme if mappings provided
            if left_id_map is not None and right_id_map is not None:
                mapped = cand_df[["id1", "id2"]].copy()
                mapped["id1"] = mapped["id1"].map(left_id_map).astype(str)
                mapped["id2"] = mapped["id2"].map(right_id_map).astype(str)
                cand_pairs_set = set(
                    (a, b) for a, b in mapped.itertuples(index=False, name=None))
            else:
                # Assume candidate id scheme matches gold
                cand_pairs_set = set((str(a), str(b)) for a, b in cand_df[[
                                     "id1", "id2"]].itertuples(index=False))

            gold_set = set((str(a), str(b)) for a, b in gold_pos[[
                           gold_id1_col, gold_id2_col]].itertuples(index=False))

            candidate_recall = len(
                cand_pairs_set & gold_set) / max(len(gold_set), 1)
            results["candidate_recall"] = float(candidate_recall)
            results["gold_positive_pairs"] = int(len(gold_set))

        # Block-level stats if available
        if "block_key" in cand_df.columns:
            block_stats = BlockingEvaluator._create_block_key_stats(cand_df)
            results["num_blocks"] = int(len(block_stats))
        else:
            block_stats = None

        # Write artifacts
        if out_dir is not None:
            os.makedirs(out_dir, exist_ok=True)
            BlockingEvaluator._write_artifacts(
                results=results,
                candidates=cand_df,
                block_stats=block_stats,
                out_dir=out_dir,
                sample_size=sample_size,
            )

        logging.info(
            "Blocking evaluation: candidates=%d unique=%d duplicates=%d",
            len(cand_df), unique_pairs, duplicates,
        )
        return results

    @staticmethod
    def _materialize_candidates(candidates: CandidateInput) -> pd.DataFrame:
        if isinstance(candidates, pd.DataFrame):
            return candidates.copy()
        frames: List[pd.DataFrame] = []
        for batch in candidates:  # type: ignore[union-attr]
            if batch is None:
                continue
            if not isinstance(batch, pd.DataFrame):
                continue
            if batch.empty:
                continue
            frames.append(batch)
        if frames:
            df = pd.concat(frames, ignore_index=True)
        else:
            df = pd.DataFrame(columns=["id1", "id2"]).copy()
        # Keep only expected columns if present
        cols = [c for c in ["id1", "id2", "block_key"] if c in df.columns]
        return df[cols] if cols else df

    @staticmethod
    def _select_positive_gold(
        gold_pairs: pd.DataFrame,
        id1_col: str,
        id2_col: str,
        label_col: Optional[str],
    ) -> pd.DataFrame:
        req = [id1_col, id2_col]
        for c in req:
            if c not in gold_pairs.columns:
                raise ValueError(f"Gold pairs missing required column: {c}")
        if label_col is None:
            return gold_pairs[[id1_col, id2_col]].copy()
        if label_col not in gold_pairs.columns:
            raise ValueError(f"Gold pairs missing label column: {label_col}")
        # Interpret truthy labels: 1/True/"TRUE"/"true" as positive
        labels = gold_pairs[label_col]
        if labels.dtype == bool:
            mask = labels
        else:
            mask = labels.astype(str).str.upper().isin(
                ["1", "TRUE", "T", "YES", "Y"])
        return gold_pairs.loc[mask, [id1_col, id2_col]].copy()

    @staticmethod
    def _create_block_key_stats(candidates: pd.DataFrame) -> pd.DataFrame:
        df = candidates
        # Only rows with block_key
        df = df[df["block_key"].notna()].copy()
        if df.empty:
            return pd.DataFrame(columns=[
                "block_key", "pair_count", "left_unique", "right_unique", "density"
            ])

        grouped = df.groupby("block_key")
        stats = grouped.agg(
            pair_count=("id1", "size"),
            left_unique=("id1", pd.Series.nunique),
            right_unique=("id2", pd.Series.nunique),
        ).reset_index()
        # Block density: observed pairs / (|L|*|R|) within the block
        stats["density"] = stats.apply(
            lambda r: (r["pair_count"] / max(r["left_unique"] * r["right_unique"], 1)), axis=1
        )
        return stats.sort_values("pair_count", ascending=False)

    @staticmethod
    def _write_artifacts(
        *,
        results: Dict[str, Union[int, float, str, List[str]]],
        candidates: pd.DataFrame,
        block_stats: Optional[pd.DataFrame],
        out_dir: str,
        sample_size: int,
    ) -> List[str]:
        import json

        outputs: List[str] = []
        # Summary JSON
        summary_path = os.path.join(
            out_dir, "blocking_evaluation_summary.json")
        with open(summary_path, "w", encoding="utf-8") as f:
            json.dump(results, f, indent=2)
        outputs.append(summary_path)

        # Candidate sample CSV
        sample = candidates.head(sample_size)
        sample_path = os.path.join(out_dir, "candidate_pairs_sample.csv")
        sample.to_csv(sample_path, index=False)
        outputs.append(sample_path)

        # Block stats CSV
        if block_stats is not None and not block_stats.empty:
            block_csv = os.path.join(out_dir, "block_stats.csv")
            block_stats.to_csv(block_csv, index=False)
            outputs.append(block_csv)

        return outputs


__all__ = ["BlockingEvaluator"]
