{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyDI Data Integration Tutorial\n",
    "\n",
    "This tutorial demonstrates comprehensive data integration using PyDI. We'll work with movie datasets to showcase the data integration pipeline from entity matching to Data Fusion.\n",
    "\n",
    "### What You'll Learn\n",
    "\n",
    "1. **Data Loading & Profiling**: Load and analyze movie datasets with provenance tracking\n",
    "2. **Entity Matching**: \n",
    "   - Blocking strategies (Standard, Sorted Neighbourhood, Token-based, Embedding-based)\n",
    "   - Multi-attribute similarity matching with custom comparators\n",
    "   - Machine learning-based entity matching\n",
    "3. **Data Fusion**: \n",
    "   - Conflict resolution with custom fusion rules\n",
    "   - Quality assessment against test set\n",
    "   - Provenance-based conflict resolution\n",
    "\n",
    "### Datasets\n",
    "\n",
    "We'll use three movie datasets:\n",
    "- **Academy Awards**: Movies with Oscar information (4,592 records)\n",
    "- **Actors**: Movies with actor details (149 records) \n",
    "- **Golden Globes**: Movies with Golden Globe awards (2,286 records)\n",
    "\n",
    "These datasets contain overlapping movie information but with different attributes, data quality issues, and conflicting values - perfect for demonstrating real-world data integration challenges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyDI Tutorial\n",
      "Repository root: /Users/aaronsteiner/Documents/GitHub/PyDI\n",
      "Output directory: /Users/aaronsteiner/Documents/GitHub/PyDI/docs/tutorial/output/movies\n",
      "All systems ready! üöÄ\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Setup paths\n",
    "def get_repo_root():\n",
    "    \"\"\"Get repository root directory.\"\"\"\n",
    "    current = Path.cwd()\n",
    "    while current != current.parent:\n",
    "        if (current / 'pyproject.toml').exists():\n",
    "            return current\n",
    "        current = current.parent\n",
    "    return Path.cwd()\n",
    "\n",
    "ROOT = get_repo_root()\n",
    "OUTPUT_DIR = ROOT / \"docs\" / \"tutorial\" / \"output\" / \"movies\"\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"PyDI Tutorial\")\n",
    "print(f\"Repository root: {ROOT}\")\n",
    "print(f\"Output directory: {OUTPUT_DIR}\")\n",
    "print(f\"All systems ready! üöÄ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Data Loading and Profiling\n",
    "\n",
    "PyDI provides provenance-aware data loading that automatically tracks dataset metadata and optionally adds unique identifiers to each record. Let's load our movie datasets and understand their characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Academy Awards:\n",
      "  Records: 4,580\n",
      "  Attributes: 6\n",
      "  Columns: ['id', 'title', 'actors_actor_name', 'date', 'director_name', 'oscar']\n",
      "  Dataset name: academy_awards\n",
      "\n",
      "Actors:\n",
      "  Records: 151\n",
      "  Attributes: 6\n",
      "  Columns: ['id', 'title', 'actors_actor_name', 'actors_actor_birthday', 'actors_actor_birthplace', 'date']\n",
      "  Dataset name: actors\n",
      "\n",
      "Golden Globes:\n",
      "  Records: 2,279\n",
      "  Attributes: 6\n",
      "  Columns: ['id', 'title', 'actors_actor_name', 'date', 'director_name', 'globe']\n",
      "  Dataset name: golden_globes\n",
      "\n",
      "Total records across all datasets: 7,010\n"
     ]
    }
   ],
   "source": [
    "from PyDI.io import load_xml\n",
    "\n",
    "# Define dataset paths\n",
    "DATA_DIR = ROOT / \"docs\" / \"tutorial\" / \"input\" / \"movies\"\n",
    "\n",
    "# Load Academy Awards dataset\n",
    "academy_awards = load_xml(\n",
    "    DATA_DIR / \"data\" / \"academy_awards.xml\",\n",
    "    name=\"academy_awards\",\n",
    "    nested_handling=\"aggregate\"\n",
    ")\n",
    "\n",
    "# Load Actors dataset  \n",
    "actors = load_xml(\n",
    "    DATA_DIR / \"data\" / \"actors.xml\",\n",
    "    name=\"actors\", \n",
    "    nested_handling=\"aggregate\"\n",
    ")\n",
    "\n",
    "# Load Golden Globes dataset\n",
    "golden_globes = load_xml(\n",
    "    DATA_DIR / \"data\" / \"golden_globes.xml\",\n",
    "    name=\"golden_globes\",\n",
    "    nested_handling=\"aggregate\"\n",
    ")\n",
    "\n",
    "# Display basic information\n",
    "datasets = [academy_awards, actors, golden_globes]\n",
    "names = [\"Academy Awards\", \"Actors\", \"Golden Globes\"]\n",
    "\n",
    "for df, name in zip(datasets, names):\n",
    "    print(f\"{name}:\")\n",
    "    print(f\"  Records: {len(df):,}\")\n",
    "    print(f\"  Attributes: {len(df.columns)}\")\n",
    "    print(f\"  Columns: {list(df.columns)}\")\n",
    "    print(f\"  Dataset name: {df.attrs.get('dataset_name', 'unknown')}\")\n",
    "    print()\n",
    "\n",
    "total_records = sum(len(df) for df in datasets)\n",
    "print(f\"Total records across all datasets: {total_records:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìΩÔ∏è Academy Awards Dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>actors_actor_name</th>\n",
       "      <th>date</th>\n",
       "      <th>director_name</th>\n",
       "      <th>oscar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>academy_awards_1</td>\n",
       "      <td>Biutiful</td>\n",
       "      <td>Javier Bardem</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>academy_awards_2</td>\n",
       "      <td>True Grit</td>\n",
       "      <td>[Jeff Bridges, Hailee Steinfeld]</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>Joel Coen and Ethan Coen</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>academy_awards_3</td>\n",
       "      <td>The Social Network</td>\n",
       "      <td>Jesse Eisenberg</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>David Fincher</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id               title                 actors_actor_name  \\\n",
       "0  academy_awards_1            Biutiful                     Javier Bardem   \n",
       "1  academy_awards_2           True Grit  [Jeff Bridges, Hailee Steinfeld]   \n",
       "2  academy_awards_3  The Social Network                   Jesse Eisenberg   \n",
       "\n",
       "         date             director_name oscar  \n",
       "0  2010-01-01                       NaN   NaN  \n",
       "1  2010-01-01  Joel Coen and Ethan Coen   NaN  \n",
       "2  2010-01-01             David Fincher   yes  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üé≠ Actors Dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>actors_actor_name</th>\n",
       "      <th>actors_actor_birthday</th>\n",
       "      <th>actors_actor_birthplace</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>actors_1</td>\n",
       "      <td>7th Heaven</td>\n",
       "      <td>Janet Gaynor</td>\n",
       "      <td>1906-01-01</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>1929-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>actors_2</td>\n",
       "      <td>Coquette</td>\n",
       "      <td>Mary Pickford</td>\n",
       "      <td>1892-01-01</td>\n",
       "      <td>Canada</td>\n",
       "      <td>1930-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>actors_3</td>\n",
       "      <td>The Divorcee</td>\n",
       "      <td>Norma Shearer</td>\n",
       "      <td>1902-01-01</td>\n",
       "      <td>Canada</td>\n",
       "      <td>1931-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id         title actors_actor_name actors_actor_birthday  \\\n",
       "0  actors_1    7th Heaven      Janet Gaynor            1906-01-01   \n",
       "1  actors_2      Coquette     Mary Pickford            1892-01-01   \n",
       "2  actors_3  The Divorcee     Norma Shearer            1902-01-01   \n",
       "\n",
       "  actors_actor_birthplace        date  \n",
       "0            Pennsylvania  1929-01-01  \n",
       "1                  Canada  1930-01-01  \n",
       "2                  Canada  1931-01-01  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üèÜ Golden Globes Dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>actors_actor_name</th>\n",
       "      <th>date</th>\n",
       "      <th>director_name</th>\n",
       "      <th>globe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>golden_globes_1</td>\n",
       "      <td>Frankie and Alice</td>\n",
       "      <td>Halle Berry</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>golden_globes_2</td>\n",
       "      <td>Rabbit Hole</td>\n",
       "      <td>Nicole Kidman</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>golden_globes_3</td>\n",
       "      <td>Winter's Bone</td>\n",
       "      <td>Jennifer Lawrence</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                id              title  actors_actor_name        date  \\\n",
       "0  golden_globes_1  Frankie and Alice        Halle Berry  2011-01-01   \n",
       "1  golden_globes_2        Rabbit Hole      Nicole Kidman  2011-01-01   \n",
       "2  golden_globes_3      Winter's Bone  Jennifer Lawrence  2011-01-01   \n",
       "\n",
       "  director_name globe  \n",
       "0           NaN   NaN  \n",
       "1           NaN   NaN  \n",
       "2           NaN   NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Preview the data structure\n",
    "\n",
    "print(\"\\nüìΩÔ∏è Academy Awards Dataset:\")\n",
    "display(academy_awards.head(3))\n",
    "\n",
    "print(\"\\nüé≠ Actors Dataset:\")\n",
    "display(actors.head(3))\n",
    "\n",
    "print(\"\\nüèÜ Golden Globes Dataset:\")\n",
    "display(golden_globes.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Quality Analysis\n",
    "\n",
    "Let's use PyDI's profiling capabilities to understand our data quality and identify the best attributes for matching."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Dataset Summary\n",
    "\n",
    "First, let's use the DataProfiler's `summary()` method to get basic statistics for each dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "academy_awards:\n",
      "  Rows: 4,580\n",
      "  Columns: 6\n",
      "  Total nulls: 11,028\n",
      "  Null percentage: 40.1%\n",
      "  Null counts per column:\n",
      "    title: 12 (0.3%)\n",
      "    actors_actor_name: 3,531 (77.1%)\n",
      "    director_name: 4,172 (91.1%)\n",
      "    oscar: 3,313 (72.3%)\n",
      "\n",
      "actors:\n",
      "  Rows: 151\n",
      "  Columns: 6\n",
      "  Total nulls: 0\n",
      "  Null percentage: 0.0%\n",
      "\n",
      "golden_globes:\n",
      "  Rows: 2,279\n",
      "  Columns: 6\n",
      "  Total nulls: 3,677\n",
      "  Null percentage: 26.9%\n",
      "  Null counts per column:\n",
      "    actors_actor_name: 54 (2.4%)\n",
      "    director_name: 1,966 (86.3%)\n",
      "    globe: 1,657 (72.7%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'rows': 2279,\n",
       " 'columns': 6,\n",
       " 'nulls_total': 3677,\n",
       " 'nulls_per_column': {'id': 0,\n",
       "  'title': 0,\n",
       "  'actors_actor_name': 54,\n",
       "  'date': 0,\n",
       "  'director_name': 1966,\n",
       "  'globe': 1657},\n",
       " 'dtypes': {'id': 'object',\n",
       "  'title': 'object',\n",
       "  'actors_actor_name': 'object',\n",
       "  'date': 'object',\n",
       "  'director_name': 'object',\n",
       "  'globe': 'object'}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from PyDI.profiling import DataProfiler\n",
    "\n",
    "# Initialize the DataProfiler\n",
    "profiler = DataProfiler()\n",
    "\n",
    "for df, name in zip(datasets, names):\n",
    "    profile = profiler.summary(df) # automatically prints some statistics and returns object containing stats\n",
    "\n",
    "display(profile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attribute Coverage Analysis\n",
    "\n",
    "Next, let's use the `analyze_coverage()` method to understand how attributes overlap across datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Attribute coverage across datasets:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attribute</th>\n",
       "      <th>academy_awards_count</th>\n",
       "      <th>academy_awards_pct</th>\n",
       "      <th>academy_awards_coverage</th>\n",
       "      <th>academy_awards_samples</th>\n",
       "      <th>actors_count</th>\n",
       "      <th>actors_pct</th>\n",
       "      <th>actors_coverage</th>\n",
       "      <th>actors_samples</th>\n",
       "      <th>golden_globes_count</th>\n",
       "      <th>golden_globes_pct</th>\n",
       "      <th>golden_globes_coverage</th>\n",
       "      <th>golden_globes_samples</th>\n",
       "      <th>avg_coverage</th>\n",
       "      <th>max_coverage</th>\n",
       "      <th>datasets_with_attribute</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>actors_actor_birthday</td>\n",
       "      <td>0/0</td>\n",
       "      <td>0%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>N/A</td>\n",
       "      <td>151/151</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['1906-01-01', '1892-01-01', '1902-01-01']</td>\n",
       "      <td>0/0</td>\n",
       "      <td>0%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>actors_actor_birthplace</td>\n",
       "      <td>0/0</td>\n",
       "      <td>0%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>N/A</td>\n",
       "      <td>151/151</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['Pennsylvania', 'Canada', 'Canada']</td>\n",
       "      <td>0/0</td>\n",
       "      <td>0%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>actors_actor_name</td>\n",
       "      <td>1049/4580</td>\n",
       "      <td>22.9%</td>\n",
       "      <td>0.229039</td>\n",
       "      <td>['Javier Bardem', ['Jeff Bridges', 'Hailee Ste...</td>\n",
       "      <td>151/151</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['Janet Gaynor', 'Mary Pickford', 'Norma Shear...</td>\n",
       "      <td>2225/2279</td>\n",
       "      <td>97.6%</td>\n",
       "      <td>0.976305</td>\n",
       "      <td>['Halle Berry', 'Nicole Kidman', 'Jennifer Law...</td>\n",
       "      <td>0.735115</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>date</td>\n",
       "      <td>4580/4580</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>['2010-01-01', '2010-01-01', '2010-01-01']</td>\n",
       "      <td>151/151</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['1929-01-01', '1930-01-01', '1931-01-01']</td>\n",
       "      <td>2279/2279</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>['2011-01-01', '2011-01-01', '2011-01-01']</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>director_name</td>\n",
       "      <td>408/4580</td>\n",
       "      <td>8.9%</td>\n",
       "      <td>0.089083</td>\n",
       "      <td>['Joel Coen and Ethan Coen', 'David Fincher', ...</td>\n",
       "      <td>0/0</td>\n",
       "      <td>0%</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N/A</td>\n",
       "      <td>313/2279</td>\n",
       "      <td>13.7%</td>\n",
       "      <td>0.137341</td>\n",
       "      <td>['Darren Aronofsky', 'David Fincher', 'Tom Hoo...</td>\n",
       "      <td>0.075475</td>\n",
       "      <td>0.137341</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>globe</td>\n",
       "      <td>0/0</td>\n",
       "      <td>0%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0/0</td>\n",
       "      <td>0%</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N/A</td>\n",
       "      <td>622/2279</td>\n",
       "      <td>27.3%</td>\n",
       "      <td>0.272927</td>\n",
       "      <td>['yes', 'yes', 'yes']</td>\n",
       "      <td>0.090976</td>\n",
       "      <td>0.272927</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>id</td>\n",
       "      <td>4580/4580</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>['academy_awards_1', 'academy_awards_2', 'acad...</td>\n",
       "      <td>151/151</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['actors_1', 'actors_2', 'actors_3']</td>\n",
       "      <td>2279/2279</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>['golden_globes_1', 'golden_globes_2', 'golden...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>oscar</td>\n",
       "      <td>1267/4580</td>\n",
       "      <td>27.7%</td>\n",
       "      <td>0.276638</td>\n",
       "      <td>['yes', 'yes', 'yes']</td>\n",
       "      <td>0/0</td>\n",
       "      <td>0%</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0/0</td>\n",
       "      <td>0%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0.092213</td>\n",
       "      <td>0.276638</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>title</td>\n",
       "      <td>4568/4580</td>\n",
       "      <td>99.7%</td>\n",
       "      <td>0.997380</td>\n",
       "      <td>['Biutiful', 'True Grit', 'The Social Network']</td>\n",
       "      <td>151/151</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['7th Heaven', 'Coquette', 'The Divorcee']</td>\n",
       "      <td>2279/2279</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>['Frankie and Alice', 'Rabbit Hole', \"Winter's...</td>\n",
       "      <td>0.999127</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 attribute academy_awards_count academy_awards_pct  \\\n",
       "0    actors_actor_birthday                  0/0                 0%   \n",
       "1  actors_actor_birthplace                  0/0                 0%   \n",
       "2        actors_actor_name            1049/4580              22.9%   \n",
       "3                     date            4580/4580             100.0%   \n",
       "4            director_name             408/4580               8.9%   \n",
       "5                    globe                  0/0                 0%   \n",
       "6                       id            4580/4580             100.0%   \n",
       "7                    oscar            1267/4580              27.7%   \n",
       "8                    title            4568/4580              99.7%   \n",
       "\n",
       "   academy_awards_coverage                             academy_awards_samples  \\\n",
       "0                 0.000000                                                N/A   \n",
       "1                 0.000000                                                N/A   \n",
       "2                 0.229039  ['Javier Bardem', ['Jeff Bridges', 'Hailee Ste...   \n",
       "3                 1.000000         ['2010-01-01', '2010-01-01', '2010-01-01']   \n",
       "4                 0.089083  ['Joel Coen and Ethan Coen', 'David Fincher', ...   \n",
       "5                 0.000000                                                N/A   \n",
       "6                 1.000000  ['academy_awards_1', 'academy_awards_2', 'acad...   \n",
       "7                 0.276638                              ['yes', 'yes', 'yes']   \n",
       "8                 0.997380    ['Biutiful', 'True Grit', 'The Social Network']   \n",
       "\n",
       "  actors_count actors_pct  actors_coverage  \\\n",
       "0      151/151     100.0%              1.0   \n",
       "1      151/151     100.0%              1.0   \n",
       "2      151/151     100.0%              1.0   \n",
       "3      151/151     100.0%              1.0   \n",
       "4          0/0         0%              0.0   \n",
       "5          0/0         0%              0.0   \n",
       "6      151/151     100.0%              1.0   \n",
       "7          0/0         0%              0.0   \n",
       "8      151/151     100.0%              1.0   \n",
       "\n",
       "                                      actors_samples golden_globes_count  \\\n",
       "0         ['1906-01-01', '1892-01-01', '1902-01-01']                 0/0   \n",
       "1               ['Pennsylvania', 'Canada', 'Canada']                 0/0   \n",
       "2  ['Janet Gaynor', 'Mary Pickford', 'Norma Shear...           2225/2279   \n",
       "3         ['1929-01-01', '1930-01-01', '1931-01-01']           2279/2279   \n",
       "4                                                N/A            313/2279   \n",
       "5                                                N/A            622/2279   \n",
       "6               ['actors_1', 'actors_2', 'actors_3']           2279/2279   \n",
       "7                                                N/A                 0/0   \n",
       "8         ['7th Heaven', 'Coquette', 'The Divorcee']           2279/2279   \n",
       "\n",
       "  golden_globes_pct  golden_globes_coverage  \\\n",
       "0                0%                0.000000   \n",
       "1                0%                0.000000   \n",
       "2             97.6%                0.976305   \n",
       "3            100.0%                1.000000   \n",
       "4             13.7%                0.137341   \n",
       "5             27.3%                0.272927   \n",
       "6            100.0%                1.000000   \n",
       "7                0%                0.000000   \n",
       "8            100.0%                1.000000   \n",
       "\n",
       "                               golden_globes_samples  avg_coverage  \\\n",
       "0                                                N/A      0.333333   \n",
       "1                                                N/A      0.333333   \n",
       "2  ['Halle Berry', 'Nicole Kidman', 'Jennifer Law...      0.735115   \n",
       "3         ['2011-01-01', '2011-01-01', '2011-01-01']      1.000000   \n",
       "4  ['Darren Aronofsky', 'David Fincher', 'Tom Hoo...      0.075475   \n",
       "5                              ['yes', 'yes', 'yes']      0.090976   \n",
       "6  ['golden_globes_1', 'golden_globes_2', 'golden...      1.000000   \n",
       "7                                                N/A      0.092213   \n",
       "8  ['Frankie and Alice', 'Rabbit Hole', \"Winter's...      0.999127   \n",
       "\n",
       "   max_coverage  datasets_with_attribute  \n",
       "0      1.000000                        1  \n",
       "1      1.000000                        1  \n",
       "2      1.000000                        3  \n",
       "3      1.000000                        3  \n",
       "4      0.137341                        2  \n",
       "5      0.272927                        1  \n",
       "6      1.000000                        3  \n",
       "7      0.276638                        1  \n",
       "8      1.000000                        3  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîó Attributes suitable for entity matching:\n",
      "Attributes available in 2+ datasets: ['actors_actor_name', 'date', 'director_name', 'id', 'title']\n"
     ]
    }
   ],
   "source": [
    "coverage = profiler.analyze_coverage(\n",
    "    datasets=datasets,\n",
    "    include_samples=True,\n",
    "    sample_count=3  # Show 3 sample values per attribute\n",
    ")\n",
    "\n",
    "print(\"üìä Attribute coverage across datasets:\")\n",
    "display(coverage)\n",
    "\n",
    "# Identify attributes suitable for entity matching\n",
    "print(\"\\nüîó Attributes suitable for entity matching:\")\n",
    "matching_attrs = coverage[coverage['datasets_with_attribute'] >= 2]['attribute'].tolist()\n",
    "print(f\"Attributes available in 2+ datasets: {matching_attrs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detailed Data Profiling\n",
    "\n",
    "Now let's generate comprehensive HTML profiles for each dataset using the `profile()` method. These reports provide in-depth statistical analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Profiling Academy Awards...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <ins><a href=\"https://ydata.ai/register\">Upgrade to ydata-sdk</a></ins>\n",
       "                <p>\n",
       "                    Improve your data and profiling with ydata-sdk, featuring data quality scoring, redundancy detection, outlier identification, text validation, and synthetic data generation.\n",
       "                </p>\n",
       "            </div>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02de109bdfc145068e749ee63c6b0900",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:00<00:00, 162.17it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9166663168174fd8879ddffc214e8603",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate report structure:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bf1d08fe15344ddadd1999b67a7cf72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Render HTML:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "574b6a99559c46459ada538219802ad4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Export report to file:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úÖ Profile saved: c:\\Users\\Ralph\\dev\\pydi\\docs\\tutorial\\output\\movies\\dataset-profiles\\academy_awards_profile.html\n",
      "üìä Profiling Actors...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a381fbee4f30425da271e2ce15da3e93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:00<00:00, 333.31it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af3dae602def4a07b984a967925e282f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate report structure:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aeaa2346be7140399c1c0eaaeac3a624",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Render HTML:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d0f79db036744e28e9db12c0b06f26d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Export report to file:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úÖ Profile saved: c:\\Users\\Ralph\\dev\\pydi\\docs\\tutorial\\output\\movies\\dataset-profiles\\actors_profile.html\n",
      "üìä Profiling Golden Globes...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2559ec1e5cb84a9ca2afae68990b10dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:00<00:00, 171.44it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48873a83265e4eba878e0d8bbc0c44f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate report structure:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "091593193e134805882fab992f283fc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Render HTML:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7620172ca1642989dcb86708a41b52a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Export report to file:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úÖ Profile saved: c:\\Users\\Ralph\\dev\\pydi\\docs\\tutorial\\output\\movies\\dataset-profiles\\golden_globes_profile.html\n",
      "\n",
      "üéØ Generated 3 detailed HTML reports\n",
      "üìÅ Location: c:\\Users\\Ralph\\dev\\pydi\\docs\\tutorial\\output\\movies\\dataset-profiles\n",
      "\n",
      "üí° Open these HTML files in your browser for interactive exploration:\n",
      "  ‚Ä¢ academy_awards_profile.html\n",
      "  ‚Ä¢ actors_profile.html\n",
      "  ‚Ä¢ golden_globes_profile.html\n"
     ]
    }
   ],
   "source": [
    "# Generate detailed HTML profiles for each dataset\n",
    "\n",
    "profile_dir = OUTPUT_DIR / \"dataset-profiles\"\n",
    "profile_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "profile_paths = []\n",
    "\n",
    "for df, name in zip(datasets, names):\n",
    "    print(f\"üìä Profiling {name}...\")\n",
    "    \n",
    "    profile_path = profiler.profile(df, str(profile_dir))\n",
    "    profile_paths.append(profile_path)\n",
    "    print(f\"  ‚úÖ Profile saved: {profile_path}\")\n",
    "\n",
    "print(f\"\\nüéØ Generated {len(profile_paths)} detailed HTML reports\")\n",
    "print(f\"üìÅ Location: {profile_dir}\")\n",
    "print(\"\\nüí° Open these HTML files in your browser for interactive exploration:\")\n",
    "for path in profile_paths:\n",
    "    print(f\"  ‚Ä¢ {Path(path).name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Entity Matching\n",
    "\n",
    "Entity Matching is the process of identifying records that refer to the same real-world entity. PyDI implements different blocking and matching methods.\n",
    "\n",
    "### Step 1: Blocking\n",
    "\n",
    "Blocking reduces the number of comparisons from O(n¬≤) to a manageable subset. Let's explore different blocking strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's setup logging first\n",
    "import logging\n",
    "\n",
    "import os\n",
    "os.makedirs('output/logs', exist_ok=True)\n",
    "\n",
    "# choose either default logging or debug logging\n",
    "\n",
    "# Configure logging for INFO level\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='[%(levelname)-5s] %(name)s - %(message)s',\n",
    "    handlers=[\n",
    "          logging.FileHandler('output/logs/pydi.log'),  # Save to file\n",
    "          logging.StreamHandler()                      # Display on console\n",
    "      ],\n",
    "    force=True\n",
    ")\n",
    "\n",
    "# # Configure logging for DEBUG level\n",
    "# logging.basicConfig(\n",
    "#     level=logging.DEBUG,\n",
    "#     format='[%(levelname)-5s] %(name)s - %(message)s',\n",
    "#     handlers=[\n",
    "#           logging.FileHandler('output/logs/pydi.log'),  # Save to file\n",
    "#           logging.StreamHandler()                      # Display on console\n",
    "#       ],\n",
    "#     force=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without blocking: 344,129 comparisons required\n",
      "\n",
      "üéØ Goal: Reduce comparisons while maintaining high recall\n",
      "\n",
      "\n",
      " No Blocking\n",
      "  Generated: 344,129 candidates\n"
     ]
    }
   ],
   "source": [
    "from PyDI.entitymatching import NoBlocker, StandardBlocker, SortedNeighbourhoodBlocker, TokenBlocker, EmbeddingBlocker\n",
    "\n",
    "# We'll focus on Actors and Golden Globes for showcasing blocking strategies\n",
    "\n",
    "max_pairs = len(actors) * len(golden_globes)\n",
    "print(f\"Without blocking: {max_pairs:,} comparisons required\")\n",
    "print(\"\\nüéØ Goal: Reduce comparisons while maintaining high recall\\n\")\n",
    "\n",
    "# No Blocking - compare all possible pairs\n",
    "print(\"\\n No Blocking\")\n",
    "\n",
    "no_blocker = NoBlocker(\n",
    "    actors, golden_globes,\n",
    "    batch_size=1000,\n",
    "    id_column='id'  # specify the ID column for both datasets\n",
    ")\n",
    "\n",
    "# in an actual large-scale application, we do not build a list of all pairs but stream over them like this\n",
    "for batch in no_blocker:\n",
    "    # do something with the pairs\n",
    "    continue\n",
    "\n",
    "# but we can also generate the full set of pairs for smaller datasets\n",
    "no_candidates = no_blocker.materialize()\n",
    "\n",
    "print(f\"  Generated: {len(no_candidates):,} candidates\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use an actual blocker. Note that when instantiating the blocker, it also writes out a corresponding debug file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO ] PyDI.entitymatching.blocking.standard.StandardBlocker - created 145 blocking keys for first dataset\n",
      "[INFO ] PyDI.entitymatching.blocking.standard.StandardBlocker - created 1522 blocking keys for second dataset\n",
      "[INFO ] PyDI.entitymatching.blocking.standard.StandardBlocker - created 91 blocks from blocking keys\n",
      "[INFO ] PyDI.entitymatching.blocking.standard.StandardBlocker - Debug results written to file: c:\\Users\\Ralph\\dev\\pydi\\docs\\tutorial\\output\\movies\\blocking-evaluation\\debugResultsBlocking_StandardBlocker.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1Ô∏è‚É£ Standard Blocking (Concatenation of first 2 characters of each of the first three tokens of title)\n",
      "\n",
      "  Generated: 277 candidates\n"
     ]
    }
   ],
   "source": [
    "# 1. Standard Blocking - First 3 characters of title\n",
    "print(\"\\n1Ô∏è‚É£ Standard Blocking (Concatenation of first 2 characters of each of the first three tokens of title)\")\n",
    "\n",
    "# Add title_prefix directly to the original dataframes\n",
    "actors['title_prefix'] = actors['title'].astype(str).apply(lambda x: ''.join([word[:2].upper() for word in x.split()[:3]]))\n",
    "golden_globes['title_prefix'] = golden_globes['title'].astype(str).apply(lambda x: ''.join([word[:2].upper() for word in x.split()[:3]]))\n",
    "\n",
    "standard_blocker_a2g = StandardBlocker(\n",
    "    actors, golden_globes,\n",
    "    on=['title_prefix'],\n",
    "    batch_size=1000,\n",
    "    output_dir=OUTPUT_DIR / \"blocking-evaluation\",\n",
    "    id_column='id'\n",
    ")\n",
    "\n",
    "standard_candidates_a2g = standard_blocker_a2g.materialize()\n",
    "\n",
    "print()\n",
    "print(f\"  Generated: {len(standard_candidates_a2g):,} candidates\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO ] PyDI.entitymatching.blocking.sorted_neighbourhood.SortedNeighbourhoodBlocker - created sorted neighbourhood with window size 20\n",
      "[INFO ] PyDI.entitymatching.blocking.sorted_neighbourhood.SortedNeighbourhoodBlocker - created 1 sorted sequence from 2430 records\n",
      "[INFO ] PyDI.entitymatching.blocking.sorted_neighbourhood.SortedNeighbourhoodBlocker - Debug results written to file: c:\\Users\\Ralph\\dev\\pydi\\docs\\tutorial\\output\\movies\\blocking-evaluation\\debugResultsBlocking_SortedNeighbourhoodBlocker.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2Ô∏è‚É£ Sorted Neighbourhood Blocking (Title-based, Window=5)\n",
      "\n",
      "  Generated: 4,899 candidates\n"
     ]
    }
   ],
   "source": [
    "# 2. Sorted Neighbourhood - Sequential similarity\n",
    "print(\"\\n2Ô∏è‚É£ Sorted Neighbourhood Blocking (Title-based, Window=5)\")\n",
    "\n",
    "sn_blocker_a2g = SortedNeighbourhoodBlocker(\n",
    "    actors, golden_globes,\n",
    "    key='title',  # Sort by title\n",
    "    window=20,     # Compare with 20 neighbors\n",
    "    batch_size=1000,\n",
    "    output_dir=OUTPUT_DIR / \"blocking-evaluation\",\n",
    "    id_column='id'\n",
    ")\n",
    "\n",
    "sn_candidates_a2g = sn_blocker_a2g.materialize()\n",
    "\n",
    "print()\n",
    "print(f\"  Generated: {len(sn_candidates_a2g):,} candidates\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO ] PyDI.entitymatching.blocking.token_blocking.TokenBlocker - created 330 token keys for first dataset\n",
      "[INFO ] PyDI.entitymatching.blocking.token_blocking.TokenBlocker - created 572 token keys for second dataset\n",
      "[INFO ] PyDI.entitymatching.blocking.token_blocking.TokenBlocker - created 325 blocks from token keys\n",
      "[INFO ] PyDI.entitymatching.blocking.token_blocking.TokenBlocker - Debug results written to file: c:\\Users\\Ralph\\dev\\pydi\\docs\\tutorial\\output\\movies\\blocking-evaluation\\debugResultsBlocking_TokenBlocker.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3Ô∏è‚É£ Token Blocking (Title Tokens, Min Length=3, 2-grams)\n",
      "\n",
      "  Generated: 166,834 candidates\n"
     ]
    }
   ],
   "source": [
    "# 3. Token Blocking - Token-based similarity\n",
    "print(\"\\n3Ô∏è‚É£ Token Blocking (Title Tokens, Min Length=3, 2-grams)\")\n",
    "\n",
    "token_blocker_a2g = TokenBlocker(\n",
    "    actors, golden_globes,\n",
    "    column='title',      # Tokenize titles\n",
    "    batch_size=1000,\n",
    "    output_dir=OUTPUT_DIR / \"blocking-evaluation\",\n",
    "    id_column='id',\n",
    "    ngram_size=2,\n",
    "    ngram_type='character'\n",
    ")\n",
    "\n",
    "token_candidates_a2g = token_blocker_a2g.materialize()\n",
    "\n",
    "print()\n",
    "print(f\"  Generated: {len(token_candidates_a2g):,} candidates\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO ] PyDI.entitymatching.blocking.embedding.EmbeddingBlocker - Initialized EmbeddingBlocker with sklearn backend, top_k=20, threshold=0.3\n",
      "[INFO ] sentence_transformers.SentenceTransformer - Use pytorch device_name: cpu\n",
      "[INFO ] sentence_transformers.SentenceTransformer - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4Ô∏è‚É£ Embedding Blocking (Semantic Similarity)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO ] PyDI.entitymatching.blocking.embedding.EmbeddingBlocker - Loaded sentence transformer model: sentence-transformers/all-MiniLM-L6-v2\n",
      "[INFO ] PyDI.entitymatching.blocking.embedding.EmbeddingBlocker - created 384d embeddings for first dataset\n",
      "[INFO ] PyDI.entitymatching.blocking.embedding.EmbeddingBlocker - created 384d embeddings for second dataset\n",
      "[INFO ] PyDI.entitymatching.blocking.embedding.EmbeddingBlocker - created similarity index with 2279 vectors, metric=cosine\n",
      "[INFO ] PyDI.entitymatching.blocking.embedding.EmbeddingBlocker - Debug results written to file: c:\\Users\\Ralph\\dev\\pydi\\docs\\tutorial\\output\\movies\\blocking-evaluation\\debugResultsBlocking_EmbeddingBlocker.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Generated: 2,945 candidates\n"
     ]
    }
   ],
   "source": [
    "# 4. Embedding Blocking - Semantic similarity\n",
    "print(\"\\n4Ô∏è‚É£ Embedding Blocking (Semantic Similarity)\")\n",
    "\n",
    "embedding_blocker_a2g = EmbeddingBlocker(\n",
    "    actors, golden_globes,\n",
    "    text_cols=['title'],\n",
    "    model=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    index_backend=\"sklearn\",\n",
    "    top_k=20,          # Top 20 most similar\n",
    "    batch_size=500,\n",
    "    output_dir=OUTPUT_DIR / \"blocking-evaluation\",\n",
    "    id_column='id'\n",
    ")\n",
    "    \n",
    "embedding_candidates_a2g = embedding_blocker_a2g.materialize()\n",
    "\n",
    "print()\n",
    "print(f\"  Generated: {len(embedding_candidates_a2g):,} candidates\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Evaluation Against Ground Truth\n",
    "\n",
    "PyDI provides evaluation methods for blocking with pair completeness, pair quality, and reduction ratio:\n",
    "- **`evaluate_blocking()`**: Evaluates blocking given an already materialized set of pairs.\n",
    "- **`evaluate_blocking_batched()`**: Evaluates blocking by iterating over batches and storing results. Useful for very large datasets \n",
    "\n",
    "Let's first evaluate materialized blocking results against a set of provided ground truth correspondences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO ] root -   Pair Completeness: 0.346\n",
      "[INFO ] root -   Pair Quality:      0.032\n",
      "[INFO ] root -   Reduction Ratio:   0.999\n",
      "[INFO ] root -   True Matches Found: 9/26\n",
      "[INFO ] root - Blocking evaluation complete!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üí° Evaluating pair quality only makes sense if the test set contains all possible pairs, which is not the case in this example!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'pair_completeness': 0.34615384615384615,\n",
       " 'pair_quality': 0.032490974729241874,\n",
       " 'reduction_ratio': 0.9991950692908764,\n",
       " 'total_candidates': 277,\n",
       " 'total_possible_pairs': 344129,\n",
       " 'true_positives_found': 9,\n",
       " 'total_true_pairs': 26,\n",
       " 'evaluation_timestamp': '2025-09-25T15:02:11.693712',\n",
       " 'output_files': ['c:\\\\Users\\\\Ralph\\\\dev\\\\pydi\\\\docs\\\\tutorial\\\\output\\\\movies\\\\blocking-evaluation\\\\blocking_evaluation_summary.json',\n",
       "  'c:\\\\Users\\\\Ralph\\\\dev\\\\pydi\\\\docs\\\\tutorial\\\\output\\\\movies\\\\blocking-evaluation\\\\blocking_detailed_results.csv']}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from PyDI.io import load_csv\n",
    "from PyDI.entitymatching import EntityMatchingEvaluator\n",
    "# Showcase EntityMatchingEvaluator.evaluate_blocking utility\n",
    "\n",
    "# Load test set with proper column names\n",
    "test_gt = load_csv(\n",
    "    DATA_DIR / \"entitymatching\" / \"actors_2_golden_globes_test.csv\",\n",
    "    name=\"test_set\", header=None, names=['id1', 'id2', 'label'], add_index=False\n",
    ")\n",
    "\n",
    "# Use EntityMatchingEvaluator.evaluate_blocking on Standard Blocking\n",
    "results = EntityMatchingEvaluator.evaluate_blocking(\n",
    "    candidate_pairs=standard_candidates_a2g,\n",
    "    blocker=standard_blocker_a2g,\n",
    "    test_pairs=test_gt,\n",
    "    out_dir=OUTPUT_DIR / \"blocking-evaluation\"\n",
    ")\n",
    "\n",
    "print(f\"\\nüí° Evaluating pair quality only makes sense if the test set contains all possible pairs, which is not the case in this example!\")\n",
    "\n",
    "display(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When datasets are huge, it is necessary to use the evaluate_blocking_batched() function to avoid materializing the full set of pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO ] root - Starting batched blocking evaluation...\n",
      "[INFO ] root -   Pair Completeness: 0.346\n",
      "[INFO ] root -   Pair Quality:      0.032\n",
      "[INFO ] root -   Reduction Ratio:   0.999\n",
      "[INFO ] root -   True Matches Found: 9/26\n",
      "[INFO ] root -   Batches Processed:  1\n",
      "[INFO ] root - Blocking evaluation complete!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'pair_completeness': 0.34615384615384615,\n",
       " 'pair_quality': 0.032490974729241874,\n",
       " 'reduction_ratio': 0.9991950692908764,\n",
       " 'total_candidates': 277,\n",
       " 'total_possible_pairs': 344129,\n",
       " 'true_positives_found': 9,\n",
       " 'total_true_pairs': 26,\n",
       " 'batches_processed': 1,\n",
       " 'evaluation_timestamp': '2025-09-25T15:02:11.723528',\n",
       " 'output_files': ['c:\\\\Users\\\\Ralph\\\\dev\\\\pydi\\\\docs\\\\tutorial\\\\output\\\\movies\\\\blocking-evaluation\\\\blocking_evaluation_summary.json',\n",
       "  'c:\\\\Users\\\\Ralph\\\\dev\\\\pydi\\\\docs\\\\tutorial\\\\output\\\\movies\\\\blocking-evaluation\\\\blocking_detailed_results.csv']}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = EntityMatchingEvaluator.evaluate_blocking_batched(\n",
    "    blocker=standard_blocker_a2g,\n",
    "    test_pairs=test_gt,\n",
    "    out_dir=OUTPUT_DIR / \"blocking-evaluation\"\n",
    ")\n",
    "\n",
    "display(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do the same kind of blocking for the dataset combination Academy Awards <-> Actors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO ] PyDI.entitymatching.blocking.standard.StandardBlocker - created 3585 blocking keys for first dataset\n",
      "[INFO ] PyDI.entitymatching.blocking.standard.StandardBlocker - created 145 blocking keys for second dataset\n",
      "[INFO ] PyDI.entitymatching.blocking.standard.StandardBlocker - created 142 blocks from blocking keys\n",
      "[INFO ] PyDI.entitymatching.blocking.standard.StandardBlocker - Debug results written to file: c:\\Users\\Ralph\\dev\\pydi\\docs\\tutorial\\output\\movies\\blocking-evaluation\\debugResultsBlocking_StandardBlocker.csv\n",
      "[INFO ] PyDI.entitymatching.blocking.sorted_neighbourhood.SortedNeighbourhoodBlocker - created sorted neighbourhood with window size 20\n",
      "[INFO ] PyDI.entitymatching.blocking.sorted_neighbourhood.SortedNeighbourhoodBlocker - created 1 sorted sequence from 4731 records\n",
      "[INFO ] PyDI.entitymatching.blocking.sorted_neighbourhood.SortedNeighbourhoodBlocker - Debug results written to file: c:\\Users\\Ralph\\dev\\pydi\\docs\\tutorial\\output\\movies\\blocking-evaluation\\debugResultsBlocking_SortedNeighbourhoodBlocker.csv\n",
      "[INFO ] PyDI.entitymatching.blocking.token_blocking.TokenBlocker - created 710 token keys for first dataset\n",
      "[INFO ] PyDI.entitymatching.blocking.token_blocking.TokenBlocker - created 330 token keys for second dataset\n",
      "[INFO ] PyDI.entitymatching.blocking.token_blocking.TokenBlocker - created 330 blocks from token keys\n",
      "[INFO ] PyDI.entitymatching.blocking.token_blocking.TokenBlocker - Debug results written to file: c:\\Users\\Ralph\\dev\\pydi\\docs\\tutorial\\output\\movies\\blocking-evaluation\\debugResultsBlocking_TokenBlocker.csv\n",
      "[INFO ] PyDI.entitymatching.blocking.embedding.EmbeddingBlocker - Initialized EmbeddingBlocker with sklearn backend, top_k=20, threshold=0.3\n",
      "[INFO ] sentence_transformers.SentenceTransformer - Use pytorch device_name: cpu\n",
      "[INFO ] sentence_transformers.SentenceTransformer - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n",
      "[INFO ] PyDI.entitymatching.blocking.embedding.EmbeddingBlocker - Loaded sentence transformer model: sentence-transformers/all-MiniLM-L6-v2\n",
      "[INFO ] PyDI.entitymatching.blocking.embedding.EmbeddingBlocker - created 384d embeddings for first dataset\n",
      "[INFO ] PyDI.entitymatching.blocking.embedding.EmbeddingBlocker - created 384d embeddings for second dataset\n",
      "[INFO ] PyDI.entitymatching.blocking.embedding.EmbeddingBlocker - created similarity index with 151 vectors, metric=cosine\n",
      "[INFO ] PyDI.entitymatching.blocking.embedding.EmbeddingBlocker - Debug results written to file: c:\\Users\\Ralph\\dev\\pydi\\docs\\tutorial\\output\\movies\\blocking-evaluation\\debugResultsBlocking_EmbeddingBlocker.csv\n"
     ]
    }
   ],
   "source": [
    "# Add title_prefix directly to the original dataframes\n",
    "academy_awards['title_prefix'] = academy_awards['title'].astype(str).apply(lambda x: ''.join([word[:2].upper() for word in x.split()[:3]]))\n",
    "\n",
    "standard_blocker_aa2a = StandardBlocker(\n",
    "    academy_awards, actors,\n",
    "    on=['title_prefix'],  # Block on first 3 characters of title\n",
    "    batch_size=1000,\n",
    "    output_dir=OUTPUT_DIR / \"blocking-evaluation\",\n",
    "    id_column='id'\n",
    ")\n",
    "standard_candidates_aa2a = standard_blocker_aa2a.materialize()\n",
    "\n",
    "sn_blocker_aa2a = SortedNeighbourhoodBlocker(\n",
    "    academy_awards, actors,\n",
    "    key='title',  # Sort by title\n",
    "    window=20,     # Compare with 20 neighbors\n",
    "    batch_size=1000,\n",
    "    output_dir=OUTPUT_DIR / \"blocking-evaluation\",\n",
    "    id_column='id'\n",
    ")\n",
    "sn_candidates_aa2a = sn_blocker_aa2a.materialize()\n",
    "\n",
    "token_blocker_aa2a = TokenBlocker(\n",
    "    academy_awards, actors,\n",
    "    column='title',      # Tokenize titles\n",
    "    batch_size=1000,\n",
    "    output_dir=OUTPUT_DIR / \"blocking-evaluation\",\n",
    "    id_column='id',\n",
    "    ngram_size=2,\n",
    "    ngram_type='character'\n",
    ")\n",
    "token_candidates_aa2a = token_blocker_aa2a.materialize()\n",
    "\n",
    "embedding_blocker_aa2a = EmbeddingBlocker(\n",
    "    academy_awards, actors,\n",
    "    text_cols=['title'],\n",
    "    model=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    index_backend=\"sklearn\",\n",
    "    top_k=20,          # Top 20 most similar\n",
    "    batch_size=500,\n",
    "    output_dir=OUTPUT_DIR / \"blocking-evaluation\",\n",
    "    id_column='id'\n",
    ")\n",
    "embedding_candidates_aa2a = embedding_blocker_aa2a.materialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's evaluate which blocking method we want to use for each dataset combination:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO ] root -   Pair Completeness: 0.346\n",
      "[INFO ] root -   Pair Quality:      0.032\n",
      "[INFO ] root -   Reduction Ratio:   0.999\n",
      "[INFO ] root -   True Matches Found: 9/26\n",
      "[INFO ] root - Blocking evaluation complete!\n",
      "[INFO ] root -   Pair Completeness: 0.462\n",
      "[INFO ] root -   Pair Quality:      0.002\n",
      "[INFO ] root -   Reduction Ratio:   0.986\n",
      "[INFO ] root -   True Matches Found: 12/26\n",
      "[INFO ] root - Blocking evaluation complete!\n",
      "[INFO ] root -   Pair Completeness: 1.000\n",
      "[INFO ] root -   Pair Quality:      0.000\n",
      "[INFO ] root -   Reduction Ratio:   0.515\n",
      "[INFO ] root -   True Matches Found: 26/26\n",
      "[INFO ] root - Blocking evaluation complete!\n",
      "[INFO ] root -   Pair Completeness: 1.000\n",
      "[INFO ] root -   Pair Quality:      0.009\n",
      "[INFO ] root -   Reduction Ratio:   0.991\n",
      "[INFO ] root -   True Matches Found: 26/26\n",
      "[INFO ] root - Blocking evaluation complete!\n",
      "[INFO ] root -   Pair Completeness: 0.957\n",
      "[INFO ] root -   Pair Quality:      0.113\n",
      "[INFO ] root -   Reduction Ratio:   0.999\n",
      "[INFO ] root -   True Matches Found: 45/47\n",
      "[INFO ] root - Blocking evaluation complete!\n",
      "[INFO ] root -   Pair Completeness: 0.979\n",
      "[INFO ] root -   Pair Quality:      0.008\n",
      "[INFO ] root -   Reduction Ratio:   0.992\n",
      "[INFO ] root -   True Matches Found: 46/47\n",
      "[INFO ] root - Blocking evaluation complete!\n",
      "[INFO ] root -   Pair Completeness: 1.000\n",
      "[INFO ] root -   Pair Quality:      0.000\n",
      "[INFO ] root -   Reduction Ratio:   0.467\n",
      "[INFO ] root -   True Matches Found: 47/47\n",
      "[INFO ] root - Blocking evaluation complete!\n",
      "[INFO ] root -   Pair Completeness: 1.000\n",
      "[INFO ] root -   Pair Quality:      0.001\n",
      "[INFO ] root -   Reduction Ratio:   0.943\n",
      "[INFO ] root -   True Matches Found: 47/47\n",
      "[INFO ] root - Blocking evaluation complete!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best blocking for a2g: EmbeddingBlocking (PC: 1.000, RR: 0.991)\n",
      "Best blocking for aa2a: EmbeddingBlocking (PC: 1.000, RR: 0.943)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate all blocking methods for both dataset combinations\n",
    "\n",
    "evaluator = EntityMatchingEvaluator()\n",
    "\n",
    "# Create dictionaries of candidates for both dataset combinations\n",
    "a2g_blocking_candidates = {\n",
    "    'StandardBlocking': [standard_candidates_a2g, standard_blocker_a2g],\n",
    "    'SortedNeighbourhoodBlocker': [sn_candidates_a2g, sn_blocker_a2g],\n",
    "    'TokenBlocking': [token_candidates_a2g,token_blocker_a2g],\n",
    "    'EmbeddingBlocking': [embedding_candidates_a2g,embedding_blocker_a2g]\n",
    "}\n",
    "\n",
    "aa2a_blocking_candidates = {\n",
    "    'StandardBlocking': [standard_candidates_aa2a,standard_blocker_aa2a],\n",
    "    'SortedNeighbourhood': [sn_candidates_aa2a, sn_blocker_aa2a],\n",
    "    'TokenBlocking': [token_candidates_aa2a,token_blocker_aa2a],\n",
    "    'EmbeddingBlocking': [embedding_candidates_aa2a,embedding_blocker_aa2a]\n",
    "}\n",
    "\n",
    "# Load correspondences for evaluation\n",
    "a2g_correspondences = load_csv(\n",
    "    DATA_DIR / \"entitymatching\" / \"actors_2_golden_globes_test.csv\",\n",
    "    name=\"a2g_test\", header=None, names=['id1', 'id2', 'label'], add_index=False\n",
    ")\n",
    "\n",
    "aa2a_correspondences = load_csv(\n",
    "    DATA_DIR / \"entitymatching\" / \"academy_awards_2_actors_test.csv\",\n",
    "    name=\"aa2a_test\", header=None, names=['id1', 'id2', 'label'], add_index=False\n",
    ")\n",
    "\n",
    "# Evaluate blocking for a2g datasets\n",
    "a2g_results = []\n",
    "for method_name, candidates in a2g_blocking_candidates.items():\n",
    "    result = evaluator.evaluate_blocking(candidates[0], a2g_correspondences,candidates[1], out_dir=OUTPUT_DIR / \"blocking-evaluation\")\n",
    "    result['method'] = method_name\n",
    "    result['dataset'] = 'a2g'\n",
    "    a2g_results.append(result)\n",
    "\n",
    "# Evaluate blocking for aa2a datasets  \n",
    "aa2a_results = []\n",
    "for method_name, candidates in aa2a_blocking_candidates.items():\n",
    "    result = evaluator.evaluate_blocking(candidates[0], aa2a_correspondences,candidates[1], out_dir=OUTPUT_DIR / \"blocking-evaluation\")\n",
    "    result['method'] = method_name\n",
    "    result['dataset'] = 'aa2a'\n",
    "    aa2a_results.append(result)\n",
    "\n",
    "# Select best method for each dataset (highest pair_completeness, then highest reduction_ratio)\n",
    "a2g_best = max(a2g_results, key=lambda x: (x['pair_completeness'], x['reduction_ratio']))\n",
    "aa2a_best = max(aa2a_results, key=lambda x: (x['pair_completeness'], x['reduction_ratio']))\n",
    "\n",
    "print(f\"Best blocking for a2g: {a2g_best['method']} (PC: {a2g_best['pair_completeness']:.3f}, RR: {a2g_best['reduction_ratio']:.3f})\")\n",
    "print(f\"Best blocking for aa2a: {aa2a_best['method']} (PC: {aa2a_best['pair_completeness']:.3f}, RR: {aa2a_best['reduction_ratio']:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Entity Matching with Comparators\n",
    "\n",
    "Now we'll use PyDI's linear matching rule capabilities to find duplicate movies using multiple attribute comparisons.\n",
    "\n",
    "First, we define some comparators for attributes relevant to matching:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyDI.entitymatching import StringComparator, DateComparator, NumericComparator\n",
    "\n",
    "# Create comparators for different attributes\n",
    "comparators = [\n",
    "    # Title similarity - most important for movies\n",
    "    StringComparator(\n",
    "        column='title',\n",
    "        similarity_function='jaccard',  # Good for movie titles\n",
    "        preprocess=str.lower  # Case normalization\n",
    "    ),\n",
    "    \n",
    "    # Date proximity - movies from same year likely same film\n",
    "    DateComparator(\n",
    "        column='date', \n",
    "        max_days_difference=365  # Allow 1 year difference\n",
    "    ),\n",
    "    \n",
    "    # Actor name similarity - supporting evidence\n",
    "    StringComparator(\n",
    "        column='actors_actor_name',\n",
    "        similarity_function='jaccard',  # Good for names\n",
    "        preprocess=str.lower,\n",
    "        list_strategy='concatenate' # Handle list attribute by concatenation\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we setup the matcher and run the matching with our chosen best blocking method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO ] PyDI.entitymatching.blocking.embedding.EmbeddingBlocker - Initialized EmbeddingBlocker with sklearn backend, top_k=20, threshold=0.3\n",
      "[INFO ] PyDI.entitymatching.rule_based.RuleBasedMatcher - Starting Entity Matching\n",
      "[INFO ] PyDI.entitymatching.rule_based.RuleBasedMatcher - Blocking 151 x 2279 elements\n",
      "[INFO ] sentence_transformers.SentenceTransformer - Use pytorch device_name: cpu\n",
      "[INFO ] sentence_transformers.SentenceTransformer - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n",
      "[INFO ] PyDI.entitymatching.blocking.embedding.EmbeddingBlocker - Loaded sentence transformer model: sentence-transformers/all-MiniLM-L6-v2\n",
      "[INFO ] PyDI.entitymatching.blocking.embedding.EmbeddingBlocker - created 384d embeddings for first dataset\n",
      "[INFO ] PyDI.entitymatching.blocking.embedding.EmbeddingBlocker - created 384d embeddings for second dataset\n",
      "[INFO ] PyDI.entitymatching.blocking.embedding.EmbeddingBlocker - created similarity index with 2279 vectors, metric=cosine\n",
      "[INFO ] PyDI.entitymatching.blocking.embedding.EmbeddingBlocker - Debug results written to file: c:\\Users\\Ralph\\dev\\pydi\\docs\\tutorial\\output\\movies\\blocking-evaluation\\debugResultsBlocking_EmbeddingBlocker.csv\n",
      "[INFO ] PyDI.entitymatching.rule_based.RuleBasedMatcher - Matching 151 x 2279 elements after 0:00:2.841; 2945 blocked pairs (reduction ratio: 0.9914421626773681)\n",
      "[INFO ] PyDI.entitymatching.rule_based.RuleBasedMatcher - Entity Matching finished after 0:00:4.027; found 86 correspondences.\n"
     ]
    }
   ],
   "source": [
    "from PyDI.entitymatching import RuleBasedMatcher\n",
    "\n",
    "# Initialize the blocker\n",
    "embedding_blocker_a2g = EmbeddingBlocker(\n",
    "    actors, golden_globes,\n",
    "    text_cols=['title'],\n",
    "    model=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    index_backend=\"sklearn\",\n",
    "    top_k=20,          # Top 20 most similar\n",
    "    batch_size=500,\n",
    "    output_dir=OUTPUT_DIR / \"blocking-evaluation\",\n",
    "    id_column='id'\n",
    ")\n",
    "\n",
    "# Initialize Rule-Based Matcher\n",
    "matcher = RuleBasedMatcher()\n",
    "\n",
    "correspondences_a2g = matcher.match(\n",
    "    df_left=actors,\n",
    "    df_right=golden_globes, \n",
    "    candidates=embedding_blocker_a2g, # pass the blocker, which will internally generate candidate pairs using batching\n",
    "    comparators=comparators,\n",
    "    weights=[0.7, 0.2, 0.1],  # Title most important, then date, then actor,\n",
    "    threshold=0.7, # set a similarity threshold for a match\n",
    "    id_column='id'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Evaluation Against Ground Truth\n",
    "\n",
    "We can evaluate the result of our entity matching with this method of the EntityMatchingEvaluator:\n",
    "- **`evaluate_matching()`**: Evaluates matching given a test set and the predicted correspondences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO ] root - Performance Metrics:\n",
      "[INFO ] root -   Accuracy:  0.768\n",
      "[INFO ] root -   Precision: 1.000\n",
      "[INFO ] root -   Recall:    0.269\n",
      "[INFO ] root -   F1-Score:  0.424\n",
      "[INFO ] root - Confusion Matrix:\n",
      "[INFO ] root -   True Positives:  7\n",
      "[INFO ] root -   True Negatives:  56\n",
      "[INFO ] root -   False Positives: 0\n",
      "[INFO ] root -   False Negatives: 19\n",
      "[INFO ] root - Matching evaluation complete: P=1.0000 R=0.2692 F1=0.4242\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'precision': 1.0,\n",
       " 'recall': 0.2692307692307692,\n",
       " 'f1': 0.42424242424242425,\n",
       " 'accuracy': 0.7682926829268293,\n",
       " 'true_positives': 7,\n",
       " 'false_positives': 0,\n",
       " 'false_negatives': 19,\n",
       " 'true_negatives': 56,\n",
       " 'threshold_used': 0.0,\n",
       " 'total_correspondences': 86,\n",
       " 'filtered_correspondences': 86,\n",
       " 'evaluation_timestamp': '2025-09-25T15:02:35.090947',\n",
       " 'output_files': ['c:\\\\Users\\\\Ralph\\\\dev\\\\pydi\\\\docs\\\\tutorial\\\\output\\\\movies\\\\debug_results_entity_matching\\\\matching_evaluation_summary.json',\n",
       "  'c:\\\\Users\\\\Ralph\\\\dev\\\\pydi\\\\docs\\\\tutorial\\\\output\\\\movies\\\\debug_results_entity_matching\\\\matching_detailed_results.csv']}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gt_test = load_csv(\n",
    "    DATA_DIR / \"entitymatching\" / \"actors_2_golden_globes_test.csv\", \n",
    "    name=\"test_entity_matching\",\n",
    "    header=None,\n",
    "    names=['id1', 'id2', 'label'],\n",
    "    add_index=False\n",
    ")\n",
    "\n",
    "debug_output_dir = OUTPUT_DIR / \"debug_results_entity_matching\"\n",
    "debug_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "eval_results = EntityMatchingEvaluator.evaluate_matching(\n",
    "    correspondences=correspondences_a2g,\n",
    "    test_pairs=gt_test,\n",
    "    out_dir=debug_output_dir\n",
    ")\n",
    "\n",
    "display(eval_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we need more detailed debugging results, we can set the debug flag during matching and pass the resulting info object to the evaluate_matching function to write detailed debug logs to a directory of our choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO ] PyDI.entitymatching.rule_based.RuleBasedMatcher - Starting Entity Matching\n",
      "[INFO ] PyDI.entitymatching.rule_based.RuleBasedMatcher - Blocking 151 x 2279 elements\n",
      "[INFO ] PyDI.entitymatching.rule_based.RuleBasedMatcher - Matching 151 x 2279 elements after 0:00:0.099; 2945 blocked pairs (reduction ratio: 0.9914421626773681)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Re-running matcher with debug mode to capture detailed results:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO ] PyDI.entitymatching.rule_based.RuleBasedMatcher - Entity Matching finished after 0:00:1.351; found 86 correspondences.\n",
      "[INFO ] root - Debug results written to c:\\Users\\Ralph\\dev\\pydi\\docs\\tutorial\\output\\movies\\debug_results_entity_matching\\debugResultsMatchingRule.csv and c:\\Users\\Ralph\\dev\\pydi\\docs\\tutorial\\output\\movies\\debug_results_entity_matching\\debugResultsMatchingRule.csv_short\n",
      "[INFO ] root - Debug results written to c:\\Users\\Ralph\\dev\\pydi\\docs\\tutorial\\output\\movies\\debug_results_entity_matching\\debugResultsMatchingRule.csv and c:\\Users\\Ralph\\dev\\pydi\\docs\\tutorial\\output\\movies\\debug_results_entity_matching\\debugResultsMatchingRule.csv_short\n",
      "[INFO ] root - Performance Metrics:\n",
      "[INFO ] root -   Accuracy:  0.768\n",
      "[INFO ] root -   Precision: 1.000\n",
      "[INFO ] root -   Recall:    0.269\n",
      "[INFO ] root -   F1-Score:  0.424\n",
      "[INFO ] root - Confusion Matrix:\n",
      "[INFO ] root -   True Positives:  7\n",
      "[INFO ] root -   True Negatives:  56\n",
      "[INFO ] root -   False Positives: 0\n",
      "[INFO ] root -   False Negatives: 19\n",
      "[INFO ] root - Matching evaluation complete: P=1.0000 R=0.2692 F1=0.4242\n"
     ]
    }
   ],
   "source": [
    "# Re-run the matcher with debug mode enabled to get detailed debug data\n",
    "print(\"üîç Re-running matcher with debug mode to capture detailed results:\")\n",
    "\n",
    "correspondences_a2g, debug_info = matcher.match(\n",
    "    df_left=actors,\n",
    "    df_right=golden_globes, \n",
    "    candidates=embedding_blocker_a2g, # pass the blocker, which will internally generate candidate pairs using batching\n",
    "    comparators=comparators,\n",
    "    weights=[0.7, 0.2, 0.1],  # Title most important, then date, then actor,\n",
    "    threshold=0.7, # set a similarity threshold for a match\n",
    "    id_column='id',\n",
    "    debug=True  # This enables debug output capture\n",
    ")\n",
    "\n",
    "eval_results = EntityMatchingEvaluator.evaluate_matching(\n",
    "    correspondences=correspondences_a2g,\n",
    "    test_pairs=gt_test,\n",
    "    out_dir=debug_output_dir,\n",
    "    debug_info=debug_info, # add debug info\n",
    "    matcher_instance=matcher # add matcher instance for context for debug files\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another helpful tool for investigating the goodness of the matching is to create the cluster size distribution that shows how many clusters (records referencing same entity) after matching exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO ] root - Cluster Size Distribution of 80 clusters:\n",
      "[INFO ] root - \tCluster Size\t| Frequency\t| Percentage\n",
      "[INFO ] root - \t‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "[INFO ] root - \t\t2\t|\t78\t|\t97.50%\n",
      "[INFO ] root - \t\t3\t|\t1\t|\t1.25%\n",
      "[INFO ] root - \t\t7\t|\t1\t|\t1.25%\n",
      "[INFO ] root - Cluster size distribution written to c:\\Users\\Ralph\\dev\\pydi\\docs\\tutorial\\output\\movies\\cluster_analysis\\cluster_size_distribution.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing cluster size distribution in our entity matching results...\n",
      "\n",
      "üìä Cluster Size Distribution Results:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster_size</th>\n",
       "      <th>frequency</th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>78</td>\n",
       "      <td>97.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cluster_size  frequency  percentage\n",
       "0             2         78       97.50\n",
       "1             3          1        1.25\n",
       "2             7          1        1.25"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Analyzing cluster size distribution in our entity matching results...\")\n",
    "\n",
    "# Create cluster size distribution from our matches\n",
    "cluster_distribution = EntityMatchingEvaluator.create_cluster_size_distribution(\n",
    "    correspondences=correspondences_a2g,\n",
    "    out_dir=str(OUTPUT_DIR / \"cluster_analysis\")\n",
    ")\n",
    "\n",
    "print(f\"\\nüìä Cluster Size Distribution Results:\")\n",
    "display(cluster_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we see strange distribution of clusters, we can further investigate specific clusters by writing out detailed cluster information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO ] root - Cluster details written to c:\\Users\\Ralph\\dev\\pydi\\docs\\tutorial\\output\\movies\\cluster_analysis\\detailed_cluster_info.json\n",
      "[INFO ] root - Exported 80 clusters with detailed record information\n"
     ]
    }
   ],
   "source": [
    "# Write out detailed cluster information with all entity records for debugging purposes\n",
    "\n",
    "# Use the matches we found earlier to demonstrate cluster details\n",
    "cluster_details_path = OUTPUT_DIR / \"cluster_analysis\" / \"detailed_cluster_info.json\"\n",
    "\n",
    "# Call write_cluster_details with our entity matches\n",
    "output_path = EntityMatchingEvaluator.write_cluster_details(\n",
    "    correspondences=correspondences_a2g,\n",
    "    out_path=cluster_details_path\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, PyDI offers 6 different post-clustering methods to \"clean\" clusters after entity matching. For example, if we want to enforce that each record in a dataset can only have exactly one correspondence in the other dataset, we can apply a greedy one-to-one matching, maximum bipartite matching or stable marriage matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO ] root - Filtered correspondences: 86 -> 86 (threshold=0.0)\n",
      "[INFO ] root - Maximum bipartite matching: 86 -> 80 \n",
      "[INFO ] root - MaximumBipartiteMatching: 86 -> 80 correspondences\n",
      "[INFO ] root - MaximumBipartiteMatching: 166 -> 160 entities\n",
      "[INFO ] root - Filtered correspondences: 86 -> 86 (threshold=0.0)\n",
      "[INFO ] root - Stable matching: 86 -> 80 correspondences (160 entities matched)\n",
      "[INFO ] root - StableMatching: 86 -> 80 correspondences\n",
      "[INFO ] root - StableMatching: 166 -> 160 entities\n"
     ]
    }
   ],
   "source": [
    "from PyDI.entitymatching import MaximumBipartiteMatching, StableMatching\n",
    "\n",
    "# use Maximum Bipartite Matching to refine results to 1:1 matches\n",
    "clusterer = MaximumBipartiteMatching()\n",
    "mbm_correspondences_a2g = clusterer.cluster(correspondences_a2g)\n",
    "\n",
    "# use Stable Matching to refine results to 1:1 matches\n",
    "clusterer = StableMatching()\n",
    "sm_correspondences_a2g = clusterer.cluster(correspondences_a2g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Machine Learning-based Matching Rules\n",
    "\n",
    "Instead of using manually configured matching rules, we can also learn the weights and best comparators using machine learning if we have a labeled training set available.\n",
    "\n",
    "Let's do this for the dataset combination Academy Awards <-> Actors.\n",
    "\n",
    "First, we need to create the features for machine learning using PyDIs FeatureExtractor class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] root - Record not found: 'actors_154'\n",
      "[WARNING] root - Record not found: 'actors_174'\n",
      "[WARNING] root - Record not found: 'actors_160'\n",
      "[WARNING] root - Record not found: 'actors_158'\n",
      "[WARNING] root - Record not found: 'actors_156'\n",
      "[WARNING] root - Record not found: 'actors_152'\n",
      "[WARNING] root - Record not found: 'actors_159'\n",
      "[WARNING] root - Record not found: 'actors_173'\n",
      "[WARNING] root - Record not found: 'actors_161'\n",
      "[WARNING] root - Record not found: 'actors_153'\n",
      "[WARNING] root - Record not found: 'actors_162'\n",
      "[WARNING] root - Record not found: 'actors_155'\n",
      "[WARNING] root - Record not found: 'actors_157'\n",
      "[WARNING] root - Record not found: 'actors_171'\n",
      "[WARNING] root - Record not found: 'actors_168'\n",
      "[WARNING] root - Record not found: 'actors_169'\n",
      "[WARNING] root - Record not found: 'actors_165'\n",
      "[WARNING] root - Record not found: 'actors_172'\n",
      "[WARNING] root - Record not found: 'actors_167'\n",
      "[WARNING] root - Record not found: 'actors_164'\n",
      "[WARNING] root - Record not found: 'actors_170'\n",
      "[WARNING] root - Record not found: 'actors_166'\n",
      "[WARNING] root - Record not found: 'actors_163'\n",
      "[WARNING] root - Record not found: nan\n",
      "[WARNING] root - Record not found: nan\n",
      "[WARNING] root - Record not found: nan\n",
      "[WARNING] root - Record not found: nan\n",
      "[INFO ] root - Label distribution: 103 positive, 232 negative\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Training features extracted!\n",
      "Feature columns: ['StringComparator(title, jaro_winkler, tokenization=char, list_strategy=None)', 'StringComparator(title, levenshtein, tokenization=char, list_strategy=None)', 'StringComparator(title, cosine, tokenization=word, list_strategy=None)', 'StringComparator(title, jaccard, tokenization=word, list_strategy=None)', 'DateComparator(date, list_strategy=None)', 'StringComparator(actors_actor_name, jaccard, tokenization=word, list_strategy=concatenate)', 'StringComparator(actors_actor_name, jaccard, tokenization=word, list_strategy=best_match)']\n",
      "Training data: X=(335, 7), y=(335,)\n",
      "Class distribution: {False: 232, True: 103}\n"
     ]
    }
   ],
   "source": [
    "from PyDI.entitymatching import FeatureExtractor\n",
    "\n",
    "# Load ground truth correspondences\n",
    "aa2a_train = load_csv(\n",
    "    DATA_DIR / \"entitymatching\" / \"academy_awards_2_actors_training.csv\",\n",
    "    name=\"ground_truth_train\",\n",
    "    header=None,\n",
    "    names=['id1', 'id2', 'label'],\n",
    "    add_index=False\n",
    ")\n",
    "\n",
    "aa2a_test = load_csv(\n",
    "    DATA_DIR / \"entitymatching\" / \"academy_awards_2_actors_test.csv\",\n",
    "    name=\"ground_truth_test\",\n",
    "    header=None,\n",
    "    names=['id1', 'id2', 'label'],\n",
    "    add_index=False\n",
    ")\n",
    "\n",
    "similarity_comparators = [\n",
    "    # Title similarity features - most important for movie matching\n",
    "    StringComparator(\"title\", similarity_function=\"jaro_winkler\", preprocess=str.lower),\n",
    "    StringComparator(\"title\", similarity_function=\"levenshtein\", preprocess=str.lower),\n",
    "    StringComparator(\"title\", similarity_function=\"cosine\", preprocess=str.lower),\n",
    "    StringComparator(\"title\", similarity_function=\"jaccard\", preprocess=str.lower),\n",
    "    \n",
    "    # Date proximity features\n",
    "    DateComparator(\"date\", max_days_difference=365),  # 1 years tolerance\n",
    "    \n",
    "    # Actor name similarity\n",
    "    StringComparator(\"actors_actor_name\", similarity_function=\"jaccard\", preprocess=str.lower, list_strategy='concatenate'),\n",
    "    StringComparator(\"actors_actor_name\", similarity_function=\"jaccard\", preprocess=str.lower, list_strategy='best_match'),\n",
    "]\n",
    "\n",
    "feature_extractor = FeatureExtractor(similarity_comparators)\n",
    "\n",
    "# Extract features using FeatureExtractor\n",
    "train_features = feature_extractor.create_features(\n",
    "    academy_awards, actors, aa2a_train[['id1', 'id2']], labels=aa2a_train['label'], id_column='id'\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Training features extracted!\")\n",
    "print(f\"Feature columns: {[col for col in train_features.columns if col not in ['id1', 'id2', 'label']]}\")\n",
    "\n",
    "# Prepare data for ML training\n",
    "feature_columns = [col for col in train_features.columns if col not in ['id1', 'id2', 'label']]\n",
    "\n",
    "X_train = train_features[feature_columns]\n",
    "y_train = train_features['label']\n",
    "\n",
    "print(f\"Training data: X={X_train.shape}, y={y_train.shape}\")\n",
    "print(f\"Class distribution: {y_train.value_counts().to_dict()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Full Scikit-learn integration\n",
    "\n",
    "From here on out, the full scikit-learn library can be used with the features extracted from PyDIs feature extractor without any wrapping as everything in PyDI is based on pandas dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Setting up GridSearchCV...\n",
      "GridSearch setup: 4 models, F1 scoring, 5-fold CV\n",
      "\n",
      "üöÄ Training Models with GridSearchCV...\n",
      "\n",
      "Training RandomForest...\n",
      "  ‚úÖ RandomForest: Best CV F1 = 0.9856\n",
      "     Best params: {'class_weight': 'balanced', 'max_depth': 5, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "\n",
      "Training LogisticRegression...\n",
      "  ‚úÖ LogisticRegression: Best CV F1 = 0.9902\n",
      "     Best params: {'C': 0.1, 'class_weight': None, 'penalty': 'l2'}\n",
      "\n",
      "Training GradientBoosting...\n",
      "  ‚úÖ GradientBoosting: Best CV F1 = 0.9905\n",
      "     Best params: {'learning_rate': 0.2, 'max_depth': 5, 'n_estimators': 50}\n",
      "\n",
      "Training SVM...\n",
      "  ‚úÖ SVM: Best CV F1 = 0.9902\n",
      "     Best params: {'C': 0.1, 'class_weight': 'balanced', 'kernel': 'rbf'}\n",
      "\n",
      "üèÜ Best Overall Model: GradientBoosting (CV F1: 0.9905)\n"
     ]
    }
   ],
   "source": [
    "# Set up GridSearchCV with multiple models and hyperparameters\n",
    "print(f\"\\nüîç Setting up GridSearchCV...\")\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "\n",
    "# Define models and parameter grids\n",
    "param_grids = {\n",
    "    'RandomForest': {\n",
    "        'model': RandomForestClassifier(random_state=42),\n",
    "        'params': {\n",
    "            'n_estimators': [50, 100, 200],\n",
    "            'max_depth': [5, 10, None],\n",
    "            'min_samples_split': [2, 5],\n",
    "            'class_weight': ['balanced', None]\n",
    "        }\n",
    "    },\n",
    "    'LogisticRegression': {\n",
    "        'model': LogisticRegression(random_state=42, max_iter=1000),\n",
    "        'params': {\n",
    "            'C': [0.1, 1.0, 10.0],\n",
    "            'penalty': ['l2'],\n",
    "            'class_weight': ['balanced', None]\n",
    "        }\n",
    "    },\n",
    "    'GradientBoosting': {\n",
    "        'model': GradientBoostingClassifier(random_state=42),\n",
    "        'params': {\n",
    "            'n_estimators': [50, 100],\n",
    "            'learning_rate': [0.1, 0.2],\n",
    "            'max_depth': [3, 5],\n",
    "        }\n",
    "    },\n",
    "    'SVM': {\n",
    "        'model': SVC(random_state=42, probability=True),\n",
    "        'params': {\n",
    "            'C': [0.1, 1.0, 10.0],\n",
    "            'kernel': ['rbf', 'linear'],\n",
    "            'class_weight': ['balanced', None]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Use F1 score as the scoring metric (good for imbalanced data)\n",
    "scorer = make_scorer(f1_score)\n",
    "cv_folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "print(f\"GridSearch setup: {len(param_grids)} models, F1 scoring, 5-fold CV\")\n",
    "\n",
    "# Train models using GridSearchCV\n",
    "print(f\"\\nüöÄ Training Models with GridSearchCV...\")\n",
    "\n",
    "grid_search_results = {}\n",
    "best_overall_score = -1\n",
    "best_overall_model = None\n",
    "best_model_name = None\n",
    "\n",
    "for model_name, config in param_grids.items():\n",
    "    print(f\"\\nTraining {model_name}...\")\n",
    "    \n",
    "\n",
    "    # Create GridSearchCV\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=config['model'],\n",
    "        param_grid=config['params'],\n",
    "        scoring=scorer,\n",
    "        cv=cv_folds,\n",
    "        n_jobs=-1,  # Use all available cores\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    # Fit GridSearchCV\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Store results\n",
    "    grid_search_results[model_name] = {\n",
    "        'grid_search': grid_search,\n",
    "        'best_score': grid_search.best_score_,\n",
    "        'best_params': grid_search.best_params_,\n",
    "        'best_estimator': grid_search.best_estimator_\n",
    "    }\n",
    "    \n",
    "    print(f\"  ‚úÖ {model_name}: Best CV F1 = {grid_search.best_score_:.4f}\")\n",
    "    print(f\"     Best params: {grid_search.best_params_}\")\n",
    "    \n",
    "    # Track overall best model\n",
    "    if grid_search.best_score_ > best_overall_score:\n",
    "        best_overall_score = grid_search.best_score_\n",
    "        best_overall_model = grid_search.best_estimator_\n",
    "        best_model_name = model_name\n",
    "            \n",
    "print(f\"\\nüèÜ Best Overall Model: {best_model_name} (CV F1: {best_overall_score:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can directly use the trained model with PyDIs MLBasedMatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO ] PyDI.entitymatching.ml_based.MLBasedMatcher - Starting Entity Matching\n",
      "[INFO ] PyDI.entitymatching.ml_based.MLBasedMatcher - Blocking 4580 x 151 elements\n",
      "[INFO ] PyDI.entitymatching.ml_based.MLBasedMatcher - Matching 4580 x 151 elements after 0:00:0.850; 39558 blocked pairs (reduction ratio: 0.9428005436825819)\n",
      "[INFO ] PyDI.entitymatching.ml_based.MLBasedMatcher - Entity Matching finished after 0:00:16.290; found 150 correspondences.\n"
     ]
    }
   ],
   "source": [
    "from PyDI.entitymatching import MLBasedMatcher\n",
    "\n",
    "# Create MLBasedMatcher and apply trained model\n",
    "ml_matcher = MLBasedMatcher(feature_extractor)\n",
    "\n",
    "correspondences_aa2a = ml_matcher.match(\n",
    "    academy_awards, actors, candidates=embedding_blocker_aa2a, id_column='id', trained_classifier=best_overall_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Top Feature Importances:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>StringComparator(actors_actor_name, jaccard, t...</td>\n",
       "      <td>0.5782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>StringComparator(actors_actor_name, jaccard, t...</td>\n",
       "      <td>0.3943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>StringComparator(title, levenshtein, tokenizat...</td>\n",
       "      <td>0.0275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>StringComparator(title, cosine, tokenization=w...</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>StringComparator(title, jaro_winkler, tokeniza...</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DateComparator(date, list_strategy=None)</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>StringComparator(title, jaccard, tokenization=...</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             feature importance\n",
       "6  StringComparator(actors_actor_name, jaccard, t...     0.5782\n",
       "5  StringComparator(actors_actor_name, jaccard, t...     0.3943\n",
       "1  StringComparator(title, levenshtein, tokenizat...     0.0275\n",
       "2  StringComparator(title, cosine, tokenization=w...     0.0000\n",
       "0  StringComparator(title, jaro_winkler, tokeniza...     0.0000\n",
       "4           DateComparator(date, list_strategy=None)     0.0000\n",
       "3  StringComparator(title, jaccard, tokenization=...     0.0000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show feature importance if available\n",
    "if hasattr(best_overall_model, 'feature_importances_'):\n",
    "    print(f\"\\nüîç Top Feature Importances:\")\n",
    "    importance_df = ml_matcher.get_feature_importance(best_overall_model, feature_columns)\n",
    "    display(importance_df.head(8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's evaluate the ML-based matching with the evaluator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO ] root - Performance Metrics:\n",
      "[INFO ] root -   Accuracy:  1.000\n",
      "[INFO ] root -   Precision: 1.000\n",
      "[INFO ] root -   Recall:    1.000\n",
      "[INFO ] root -   F1-Score:  1.000\n",
      "[INFO ] root - Confusion Matrix:\n",
      "[INFO ] root -   True Positives:  47\n",
      "[INFO ] root -   True Negatives:  3300\n",
      "[INFO ] root -   False Positives: 0\n",
      "[INFO ] root -   False Negatives: 0\n",
      "[INFO ] root - Matching evaluation complete: P=1.0000 R=1.0000 F1=1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'precision': 1.0,\n",
       " 'recall': 1.0,\n",
       " 'f1': 1.0,\n",
       " 'accuracy': 1.0,\n",
       " 'true_positives': 47,\n",
       " 'false_positives': 0,\n",
       " 'false_negatives': 0,\n",
       " 'true_negatives': 3300,\n",
       " 'threshold_used': 0.0,\n",
       " 'total_correspondences': 150,\n",
       " 'filtered_correspondences': 150,\n",
       " 'evaluation_timestamp': '2025-09-25T15:02:56.752762',\n",
       " 'output_files': ['c:\\\\Users\\\\Ralph\\\\dev\\\\pydi\\\\docs\\\\tutorial\\\\output\\\\movies\\\\debug_results_entity_matching\\\\matching_evaluation_summary.json',\n",
       "  'c:\\\\Users\\\\Ralph\\\\dev\\\\pydi\\\\docs\\\\tutorial\\\\output\\\\movies\\\\debug_results_entity_matching\\\\matching_detailed_results.csv']}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO ] root - Cluster Size Distribution of 148 clusters:\n",
      "[INFO ] root - \tCluster Size\t| Frequency\t| Percentage\n",
      "[INFO ] root - \t‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "[INFO ] root - \t\t2\t|\t146\t|\t98.65%\n",
      "[INFO ] root - \t\t3\t|\t2\t|\t1.35%\n",
      "[INFO ] root - Cluster size distribution written to c:\\Users\\Ralph\\dev\\pydi\\docs\\tutorial\\output\\movies\\cluster_analysis\\cluster_size_distribution.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Cluster Size Distribution Results:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster_size</th>\n",
       "      <th>frequency</th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>146</td>\n",
       "      <td>98.648649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1.351351</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cluster_size  frequency  percentage\n",
       "0             2        146   98.648649\n",
       "1             3          2    1.351351"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_results = EntityMatchingEvaluator.evaluate_matching(\n",
    "    correspondences=correspondences_aa2a,\n",
    "    test_pairs=aa2a_test,\n",
    "    out_dir=debug_output_dir\n",
    ")\n",
    "\n",
    "display(eval_results)\n",
    "\n",
    "# Create cluster size distribution from our matches\n",
    "cluster_distribution = EntityMatchingEvaluator.create_cluster_size_distribution(\n",
    "    correspondences=correspondences_aa2a,\n",
    "    out_dir=OUTPUT_DIR / \"cluster_analysis\"\n",
    ")\n",
    "\n",
    "print(f\"\\nüìä Cluster Size Distribution Results:\")\n",
    "display(cluster_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively to similarity metrics for each attribute, PyDIs VectorFeatureExtractor can be used to create embeddings using SentenceTransformers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO ] sentence_transformers.SentenceTransformer - Use pytorch device_name: cpu\n",
      "[INFO ] sentence_transformers.SentenceTransformer - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n",
      "[INFO ] root - Initialized VectorFeatureExtractor with model sentence-transformers/all-MiniLM-L6-v2\n",
      "[INFO ] root - Computing vector features for 362 pairs\n",
      "[INFO ] root - Computing embeddings for left dataset...\n",
      "[INFO ] root - Computing embeddings for right dataset...\n",
      "[WARNING] root - Missing embedding for pair academy_awards_1272-actors_154\n",
      "[WARNING] root - Missing embedding for pair academy_awards_1541-actors_174\n",
      "[WARNING] root - Missing embedding for pair academy_awards_1633-actors_160\n",
      "[WARNING] root - Missing embedding for pair academy_awards_1880-actors_158\n",
      "[WARNING] root - Missing embedding for pair academy_awards_2141-actors_156\n",
      "[WARNING] root - Missing embedding for pair academy_awards_2187-actors_152\n",
      "[WARNING] root - Missing embedding for pair academy_awards_2288-actors_159\n",
      "[WARNING] root - Missing embedding for pair academy_awards_2334-actors_173\n",
      "[WARNING] root - Missing embedding for pair academy_awards_2620-actors_161\n",
      "[WARNING] root - Missing embedding for pair academy_awards_2625-actors_153\n",
      "[WARNING] root - Missing embedding for pair academy_awards_3423-actors_162\n",
      "[WARNING] root - Missing embedding for pair academy_awards_3713-actors_155\n",
      "[WARNING] root - Missing embedding for pair academy_awards_3813-actors_157\n",
      "[WARNING] root - Missing embedding for pair academy_awards_4397-actors_171\n",
      "[WARNING] root - Missing embedding for pair academy_awards_4399-actors_168\n",
      "[WARNING] root - Missing embedding for pair academy_awards_4442-actors_169\n",
      "[WARNING] root - Missing embedding for pair academy_awards_4444-actors_165\n",
      "[WARNING] root - Missing embedding for pair academy_awards_4446-actors_172\n",
      "[WARNING] root - Missing embedding for pair academy_awards_4475-actors_167\n",
      "[WARNING] root - Missing embedding for pair academy_awards_4491-actors_164\n",
      "[WARNING] root - Missing embedding for pair academy_awards_4500-actors_170\n",
      "[WARNING] root - Missing embedding for pair academy_awards_4520-actors_166\n",
      "[WARNING] root - Missing embedding for pair academy_awards_4529-actors_163\n",
      "[WARNING] root - Missing embedding for pair nan-nan\n",
      "[WARNING] root - Missing embedding for pair nan-nan\n",
      "[WARNING] root - Missing embedding for pair nan-nan\n",
      "[WARNING] root - Missing embedding for pair nan-nan\n",
      "[INFO ] root - Vector feature extraction complete: 335 pairs embedded.\n"
     ]
    }
   ],
   "source": [
    "# VectorFeatureExtractor Examples\n",
    "\n",
    "from PyDI.entitymatching import VectorFeatureExtractor\n",
    "\n",
    "# SentenceTransformers embeddings using VectorFeatureExtractor\n",
    "st_extractor = VectorFeatureExtractor(\n",
    "    embedding_model='sentence-transformers/all-MiniLM-L6-v2',\n",
    "    columns=['title', 'actors_actor_name', 'date'],\n",
    "    distance_metrics=['cosine'],\n",
    "    pooling_strategy='concatenate',\n",
    "    list_strategies={'actors_actor_name': 'concatenate'}\n",
    ")\n",
    "\n",
    "# Extract features using VectorFeatureExtractor\n",
    "train_features = st_extractor.create_features(\n",
    "    academy_awards, actors, aa2a_train[['id1', 'id2']], labels=aa2a_train['label'], id_column='id'\n",
    ")\n",
    "\n",
    "# ready to train ML models with scikit-learn as before\n",
    "# matching workflow is analogous to previous example with FeatureExtractor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Data Fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "academy_awards[\"academy_awards_id\"] = academy_awards[\"id\"]\n",
    "\n",
    "academy_awards.attrs[\"trust_score\"] = 3\n",
    "actors.attrs[\"trust_score\"] = 2\n",
    "golden_globes.attrs[\"trust_score\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total correspondences: 236\n"
     ]
    }
   ],
   "source": [
    "all_correspondences = pd.concat([correspondences_a2g, correspondences_aa2a], ignore_index=True)\n",
    "print(f'Total correspondences: {len(all_correspondences):,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Fusion Strategy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO ] PyDI.fusion.strategy - Registered fuser for attribute 'title' using rule 'longest_string'\n",
      "[INFO ] PyDI.fusion.strategy - Registered fuser for attribute 'director_name' using rule 'longest_string'\n",
      "[INFO ] PyDI.fusion.strategy - Registered fuser for attribute 'date' using rule 'prefer_higher_trust'\n",
      "[INFO ] PyDI.fusion.strategy - Registered fuser for attribute 'actors_actor_name' using rule 'union'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strategy ready.\n"
     ]
    }
   ],
   "source": [
    "from PyDI.fusion import DataFusionStrategy, longest_string, union, prefer_higher_trust\n",
    "\n",
    "strategy = DataFusionStrategy('movie_fusion_strategy')\n",
    "\n",
    "strategy.add_attribute_fuser('title', longest_string)\n",
    "strategy.add_attribute_fuser('director_name', longest_string)\n",
    "strategy.add_attribute_fuser('date', prefer_higher_trust, trust_key=\"trust_score\")\n",
    "\n",
    "strategy.add_attribute_fuser('actors_actor_name', union)\n",
    "\n",
    "print('Strategy ready.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Fusion\n",
    "We build connected components from the converted correspondences and fuse per attribute using the rules above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO ] PyDI.fusion.engine - Fusion debug logging enabled; refer to c:\\Users\\Ralph\\dev\\pydi\\docs\\tutorial\\output\\movies\\data_fusion\\debug_fusion.jsonl for detailed traces.\n",
      "[INFO ] PyDI.fusion.engine - Starting data fusion with strategy 'movie_fusion_strategy'\n",
      "[INFO ] PyDI.fusion.engine - Correspondence ID coverage: matched 383 of 383 unique IDs\n",
      "[INFO ] PyDI.fusion.engine - Created 6775 record groups from 236 correspondences\n",
      "[INFO ] PyDI.fusion.engine - Group size distribution (size: count): 1: 6627, 2: 67, 3: 79, 4: 1, 8: 1\n",
      "[INFO ] PyDI.fusion.engine - Fusion complete: 148 records from 148 groups\n",
      "[INFO ] PyDI.fusion.engine - Fusion time: 0.62 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fused rows: 148\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>_fusion_group_id</th>\n",
       "      <th>_fusion_sources</th>\n",
       "      <th>id</th>\n",
       "      <th>title_prefix</th>\n",
       "      <th>actors_actor_birthplace</th>\n",
       "      <th>academy_awards_id</th>\n",
       "      <th>date</th>\n",
       "      <th>oscar</th>\n",
       "      <th>director_name</th>\n",
       "      <th>actors_actor_birthday</th>\n",
       "      <th>actors_actor_name</th>\n",
       "      <th>title</th>\n",
       "      <th>_fusion_confidence</th>\n",
       "      <th>_fusion_metadata</th>\n",
       "      <th>globe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>actors_141</td>\n",
       "      <td>group_0</td>\n",
       "      <td>[academy_awards, actors]</td>\n",
       "      <td>actors_141</td>\n",
       "      <td>FOGU</td>\n",
       "      <td>California</td>\n",
       "      <td>academy_awards_902</td>\n",
       "      <td>1994-01-01</td>\n",
       "      <td>yes</td>\n",
       "      <td>Robert Zemeckis</td>\n",
       "      <td>1956-01-01</td>\n",
       "      <td>[Gary Sinise, Tom Hanks]</td>\n",
       "      <td>Forrest Gump</td>\n",
       "      <td>0.671296</td>\n",
       "      <td>{'id_rule': 'first_non_null', 'title_prefix_ru...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>golden_globes_2004</td>\n",
       "      <td>group_1</td>\n",
       "      <td>[academy_awards, golden_globes, actors]</td>\n",
       "      <td>golden_globes_2004</td>\n",
       "      <td>MAFOAL</td>\n",
       "      <td>England</td>\n",
       "      <td>academy_awards_2337</td>\n",
       "      <td>1966-01-01</td>\n",
       "      <td>yes</td>\n",
       "      <td>Fred Zinnemann</td>\n",
       "      <td>1922-01-01</td>\n",
       "      <td>[Paul Scofield, Robert Shaw, Wendy Hiller]</td>\n",
       "      <td>Man For All Seasons, a</td>\n",
       "      <td>0.602273</td>\n",
       "      <td>{'id_rule': 'first_non_null', 'title_prefix_ru...</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>actors_126</td>\n",
       "      <td>group_2</td>\n",
       "      <td>[academy_awards, actors]</td>\n",
       "      <td>actors_126</td>\n",
       "      <td>ONFLOV</td>\n",
       "      <td>New York</td>\n",
       "      <td>academy_awards_1880</td>\n",
       "      <td>1975-01-01</td>\n",
       "      <td>yes</td>\n",
       "      <td>Milos Forman</td>\n",
       "      <td>1937-01-01</td>\n",
       "      <td>[Brad Dourif, Jack Nicholson, Louise Fletcher]</td>\n",
       "      <td>One Flew over the Cuckoo's Nest</td>\n",
       "      <td>0.668459</td>\n",
       "      <td>{'id_rule': 'first_non_null', 'title_prefix_ru...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>actors_29</td>\n",
       "      <td>group_3</td>\n",
       "      <td>[academy_awards, golden_globes, actors]</td>\n",
       "      <td>actors_29</td>\n",
       "      <td>AN</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>academy_awards_2892</td>\n",
       "      <td>1956-01-01</td>\n",
       "      <td>yes</td>\n",
       "      <td>None</td>\n",
       "      <td>1915-01-01</td>\n",
       "      <td>[Helen Hayes, Ingrid Bergman]</td>\n",
       "      <td>Anastasia</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>{'id_rule': 'first_non_null', 'title_prefix_ru...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>academy_awards_503</td>\n",
       "      <td>group_4</td>\n",
       "      <td>[academy_awards, golden_globes, actors]</td>\n",
       "      <td>academy_awards_503</td>\n",
       "      <td>TRDA</td>\n",
       "      <td>New York</td>\n",
       "      <td>academy_awards_503</td>\n",
       "      <td>2001-01-01</td>\n",
       "      <td>yes</td>\n",
       "      <td>None</td>\n",
       "      <td>1954-01-01</td>\n",
       "      <td>[Denzel Washington, Ethan Hawke]</td>\n",
       "      <td>Training Day</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>{'id_rule': 'first_non_null', 'title_prefix_ru...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  _id _fusion_group_id  \\\n",
       "0          actors_141          group_0   \n",
       "1  golden_globes_2004          group_1   \n",
       "2          actors_126          group_2   \n",
       "3           actors_29          group_3   \n",
       "4  academy_awards_503          group_4   \n",
       "\n",
       "                           _fusion_sources                  id title_prefix  \\\n",
       "0                 [academy_awards, actors]          actors_141         FOGU   \n",
       "1  [academy_awards, golden_globes, actors]  golden_globes_2004       MAFOAL   \n",
       "2                 [academy_awards, actors]          actors_126       ONFLOV   \n",
       "3  [academy_awards, golden_globes, actors]           actors_29           AN   \n",
       "4  [academy_awards, golden_globes, actors]  academy_awards_503         TRDA   \n",
       "\n",
       "  actors_actor_birthplace    academy_awards_id        date oscar  \\\n",
       "0              California   academy_awards_902  1994-01-01   yes   \n",
       "1                 England  academy_awards_2337  1966-01-01   yes   \n",
       "2                New York  academy_awards_1880  1975-01-01   yes   \n",
       "3                  Sweden  academy_awards_2892  1956-01-01   yes   \n",
       "4                New York   academy_awards_503  2001-01-01   yes   \n",
       "\n",
       "     director_name actors_actor_birthday  \\\n",
       "0  Robert Zemeckis            1956-01-01   \n",
       "1   Fred Zinnemann            1922-01-01   \n",
       "2     Milos Forman            1937-01-01   \n",
       "3             None            1915-01-01   \n",
       "4             None            1954-01-01   \n",
       "\n",
       "                                actors_actor_name  \\\n",
       "0                        [Gary Sinise, Tom Hanks]   \n",
       "1      [Paul Scofield, Robert Shaw, Wendy Hiller]   \n",
       "2  [Brad Dourif, Jack Nicholson, Louise Fletcher]   \n",
       "3                   [Helen Hayes, Ingrid Bergman]   \n",
       "4                [Denzel Washington, Ethan Hawke]   \n",
       "\n",
       "                             title  _fusion_confidence  \\\n",
       "0                     Forrest Gump            0.671296   \n",
       "1           Man For All Seasons, a            0.602273   \n",
       "2  One Flew over the Cuckoo's Nest            0.668459   \n",
       "3                        Anastasia            0.500000   \n",
       "4                     Training Day            0.500000   \n",
       "\n",
       "                                    _fusion_metadata globe  \n",
       "0  {'id_rule': 'first_non_null', 'title_prefix_ru...   NaN  \n",
       "1  {'id_rule': 'first_non_null', 'title_prefix_ru...   yes  \n",
       "2  {'id_rule': 'first_non_null', 'title_prefix_ru...   NaN  \n",
       "3  {'id_rule': 'first_non_null', 'title_prefix_ru...  None  \n",
       "4  {'id_rule': 'first_non_null', 'title_prefix_ru...  None  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from PyDI.fusion import DataFusionEngine\n",
    "\n",
    "engine = DataFusionEngine(strategy, debug=True, debug_format='json',debug_file=OUTPUT_DIR / \"data_fusion\" / \"debug_fusion.jsonl\")\n",
    "\n",
    "fused = engine.run(\n",
    "    datasets=[academy_awards, actors, golden_globes],\n",
    "    correspondences=all_correspondences,\n",
    "    id_column=\"id\",\n",
    "    include_singletons=False,\n",
    ")\n",
    "print(f'Fused rows: {len(fused):,}')\n",
    "display(fused.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate with Gold Standard\n",
    "We load the gold standard and evaluate accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO ] PyDI.fusion.strategy - Registered evaluation function for attribute 'title'\n",
      "[INFO ] PyDI.fusion.strategy - Registered evaluation function for attribute 'director_name'\n",
      "[INFO ] PyDI.fusion.strategy - Registered evaluation function for attribute 'actors_actor_name'\n",
      "[INFO ] PyDI.fusion.strategy - Registered evaluation function for attribute 'date'\n",
      "[INFO ] PyDI.fusion.strategy - Registered evaluation function for attribute 'oscar'\n"
     ]
    }
   ],
   "source": [
    "from PyDI.fusion import tokenized_match, year_only_match, boolean_match\n",
    "\n",
    "strategy.add_evaluation_function(\"title\", tokenized_match)\n",
    "strategy.add_evaluation_function(\"director_name\", tokenized_match)\n",
    "strategy.add_evaluation_function(\"actors_actor_name\", tokenized_match)\n",
    "strategy.add_evaluation_function(\"date\", year_only_match)\n",
    "strategy.add_evaluation_function(\"oscar\", boolean_match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO ] PyDI.fusion.evaluation - Starting fusion evaluation\n",
      "[INFO ] PyDI.fusion.evaluation - Evaluation complete: 0.947 overall accuracy (90/95)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fusion results against gold standard...\n",
      "\n",
      "Fusion Evaluation Results:\n",
      "========================================\n",
      "  overall_accuracy: 0.947\n",
      "  macro_accuracy: 0.950\n",
      "  num_evaluated_records: 20\n",
      "  num_evaluated_attributes: 5\n",
      "  total_evaluations: 95\n",
      "  total_correct: 90\n",
      "  date_accuracy: 0.950\n",
      "  date_count: 20\n",
      "  oscar_accuracy: 1.000\n",
      "  oscar_count: 20\n",
      "  director_name_accuracy: 1.000\n",
      "  director_name_count: 15\n",
      "  actors_actor_name_accuracy: 0.850\n",
      "  actors_actor_name_count: 20\n",
      "  title_accuracy: 0.950\n",
      "  title_count: 20\n",
      "\n",
      "Overall Accuracy: 94.7%\n"
     ]
    }
   ],
   "source": [
    "from PyDI.fusion import DataFusionEvaluator\n",
    "\n",
    "fusion_test_set = load_xml(DATA_DIR / 'fusion' / 'test_set.xml', name='fusion_test_set', nested_handling='aggregate')\n",
    "\n",
    "# Keep core evaluation columns if present in fused output\n",
    "eval_cols = ['academy_awards_id','title','director_name','actors_actor_name','date','oscar']\n",
    "fused_eval = fused[eval_cols].copy()\n",
    "\n",
    "# Create evaluator with our fusion strategy\n",
    "evaluator = DataFusionEvaluator(strategy)\n",
    "\n",
    "# Evaluate the fused results against the gold standard\n",
    "print(\"Evaluating fusion results against gold standard...\")\n",
    "evaluation_results = evaluator.evaluate(\n",
    "    fused_df=fused_eval,\n",
    "    fused_id_column='academy_awards_id',\n",
    "    gold_df=fusion_test_set,\n",
    "    gold_id_column='id',\n",
    ")\n",
    "\n",
    "# Display evaluation metrics\n",
    "print(\"\\nFusion Evaluation Results:\")\n",
    "print(\"=\" * 40)\n",
    "for metric, value in evaluation_results.items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"  {metric}: {value:.3f}\")\n",
    "    else:\n",
    "        print(f\"  {metric}: {value}\")\n",
    "        \n",
    "print(f\"\\nOverall Accuracy: {evaluation_results.get('overall_accuracy', 0):.1%}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
